{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant packages\n",
    "%run /Users/thomasadler/Desktop/futuristic-platipus/notebooks/ta_01_packages.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful functions\n",
    "%run /Users/thomasadler/Desktop/futuristic-platipus/notebooks/ta_02_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining working directory\n",
    "filepath = '/Users/thomasadler/Desktop/capstone_docs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dictionary part A\n",
    "Image(\"/Users/thomasadler/Desktop/futuristic-platipus/data_dictionary/4A-Master-Dictionary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dictionary part B\n",
    "Image(\"/Users/thomasadler/Desktop/futuristic-platipus/data_dictionary/4B-Master-Dictionary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a clean dataset, with no duplicate rows/columns, no missing values, all of our columns of interest and all of them in a format fit for analysis. Our outcome (dependent) variable is whether a water point is functioning or not. `is_functioning` is a binary column equal to 1 if that water point was functioning at the time of check, 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#water points\n",
    "master_df_raw=pd.read_csv(filepath + 'master_df.csv')\n",
    "\n",
    "#leaving raw dataset untouched\n",
    "\n",
    "master_df=master_df_raw.copy()\n",
    "\n",
    "#check\n",
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping legacy index column\n",
    "master_df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics\n",
    "round(master_df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through every column, and understand the information it contains and how we can use it in our models. We will use the summary statistic table above for every variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Distribution of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. wpdx_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique water points\n",
    "unique_water=len(set(master_df['wpdx_id']))\n",
    "total_observations=len(master_df['wpdx_id'])\n",
    "\n",
    "print(f\"There are {unique_water} unique water points in the dataset.\")\n",
    "print(f\"There are {total_observations} reports in the dataset.\")\n",
    "print(f\"There are {total_observations-unique_water} water points with more than one report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reports by water point\n",
    "reports_water_pt=master_df[['wpdx_id','clean_adm1' ]].groupby('wpdx_id').count()\n",
    "\n",
    "#visualise\n",
    "sns.histplot(reports_water_pt)\n",
    "\n",
    "plt.title(\"Majority of water points have only been checked once\")\n",
    "\n",
    "plt.xlabel(\"Number of reports\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#percentages\n",
    "round(reports_water_pt.value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. lat_deg & lon_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of all water points\n",
    "unique_water_points=master_df.groupby('wpdx_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualise water points, choose what variable represents the size of the points\n",
    "# fig = px.scatter_geo(\n",
    "#     water_points,\n",
    "#     lon='lon_deg', lat='lat_deg', \n",
    "#     size='served_population', #'crucialness', 'pressure', 'total_fatalities_adm4', 'total_events_adm4 \n",
    "#     height=600,\n",
    "#     width=800,\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. is_functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functioning water points\n",
    "func_distrib=master_df['is_functioning'].value_counts(normalize=True)*100\n",
    "\n",
    "print(\n",
    "    f\"The distribution of water points is {round(func_distrib[0],0).astype('int')}% not functioning and {round(func_distrib[1],0).astype('int')}% functioning.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of regional level\n",
    "regions=['clean_adm2', 'clean_adm3', 'clean_adm4']\n",
    "\n",
    "#visualise through a subplot\n",
    "plt.subplots(2,2, figsize=(30,20))\n",
    "\n",
    "for i, adm in enumerate(regions, 1):\n",
    "    adm_functioning=master_df[[adm,'is_functioning']].groupby(adm).mean()*100\n",
    "    plt.subplot(3,2,i)\n",
    "\n",
    "    sns.histplot(adm_functioning)\n",
    "\n",
    "    plt.xlabel(f\"Proportion of water points functioning in {adm}\", size=25)\n",
    "    plt.ylabel('Count', size=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "\n",
    "    plt.axvline(adm_functioning['is_functioning'].median(), c='gold', label='median')\n",
    "\n",
    "    plt.legend()   \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-8. clean_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of regions\n",
    "for regions in ['clean_adm1', 'clean_adm2', 'clean_adm3', 'clean_adm4']:   \n",
    "    print(f\"There are {len(set(master_df[regions]))} {regions} regions in our Uganda dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of water point reports by region\n",
    "adm1_reports=master_df[['clean_adm1', 'wpdx_id']].groupby('clean_adm1').count()\n",
    "\n",
    "#visualise\n",
    "sns.barplot(data=adm1_reports, y=adm1_reports.index, x=adm1_reports['wpdx_id'], palette=\"flare\")\n",
    "\n",
    "plt.xlabel('number of reports')\n",
    "\n",
    "plt.axvline(adm1_reports['wpdx_id'].mean(), c='royalblue', label='mean')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of regional level\n",
    "regions=['clean_adm2', 'clean_adm3', 'clean_adm4']\n",
    "\n",
    "#visualise through a subplot\n",
    "plt.subplots(2,2, figsize=(30,20))\n",
    "\n",
    "for i, adm in enumerate(regions, 1):\n",
    "    adm_reports=master_df[[adm, 'wpdx_id']].groupby(adm).count()\n",
    "    plt.subplot(3,1,i)\n",
    "\n",
    "    sns.histplot(adm_reports)\n",
    "\n",
    "    \n",
    "    plt.xlabel(f\"Number of reports by {adm}\", size=25)\n",
    "    plt.ylabel('Count', size=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "\n",
    "    plt.axvline(adm_reports['wpdx_id'].median(), c='gold', label='median')  \n",
    "    plt.axvline(adm_reports['wpdx_id'].mean(), c='r', label='mean')   \n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-13. distance_to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise distances for water points\n",
    "distances=['distance_to_primary', 'distance_to_secondary', 'distance_to_tertiary', 'distance_to_city', 'distance_to_town']\n",
    "\n",
    "#creating subplot\n",
    "plt.subplots(3,2, figsize=(30,20))\n",
    "\n",
    "for i, distance in enumerate(distances, 1):\n",
    "    plt.subplot(3,2,i)\n",
    "\n",
    "    sns.histplot(unique_water_points[distance])\n",
    "\n",
    "    plt.xlabel(f\"{distance} for a water point\", size=25)\n",
    "    plt.ylabel('Count', size=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "\n",
    "    plt.axvline(unique_water_points[distance].median(), c='gold', label='median')  \n",
    "    plt.axvline(unique_water_points[distance].mean(), c='r', label='mean')    \n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. usage_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sns.distplot(unique_water_points['usage_cap'])\n",
    "\n",
    "plt.xlabel('usage_cap', size=15)\n",
    "plt.ylabel('Density', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#usage capacity\n",
    "round((unique_water_points['usage_cap'].value_counts(normalize=True)*100).head(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. staleness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sns.distplot(unique_water_points['staleness_score'])\n",
    "\n",
    "plt.xlabel('staleness_score', size=15)\n",
    "plt.ylabel('Density', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlim(10,)\n",
    "\n",
    "plt.axvline(unique_water_points['staleness_score'].mean(), c='r', label='mean')\n",
    "plt.axvline(unique_water_points['staleness_score'].median(), c='gold', label='median') \n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. cluster_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of each cluster size\n",
    "unique_water_points['cluster_size'].value_counts(normalize=True).plot(kind='barh', ylabel='density', xlabel='cluster_size', fontsize=12)\n",
    "\n",
    "#percentage\n",
    "round(unique_water_points['cluster_size'].value_counts(normalize=True)*100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. is_complex_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of water points with complex technology\n",
    "tech_distrib=master_df['is_complex_tech'].value_counts(normalize=True)*100\n",
    "\n",
    "print(\n",
    "    f\"The distribution of water points is {round(tech_distrib[0],0).astype('int')}% not complex technology and {round(tech_distrib[1],0).astype('int')}% complex technology.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. is_installed_after_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of water points installed after the year 2006\n",
    "installed_distrib=master_df['is_installed_after_2006'].value_counts(normalize=True)*100\n",
    "\n",
    "print(\n",
    "    f\"The distribution of water points is {round(installed_distrib[0],0).astype('int')}% installed after 2006 and {round(installed_distrib[1],0).astype('int')}% installed before 2006.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. is_public_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of water points installed after the year 2006\n",
    "public_distrib=master_df['is_public_management'].value_counts(normalize=True)*100\n",
    "\n",
    "print(\n",
    "    f\"The distribution of water points is {round(public_distrib[0],0).astype('int')}% managed by public bodies and {round(public_distrib[1],0).astype('int')}% not managed by public bodies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. served_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise served population\n",
    "sns.histplot(unique_water_points['served_population'],)\n",
    "\n",
    "plt.xlabel('served_population', size=15)\n",
    "plt.ylabel('Count', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlim(0,1000)  \n",
    "plt.ylim(0,10000)\n",
    "\n",
    "plt.axvline(unique_water_points['served_population'].median(), c='gold', label='median')  \n",
    "plt.axvline(unique_water_points['served_population'].mean(), c='r', label='mean')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. local_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise local population\n",
    "sns.histplot(unique_water_points['local_population'])\n",
    "\n",
    "plt.xlabel('local_population', size=15)\n",
    "plt.ylabel('Count', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlim(0,3000)  \n",
    "\n",
    "plt.axvline(unique_water_points['local_population'].median(), c='gold', label='median')  \n",
    "plt.axvline(unique_water_points['local_population'].mean(), c='r', label='mean')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. crucialness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sns.distplot(unique_water_points['crucialness'])\n",
    "\n",
    "plt.xlabel('crucialness', size=15)\n",
    "plt.ylabel('Density', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "\n",
    "plt.axvline(unique_water_points['crucialness'].mean(), c='r', label='mean')\n",
    "plt.axvline(unique_water_points['crucialness'].median(), c='gold', label='median') \n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sns.distplot(unique_water_points['pressure'])\n",
    "\n",
    "plt.xlabel('pressure', size=15)\n",
    "plt.ylabel('Density', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlim(0,10)\n",
    "\n",
    "plt.axvline(unique_water_points['pressure'].mean(), c='r', label='mean')\n",
    "plt.axvline(unique_water_points['pressure'].median(), c='gold', label='median') \n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24-45. Demographics and Regional statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise variables by adm1\n",
    "adm1_df=master_df.groupby(\"clean_adm1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating subplot\n",
    "plt.subplots(22,2, figsize=(20,100))\n",
    "\n",
    "#all variables by adm1 regional level\n",
    "for i, variable in enumerate(adm1_df.columns, 1):\n",
    "    plt.subplot(22,2,i)\n",
    "\n",
    "    sns.barplot(data=adm1_df, y=adm1_df.index, x=adm1_df[variable], palette=\"Blues_d\")\n",
    "\n",
    "    plt.xlabel(f\"average {variable}\", size=16)\n",
    "    plt.ylabel('adm1', size=16)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    plt.axvline(adm1_df[variable].mean(), c='r', label='mean')  \n",
    "    plt.axvline(adm1_df[variable].median(), c='gold', label='median')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. total_fatalities_adm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset of fatalities by region\n",
    "fatalities_adm=master_df[['clean_adm1', 'clean_adm2','clean_adm3', 'clean_adm4', 'total_fatalities_adm4']]\\\n",
    "    .groupby(['clean_adm1', 'clean_adm2','clean_adm3', 'clean_adm4']).mean()\n",
    "\n",
    "fatalities_adm.reset_index(inplace=True)\n",
    "\n",
    "#check\n",
    "fatalities_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of regional level\n",
    "regions=['clean_adm2', 'clean_adm3']\n",
    "\n",
    "#visualise through a subplot\n",
    "plt.subplots(1,2, figsize=(40,10))\n",
    "\n",
    "for i, adm in enumerate(regions, 1):\n",
    "    adm_fatalities=fatalities_adm[[adm,'total_fatalities_adm4']].groupby(adm).sum()\n",
    "    plt.subplot(1,2,i)\n",
    "\n",
    "    sns.histplot(adm_fatalities, binrange=(0,200), bins=10)\n",
    "\n",
    "    plt.xlabel(f\"Number of fatalities in each {adm}\", size=30)\n",
    "    plt.ylabel('Count', size=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.ylim(0,)\n",
    "    plt.xlim(0,300)\n",
    "\n",
    "    plt.axvline(adm_fatalities['total_fatalities_adm4'].median(), c='gold', label='median')\n",
    "    plt.axvline(adm_fatalities['total_fatalities_adm4'].mean(), c='r', label='mean')\n",
    "\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fatalities by adm4\n",
    "adm4_fatalities=fatalities_adm[['clean_adm4','total_fatalities_adm4']].groupby('clean_adm4').mean()\n",
    "\n",
    "sns.histplot(adm4_fatalities, binrange=(0,10), bins=10)\n",
    "plt.xlabel(f\"Number of fatalities in each adm4\", size=10)\n",
    "plt.ylabel('Count', size=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "plt.axvline(adm4_fatalities['total_fatalities_adm4'].median(), c='gold', label='median')\n",
    "plt.axvline(adm4_fatalities['total_fatalities_adm4'].mean(), c='r', label='mean')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. total_events_adm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset of event by region\n",
    "events_adm=master_df[['clean_adm1', 'clean_adm2','clean_adm3', 'clean_adm4', 'total_events_adm4']]\\\n",
    "    .groupby(['clean_adm1', 'clean_adm2','clean_adm3', 'clean_adm4']).mean()\n",
    "\n",
    "events_adm.reset_index(inplace=True)\n",
    "\n",
    "#check\n",
    "events_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of regional level\n",
    "regions=['clean_adm2', 'clean_adm3']\n",
    "\n",
    "#visualise through a subplot\n",
    "plt.subplots(1,2, figsize=(40,10))\n",
    "\n",
    "for i, adm in enumerate(regions, 1):\n",
    "    adm_events=events_adm[[adm,'total_events_adm4']].groupby(adm).sum()\n",
    "    plt.subplot(1,2,i)\n",
    "\n",
    "    sns.histplot(adm_events, binrange=(0,200), bins=10)\n",
    "\n",
    "    plt.xlabel(f\"Number of fatalities in each {adm}\", size=30)\n",
    "    plt.ylabel('Count', size=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.ylim(0,)\n",
    "    plt.xlim(0,300)\n",
    "\n",
    "    plt.axvline(adm_events['total_events_adm4'].median(), c='gold', label='median')\n",
    "    plt.axvline(adm_events['total_events_adm4'].mean(), c='r', label='mean')\n",
    "\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fatalities by adm4\n",
    "adm4_events=events_adm[['clean_adm4','total_events_adm4']].groupby('clean_adm4').mean()\n",
    "\n",
    "sns.histplot(adm4_events, binrange=(0,10), bins=10)\n",
    "plt.xlabel(f\"Number of fatalities in each adm4\", size=10)\n",
    "plt.ylabel('Count', size=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "plt.axvline(adm4_events['total_events_adm4'].median(), c='gold', label='median')\n",
    "plt.axvline(adm4_events['total_events_adm4'].mean(), c='r', label='mean')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. perc_local_served"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sns.distplot(unique_water_points['perc_local_served'])\n",
    "\n",
    "plt.xlabel('perc_local_served', size=15)\n",
    "plt.ylabel('Density', size=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlim()\n",
    "\n",
    "plt.axvline(unique_water_points['perc_local_served'].mean(), c='r', label='mean')\n",
    "plt.axvline(unique_water_points['perc_local_served'].median(), c='gold', label='median') \n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "\n",
    "#Creating matrix of correlations between each pair of variables\n",
    "matrix = np.triu(master_df.corr())\n",
    "\n",
    "#Applying heatmap correlations\n",
    "sns.heatmap(master_df.corr(), annot=True, mask=matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation coefficients of each pair of variable', size=60)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xticks(fontsize=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap above is not easy to understand due to the number of columns. By zooming in we can identify a few trends:\n",
    "\n",
    "- number of fatalities and number of events is heavily correlated which makes sense as the more conflicts the higher the chance of people getting hurt.\n",
    "- crucialness and percentage of local population served also. They try to measure the same thing but in a slightly different way.\n",
    "- the percentage of illiterate people is correlared with primary and secondary enrollment. People going to school will be able to read and write.\n",
    "- more broadly, primary and secondary enrollment is heavily correlated with many other demographic variables\n",
    "- mobile phone ownership, TV ownership, electricity access, bank account ownership are all similarly correlated with other demographic variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see only highly positively correlated variables\n",
    "plt.figure(figsize=(80,80))\n",
    "\n",
    "#Applying heatmap correlations\n",
    "sns.heatmap(master_df.corr()>=0.7, annot=True, mask=matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation coefficients of each pair of variable', size=60)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xticks(fontsize=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at variables which have a correlation coefficient higher than 0.7.\n",
    "\n",
    "- we do not drop `perc_local_served` yet although it is very similar to what `crucialness`. It is also closely related to `pressure` as it is trying to measure the same thing. We will see later how to deal with those.\n",
    "\n",
    "- we drop mobile phone and TV ownership in favor of electricity access and secondary enrollment as we can represent the two former with the two latter. In addition, we believe that electricity is a better overall indicator of the development and wealth of a household and region. Secondary enrollment gives us a good representation of the education system in the region.\n",
    "\n",
    "- we drop the illiteracy rate and an indicator for households eating enough (less than 2 meals a day or not) in favour of access to toilet. The reason is that we already have school enrollment which should tell us already about the education situation of the region. In addition, toilet access also seems a strong candidate for a development indicator.\n",
    "\n",
    "- we keep both events and fatalities. It makes sense they are highly correlated but will wait for further to analyse to choose which one to discard.\n",
    "\n",
    "- it seems that households at a certain latitude live more often in temporary dwellings we also refrain from dropping it just yet as we might not be using latitude in most models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns from multicolinearity analysis\n",
    "master_df_clean=master_df.drop(columns=['perc_hh_own_tv', 'perc_pop10p_mobile_phone', 'perc_pop18p_illiterate', 'perc_hh_less2meals'])\n",
    "\n",
    "#check\n",
    "master_df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "\n",
    "#Creating matrix of correlations between each pair of variables\n",
    "matrix = np.triu(master_df_clean.corr())\n",
    "\n",
    "#Applying heatmap correlations\n",
    "sns.heatmap(master_df_clean.corr()<=-0.7, annot=True, mask=matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation coefficients of each pair of variable', size=60)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xticks(fontsize=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the variables which have a correlation coefficient larger than -0.8.\n",
    "- we drop primary enrollment in favour of toilet access. We already have secondary enrollemnt to represent education level of a region.\n",
    "- we drop subsistence farming in favour of electricity as we assume the latter is a better indicator for development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns from multicolinearity analysis\n",
    "master_df_clean=master_df_clean.drop(columns=['perc_pop612_primary', 'perc_hh_subs_farm'])\n",
    "\n",
    "#check\n",
    "master_df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Linearity with outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose numeric columns\n",
    "master_numeric=master_df_clean.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the correlation coefficient between explanatory and outcome variable\n",
    "correl_loop(master_numeric, master_numeric['is_functioning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our correlation coefficients tell us that toilet access, secondary enrollment, bank account ownership and the fact that the water point was installed after 2006 is strongly correlated (larger than 0.5) with the functioning of a water point.\n",
    "\n",
    "On the other hand, the percentage of households headed by a male in a region, cluster size, proportion of population in employment and fatalities in a region are not correlated with our outcome and may be dropped later down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above loops over all variables in X and computes its correlation with y.\n",
    " \n",
    "The hypotheses is:\n",
    "\n",
    "$ 𝐻_0 $ : The variable X and y are not related (correlated), they are independent.\n",
    "\n",
    "$ 𝐻_1 $ : X and y are related and not independent.\n",
    "\n",
    "The output includes:\n",
    "\n",
    "**Pearson correlation coefficient (PCC)**\n",
    "\n",
    "\n",
    "* ex: If the PCC is 0.5 between x and y, that means that an increase of one unit in x is associated with an increase of 0.5 units for y.\n",
    " \n",
    " \n",
    "**P-value**\n",
    "\n",
    "\n",
    "* Represents the probability that we see our dataset, assuming $H_0$ is true.\n",
    "     \n",
    "\n",
    "\n",
    "**Positive or negative correlation between the two variables**\n",
    "\n",
    "\n",
    "* $ -1 < PCC < -0.5 $ strong negative correlation\n",
    "* $ -0.5 < PCC < 0 $ weak negative correlation\n",
    "* $ 0 < PCC < 0.5 $ weak positive correlation\n",
    "* $ 0.5 < PCC < 1 $ strong positive correlation\n",
    "\n",
    "\n",
    "**Statistical significance of the PCC**\n",
    "\n",
    "* If the $ p-value < 0.05 $  (5% significance level), then we can reject $ H_0 $. This means that the value we are testing for (PCC in this case) is statistically significant (**SS**) or not (**NSS**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising linear relationship between all variables and our outcome variable\n",
    "box_loop(master_numeric, master_numeric['is_functioning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plots do not tell us much more than the correlation coefficients from above apart from the fact that it sems that the majority of non-functioning water points are managed by a public entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowint the variance of variables tells us whether they will be useful in our model later on. If variance is low then it won't have any variation to help us understand our outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance of numeric columns\n",
    "master_numeric.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale our data as all columns have different scales and measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "min_max = MinMaxScaler()\n",
    "scaled_data = min_max.fit_transform(master_numeric)\n",
    "\n",
    "#make a dataframe\n",
    "master_numeric_scaled = pd.DataFrame(data=scaled_data, columns=master_numeric.columns)\n",
    "\n",
    "#check variance of scaled numeric columns\n",
    "master_numeric_scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate  VarianceThreshold and set threshold for the variance\n",
    "vt = VarianceThreshold(threshold=0.0005)\n",
    "\n",
    "# Fit the data and calculate the variances per column\n",
    "vt.fit(master_numeric_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variances per column\n",
    "column_variances = vt.variances_\n",
    "\n",
    "# Plot including the threshold\n",
    "plt.figure(figsize=(60,60))\n",
    "plt.barh(np.flip(master_numeric_scaled.columns), np.flip(column_variances))\n",
    "plt.xlabel('Variance', size=40)\n",
    "plt.ylabel('Feature', size=40)\n",
    "plt.axvline(0.0005, color='red', linestyle='--')\n",
    "plt.xticks(size=40)\n",
    "plt.yticks(size=40)\n",
    "plt.xlim(0,0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our outcome variable (`is_functioning`) has high variance, which is a very good sign.\n",
    "\n",
    "The technology of the water point, the installation year and the management entity of the water point have especially high variances.\n",
    "\n",
    "On the other hand, cluster size, served population, local population, fatalities and pressure all have low variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the analysis on correlation and variances we choose to drop:\n",
    "\n",
    "- `cluster_size` due to its low variance and weak correlation with the outcome variable\n",
    "\n",
    "- `served_population`, `local_population` and `pressure` as they have low variances and are captured by `perc_local_served` created by ourselves.\n",
    "\n",
    "- `total_fatalities_adm4` because of its variance, low correlation and multicollinearity with `total_events_adm4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop columns\n",
    "master_df_clean=master_df_clean.drop(columns=['cluster_size', 'served_population', 'local_population', 'pressure', 'total_fatalities_adm4'])\n",
    "\n",
    "# #check\n",
    "master_df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get rid of columns which we feel represent redundant information access to piped water and borehole is very similar to what we are trying to predict. We are wary this might introduce bias in our estimators and we decide to discard these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop columns\n",
    "master_df_clean=master_df_clean.drop(columns=['perc_hh_piped_water', 'perc_hh_borehole'])\n",
    "\n",
    "# #check\n",
    "master_df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have dropped a few columns which were not correlated with our outcome variable, had low variances or had high multicollienarity metrics with other explanatory variables. Our dataset is now ready to be used in models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export new dataset\n",
    "master_df_clean.to_csv(filepath + 'master_modelling_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dictionary\n",
    "Image(\"/Users/thomasadler/Desktop/futuristic-platipus/data_dictionary/5-Modelling-Data-Dictionary.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6ceada7ab5ee6fcd72b8e8137f72bc53b2192058ef32f401c30586b94eefb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
