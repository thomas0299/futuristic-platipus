,Model,Parameters,Accuracy Train,Precision Train,Recall Train,F1 Train,ROC AUC Train,Accuracy Test,Precision Test,Recall Test,F1 Test,ROC AUC Test,Time Fit,Time Predict,Precision Non-functioning Test,Recall Non-functioning Test,F1 Non-functioning Test,Precision Functioning Test,Recall Functioning Test,F1 Functioning Test,Functioning Test
0,XGBoost,"Max depth=6, Gamma=0, Learning rate=0.3, Number of trees=50",0.841840136843326,0.8424943681482912,0.841840136843326,0.841764571680517,0.9243921709239664,0.7715165368288474,0.8130216167098016,0.7715165368288474,0.7860533690377162,0.8087662003643492,19.921146869659424,0.0384387969970703,0.45,0.65,0.53,0.9,0.8,0.85,
1,WPDx,Unknown,,,,,,,[0.80834636 0.80834439 0.8083527  ... 1.         1.         1.        ],"[1.00000000e+00 9.99987281e-01 9.99987281e-01 ... 5.34194828e-04
 5.21475904e-04 0.00000000e+00]",,0.7889022407467154,,,0.54,0.4,0.46,0.87,0.92,0.89,
2,K Nearest Neighbors,"Neighbors=4, Standard Scaler",0.8704615681730398,0.8844881366151469,0.8704615681730398,0.8692692663774718,0.9672137224763652,0.6781215985072306,0.781206448869335,0.6781215985072306,0.7091558938987095,0.7203815541819794,0.0343170166015625,0.1661679744720459,0.33,0.65,0.44,0.89,0.69,0.77,
3,Gaussian Naive Bayes,,0.6120332250956744,0.6144463542345676,0.6120332250956744,0.6099772942572644,0.6588822704010048,0.6423473433782713,0.7270088275254178,0.6423473433782713,0.6730178833662219,0.6154788215939245,0.1403930187225341,0.0281958580017089,0.27,0.47,0.34,0.84,0.69,0.75,
4,Neural Network,"Hidden layer=16 nodes, Optimizer=Adam, Loss function=BinaryCrossentropy, Metric=BinaryAccuracy",,,,,0.8586117697927094,,,,,0.7886899395085116,323.8172631263733,0.7877979278564453,0.42,0.63,0.5,0.9,0.78,,0.84
5,Linear SVC,"Penalty=l2, C=0.001, Standard Scaler",0.6521004870694653,0.6521204877111727,0.6521004870694653,0.6520890513280753,0.7104575976682433,0.6311983952978495,0.7410502675794186,0.6311983952978495,0.6665115831812228,0.6407327354641204,1.1706831455230713,0.0194652080535888,0.28,0.55,0.37,0.85,0.65,0.74,
6,Decision Tree,"Max depth=24, Min samples leaf=25, Criterion=entropy",0.8405862228922649,0.8408255477326503,0.8405862228922649,0.8405582332245022,0.9296680559908854,0.7510379250828008,0.7989108044399157,0.7510379250828008,0.7679148066019738,0.774381929527438,3.7895872592926025,0.015336275100708,0.41,0.62,0.49,0.89,0.78,0.83,
7,Random Forest,"Max depth=31, Min samples leaf=11, Criterion=entropy, Number trees=100",0.8970993273802621,0.8973319057743673,0.8970993273802621,0.8970842669386162,0.9664984154752732,0.7928814666231282,0.8173368432375799,0.7928814666231282,0.8023244234587595,0.8232286784236897,52.53847980499268,0.5154941082000732,0.48,0.62,0.54,0.9,0.83,0.87,
8,AdaBoost,"Learning rate=1, Number of trees=50",0.7048953380494027,0.7063073347026261,0.7048953380494027,0.7043895380695994,0.7774688074133068,0.6574613985165835,0.7698385932407658,0.6574613985165835,0.6907275832974198,0.7087672475822341,33.51238799095154,0.3009030818939209,0.32,0.64,0.42,0.88,0.66,0.76,
9,Logistic Regression,"Penalty=l2, C=0.1, Standard Scaler",0.6514191696625304,0.6514191696943492,0.6514191696625304,0.651419169644218,0.7104670681383911,0.6268134533750058,0.741167288606714,0.6268134533750058,0.662987940031414,0.6401272756416185,0.3979749679565429,0.0018579959869384,0.65,0.65,0.65,0.65,0.65,0.65,
