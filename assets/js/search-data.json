{
  
    
        "post0": {
            "title": "Initial EDA (ARCHIVED)",
            "content": "NOTEBOOK ARCHIVED . This notebook takes a long time to run and uses considerable memory and computation power. It is recommended to run individual cells if needed. This notebook has been archived as this was an initial, exploratory analysis of our datasets. . Initial EDA - exploring conflicts and water points . %run /Users/thomasadler/Desktop/futuristic-platipus/notebooks/0-ta-packages.py . OSError Traceback (most recent call last) File ~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py:696, in ExecutionMagics.run(self, parameter_s, runner, file_finder) 695 fpath = arg_lst[0] --&gt; 696 filename = file_finder(fpath) 697 except IndexError as e: File ~/opt/anaconda3/lib/python3.9/site-packages/IPython/utils/path.py:91, in get_py_filename(name) 90 else: &gt; 91 raise IOError(&#39;File `%r` not found.&#39; % name) OSError: File `&#39;/Users/thomasadler/Desktop/futuristic-platipus/notebooks/0-ta-packages.py&#39;` not found. The above exception was the direct cause of the following exception: Exception Traceback (most recent call last) /Users/thomasadler/Desktop/futuristic-platipus/notebooks/ARCHIVED_ta_conflict_water_eda.ipynb Cell 3 in &lt;cell line: 2&gt;() &lt;a href=&#39;vscode-notebook-cell:/Users/thomasadler/Desktop/futuristic-platipus/notebooks/ARCHIVED_ta_conflict_water_eda.ipynb#ch0000002?line=0&#39;&gt;1&lt;/a&gt; #importing relevant packages -&gt; &lt;a href=&#39;vscode-notebook-cell:/Users/thomasadler/Desktop/futuristic-platipus/notebooks/ARCHIVED_ta_conflict_water_eda.ipynb#ch0000002?line=1&#39;&gt;2&lt;/a&gt; get_ipython().run_line_magic(&#39;run&#39;, &#39;/Users/thomasadler/Desktop/futuristic-platipus/notebooks/0-ta-packages.py&#39;) File ~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2294, in InteractiveShell.run_line_magic(self, magic_name, line, _stack_depth) 2292 kwargs[&#39;local_ns&#39;] = self.get_local_scope(stack_depth) 2293 with self.builtin_trap: -&gt; 2294 result = fn(*args, **kwargs) 2295 return result File ~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py:707, in ExecutionMagics.run(self, parameter_s, runner, file_finder) 705 if os.name == &#39;nt&#39; and re.match(r&#34;^&#39;.*&#39;$&#34;,fpath): 706 warn(&#39;For Windows, use double quotes to wrap a filename: %run &#34;mypath myfile.py&#34;&#39;) --&gt; 707 raise Exception(msg) from e 708 except TypeError: 709 if fpath in sys.meta_path: Exception: File `&#39;/Users/thomasadler/Desktop/futuristic-platipus/notebooks/0-ta-packages.py&#39;` not found. . filepath = &#39;/Users/thomasadler/Desktop/capstone_docs/&#39; . Visualising conflicts . conflict_df=pd.read_csv(filepath+&#39;uganda_conflict_df_clean.csv&#39;) . conflict_df[&#39;event_date&#39;]=pd.to_datetime(conflict_df[&#39;event_date&#39;]) #then to date conflict_df[&#39;event_date&#39;]=conflict_df[&#39;event_date&#39;].dt.date #back to datetime conflict_df[&#39;event_date&#39;]=pd.to_datetime(conflict_df[&#39;event_date&#39;]) . working_conflict_df=conflict_df[[&#39;event_date&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4&#39;,&#39;latitude&#39;,&#39;longitude&#39; ,&#39;fatalities&#39;]] . working_conflict_df.head() . working_conflict_df.info() . Conflicts over time in uganda . fatalities_date=working_conflict_df.groupby(&#39;event_date&#39;).sum() . events_date=working_conflict_df.groupby(&#39;event_date&#39;).count() . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=fatalities_date.index, y=fatalities_date[&#39;fatalities&#39;], name=&quot;Number of fatalities&quot;), secondary_y=False, ) fig.add_trace( go.Scatter(x=events_date.index, y=events_date[&#39;fatalities&#39;], name=&quot;Number of events&quot;), secondary_y=True, ) fig.update_yaxes(title_text=&quot;Number of fatalities&quot;, secondary_y=False) fig.update_yaxes(title_text=&quot;Number of events&quot;, secondary_y=True) fig.update_layout(title=&quot;Uganda Events and Fatalities&quot;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.show() . Conflicts in regions . fatalities_date_adm1=working_conflict_df[[&#39;clean_adm1&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm1&#39;).sum().sort_values(&#39;fatalities&#39;, ascending=False).head(10) fatalities_date_adm2=working_conflict_df[[&#39;clean_adm2&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm2&#39;).sum().sort_values(&#39;fatalities&#39;, ascending=False).head(10) fatalities_date_adm3=working_conflict_df[[&#39;clean_adm3&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm3&#39;).sum().sort_values(&#39;fatalities&#39;, ascending=False).head(10) . events_date_adm1=working_conflict_df[[&#39;clean_adm1&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm1&#39;).count().sort_values(&#39;fatalities&#39;, ascending=False).head(10) events_date_adm2=working_conflict_df[[&#39;clean_adm2&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm2&#39;).count().sort_values(&#39;fatalities&#39;, ascending=False).head(10) events_date_adm3=working_conflict_df[[&#39;clean_adm3&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm3&#39;).count().sort_values(&#39;fatalities&#39;, ascending=False).head(10) . fig = px.bar(fatalities_date_adm1, x=fatalities_date_adm1.index, y=&quot;fatalities&quot;, title=&quot;Adm1-Number of fatalities&quot;) fig.show() . fig = px.bar(fatalities_date_adm2, x=fatalities_date_adm2.index, y=&quot;fatalities&quot;, title=&quot;Adm2-Number of fatalities&quot;) fig.show() . fig = px.bar(fatalities_date_adm3, x=fatalities_date_adm3.index, y=&quot;fatalities&quot;, title=&quot;Adm3-Number of fatalities&quot;) fig.show() . fig = px.bar(events_date_adm1, x=events_date_adm1.index, y=&quot;fatalities&quot;, title=&quot;Adm1-Number of events&quot;) fig.show() . fig = px.bar(events_date_adm2, x=events_date_adm2.index, y=&quot;fatalities&quot;, title=&quot;Adm2-Number of events&quot;) fig.show() . fig = px.bar(events_date_adm3, x=events_date_adm3.index, y=&quot;fatalities&quot;,title=&quot;Adm3-Number of events&quot;) fig.show() . Conflicts over time per region . working_conflict_df[&#39;event_year&#39;]=pd.DatetimeIndex(working_conflict_df[&#39;event_date&#39;]).year working_conflict_df.info() . fig = px.scatter_geo( working_conflict_df, lon=&#39;longitude&#39;, lat=&#39;latitude&#39;, size=&#39;fatalities&#39;, height=600, width=800, animation_frame=&#39;event_year&#39; ) fig.show() . Visualising water points . water_df=pd.read_csv(filepath+&#39;uganda_water_df_clean.csv&#39;) . water_df[&#39;install_year&#39;]=pd.to_datetime(water_df[ &#39;install_year&#39;]) water_df[&#39;report_date&#39;]=pd.to_datetime(water_df[ &#39;report_date&#39;]) #then to year water_df[&#39;install_year&#39;]=water_df[ &#39;install_year&#39;].dt.year #water_df[&#39;install_year&#39;]=water_df[&#39;install_year&#39;].astype(&#39;float32&#39;) #then to year #water_df[[&#39;report_year&#39;, &#39;install_year&#39;]]=water_df[[&#39;report_date&#39;, &#39;install_year&#39;]].dt.year #back to datetime #water_df[[&#39;report_date&#39;, &#39;install_year&#39;]]=pd.to_datetime(water_df[[&#39;report_date&#39;, &#39;install_year&#39;]] #also for report date) . water_df.info() . water_df[&#39;staleness_score&#39;].value_counts() . water_df[&#39;management_clean&#39;].value_counts() . water_df.columns . unique_water_df=water_df[[&#39;wpdx_id&#39;,&#39;lat_deg&#39;,&#39;lon_deg&#39;, &#39;install_year&#39;, &#39;usage_cap&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;served_population&#39;]].groupby(&#39;wpdx_id&#39;).mean() . unique_water_df.head() . working_water_df=water_df[[&#39;wpdx_id&#39;,&#39;lat_deg&#39;,&#39;lon_deg&#39;,&#39;report_date&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;install_year&#39;, &#39;usage_cap&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;served_population&#39;, &#39;status_id&#39;]] . Water points in Uganda . water_location=unique_water_df.merge(working_water_df, left_on=unique_water_df.index, right_on=working_water_df[&#39;wpdx_id&#39;], how=&#39;left&#39;) . wp_adm1=water_location[[&#39;clean_adm1&#39;, &#39;key_0&#39;]].groupby(&#39;clean_adm1&#39;).count().sort_values(&#39;key_0&#39;, ascending=False).head(10) wp_adm2=water_location[[&#39;clean_adm2&#39;, &#39;key_0&#39;]].groupby(&#39;clean_adm2&#39;).count().sort_values(&#39;key_0&#39;, ascending=False).head(10) wp_adm3=water_location[[&#39;clean_adm3&#39;, &#39;key_0&#39;]].groupby(&#39;clean_adm3&#39;).count().sort_values(&#39;key_0&#39;, ascending=False).head(10) . fig = px.bar(wp_adm1, x=wp_adm1.index, y=&quot;key_0&quot;,title=&quot;Adm1-Number of water points&quot;) fig.show() . fig = px.bar(wp_adm2, x=wp_adm2.index, y=&quot;key_0&quot;,title=&quot;Adm2-Number of water points&quot;) fig.show() . fig = px.bar(wp_adm3, x=wp_adm3.index, y=&quot;key_0&quot;,title=&quot;Adm3-Number of water points&quot;) fig.show() . Constructions over time . fig = px.histogram(unique_water_df, x=&quot;install_year&quot;, title=&#39;Water point installations&#39;) fig.show() . 3 region comparison . Violent region Agago . agago_water_df=working_water_df[working_water_df[&#39;clean_adm3&#39;]==&#39;Agago&#39;] . agago_water_df[&#39;wpdx_id&#39;].value_counts() . unique_water_agago_df=agago_water_df.groupby(&#39;wpdx_id&#39;).mean() fig = px.histogram(unique_water_agago_df, x=&quot;install_year&quot;, title=&#39;Agago water point installations&#39;) fig.show() . onewaterpoint=agago_water_df[[&#39;wpdx_id&#39;, &#39;report_date&#39;,&#39;install_year&#39;,&#39;usage_cap&#39;]][agago_water_df[&#39;wpdx_id&#39;]==&#39;6GJMWFRF+329&#39;] onewaterpoint.head() . first_day = onewaterpoint[&#39;report_date&#39;].min() onewaterpoint[&#39;install_year_dt&#39;]=pd.to_datetime(onewaterpoint[&#39;install_year&#39;].astype(&#39;float32&#39;), format=&#39;%Y&#39;) installed_year=onewaterpoint[&#39;install_year_dt&#39;].mean() last_day=datetime(2022, 6, 30) . if first_day&gt;installed_year: first_day=installed_year else: first_day=first_day . print(first_day, installed_year, last_day) . onewaterpoint=onewaterpoint.groupby([&#39;report_date&#39;, &#39;wpdx_id&#39;]).mean() onewaterpoint.reset_index(level=1,inplace=True) onewaterpoint . point_df=onewaterpoint.reindex(pd.date_range(start=first_day, end=last_day, freq=&quot;d&quot;)) point_df.info() . point_df = point_df.fillna(method=&#39;ffill&#39;) point_df.info() . point_df = point_df.fillna(0) point_df.info() . fig = px.line(point_df, x=point_df.index, y=point_df[&#39;usage_cap&#39;], title=&#39;Water point installations&#39;) fig.show() . master = pd.DataFrame() master=pd.concat([master, point_df]) master.tail() final_timeseries=master[&#39;usage_cap&#39;].groupby(level=0).mean() final_timeseries . fig = px.line(final_timeseries, x=final_timeseries.index, y=final_timeseries.values, title=&#39;Water point quality&#39;) fig.show() . def ts_quality(df): master_df = pd.DataFrame() unique_points = df[&#39;wpdx_id&#39;].unique() for id in unique_points: onewaterpoint=df[[&#39;wpdx_id&#39;, &#39;report_date&#39;,&#39;install_year&#39;,&#39;usage_cap&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;served_population&#39;,&#39;functioning&#39;]][df[&#39;wpdx_id&#39;]==id] first_day = onewaterpoint[&#39;report_date&#39;].min() onewaterpoint[&#39;install_year_dt&#39;] = pd.to_datetime( onewaterpoint[&#39;install_year&#39;].astype(&#39;float32&#39;), format=&#39;%Y&#39;) installed_year = onewaterpoint[&#39;install_year_dt&#39;].mean() last_day = datetime(2022, 6, 30) first_day = onewaterpoint[&#39;report_date&#39;].min() onewaterpoint[&#39;install_year_dt&#39;] = pd.to_datetime( onewaterpoint[&#39;install_year&#39;].astype(&#39;float32&#39;), format=&#39;%Y&#39;) installed_year = onewaterpoint[&#39;install_year_dt&#39;].mean() last_day = datetime(2022, 6, 30) if pd.isnull(first_day) == True: first_day = datetime(2022, 6, 29) elif first_day &gt; installed_year: first_day = installed_year else: first_day = first_day onewaterpoint = onewaterpoint.groupby([&#39;report_date&#39;, &#39;wpdx_id&#39;]).mean() onewaterpoint.reset_index(level=1, inplace=True) onewaterpoint point_df = onewaterpoint.reindex( pd.date_range(start=first_day, end=last_day, freq=&quot;d&quot;)) point_df = point_df.fillna(method=&#39;ffill&#39;) point_df = point_df.fillna(0) master_df = pd.concat([master_df, point_df]) final_timeseries=master_df[[&#39;usage_cap&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;served_population&#39;, &#39;functioning&#39;]].groupby(level=0).sum() return final_timeseries . agago_water_df[&#39;functioning&#39;]=agago_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) . agago_water_ts=ts_quality(agago_water_df) . agago_water_ts.tail() . fig = px.line(agago_water_ts, x=agago_water_ts.index, y=agago_water_ts[&#39;served_population&#39;], title=&#39;Water point usage capacity Agago&#39;) fig.show() . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=agago_water_ts.index, y=agago_water_ts[&#39;usage_cap&#39;], name=&quot;Usage capacity&quot;), secondary_y=False, ) fig.add_trace( go.Scatter(x=agago_water_ts.index, y=agago_water_ts[&#39;served_population&#39;], name=&quot;Served population&quot;), secondary_y=True, ) fig.update_yaxes(title_text=&quot;Usage capacity&quot;, secondary_y=False) fig.update_yaxes(title_text=&quot;Served population&quot;, secondary_y=True) fig.update_layout(title=&quot;Agago water quality&quot;) fig.update_xaxes(rangeslider_visible=True) fig.show() . lira_water_df=working_water_df[working_water_df[&#39;clean_adm2&#39;]==&#39;Lira&#39;] . lira_water_df[&#39;functioning&#39;]=lira_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) . lira_water_ts=ts_quality(lira_water_df) . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=lira_water_ts.index, y=lira_water_ts[&#39;usage_cap&#39;], name=&quot;Usage capacity&quot;), secondary_y=False, ) fig.add_trace( go.Scatter(x=lira_water_ts.index, y=lira_water_ts[&#39;served_population&#39;], name=&quot;Served population&quot;), secondary_y=True, ) fig.update_yaxes(title_text=&quot;Usage capacity&quot;, secondary_y=False) fig.update_yaxes(title_text=&quot;Served population&quot;, secondary_y=True) fig.update_layout(title=&quot;Lira water quality&quot;) fig.update_xaxes(rangeslider_visible=True) fig.show() . kamwenge_water_df=working_water_df[working_water_df[&#39;clean_adm2&#39;]==&#39;Kamwenge&#39;] . kamwenge_water_df[&#39;functioning&#39;]=kamwenge_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) . kamwenge_water_ts=ts_quality(kamwenge_water_df) . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=kamwenge_water_ts.index, y=kamwenge_water_ts[&#39;usage_cap&#39;], name=&quot;Usage capacity&quot;), secondary_y=False, ) fig.add_trace( go.Scatter(x=kamwenge_water_ts.index, y=kamwenge_water_ts[&#39;served_population&#39;], name=&quot;Served population&quot;), secondary_y=True, ) fig.update_yaxes(title_text=&quot;Usage capacity&quot;, secondary_y=False) fig.update_yaxes(title_text=&quot;Served population&quot;, secondary_y=True) fig.update_layout(title=&quot;Central water quality&quot;) fig.update_xaxes(rangeslider_visible=True) fig.show() . kitgum_water_df=working_water_df[working_water_df[&#39;clean_adm2&#39;]==&#39;Kitgum&#39;] . kitgum_water_df[&#39;functioning&#39;]=kitgum_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) . kitgum_water_ts=ts_quality(kitgum_water_df) . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=kitgum_water_ts.index, y=kitgum_water_ts[&#39;usage_cap&#39;], name=&quot;Usage capacity&quot;), secondary_y=False, ) fig.add_trace( go.Scatter(x=kitgum_water_ts.index, y=kitgum_water_ts[&#39;served_population&#39;], name=&quot;Served population&quot;), secondary_y=True, ) fig.update_yaxes(title_text=&quot;Usage capacity&quot;, secondary_y=False) fig.update_yaxes(title_text=&quot;Served population&quot;, secondary_y=True) fig.update_layout(title=&quot;Kitgum water quality&quot;) fig.update_xaxes(rangeslider_visible=True) fig.show() . Overlay conflicts and water . agago_water_ts=agago_water_ts.copy() lira_water_ts=lira_water_ts.copy() kamwenge_water_ts=kamwenge_water_ts.copy() . kitgum_water_ts=kitgum_water_ts.copy() . agago_conflict_ts=working_conflict_df[working_conflict_df[&#39;clean_adm3&#39;]==&#39;Agago&#39;] lira_conflict_ts=working_conflict_df[working_conflict_df[&#39;clean_adm3&#39;]==&#39;Lira&#39;] kamwenge_conflict_ts=working_conflict_df[working_conflict_df[&#39;clean_adm3&#39;]==&#39;Kamwenge&#39;] kitgum_conflict_ts=working_conflict_df[working_conflict_df[&#39;clean_adm2&#39;]==&#39;Kitgum&#39;] . def time_series(df1, df2, variable1, variable2, region): if variable2==&#39;fatalities&#39;: conflict_date=df2.groupby(&#39;event_date&#39;).sum() else: conflict_date=df2.groupby(&#39;event_date&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=df1.index, y=df1[variable1], name=variable1), secondary_y=False, ) fig.add_trace( go.Scatter(x=conflict_date.index, y=conflict_date[&#39;fatalities&#39;], name=variable2), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=variable1, secondary_y=False) fig.update_yaxes(title_text=variable2, secondary_y=True) fig.update_layout(title=region) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . time_series(agago_water_ts, agago_conflict_ts, &#39;usage_cap&#39;, &#39;fatalities&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;usage_cap&#39;, &#39;fatalities&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;usage_cap&#39;, &#39;fatalities&#39;, &#39;Kamwenge&#39;) time_series(kitgum_water_ts, kitgum_conflict_ts, &#39;usage_cap&#39;, &#39;fatalities&#39;, &#39;Kitgum&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;usage_cap&#39;, &#39;events&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;usage_cap&#39;, &#39;events&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;usage_cap&#39;, &#39;events&#39;, &#39;Kamwenge&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;served_population&#39;, &#39;fatalities&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;served_population&#39;, &#39;fatalities&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;served_population&#39;, &#39;fatalities&#39;, &#39;Kamwenge&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;served_population&#39;, &#39;events&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;served_population&#39;, &#39;events&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;served_population&#39;, &#39;events&#39;, &#39;Kamwenge&#39;) . time_series(kitgum_water_ts, kitgum_conflict_ts, &#39;served_population&#39;, &#39;events&#39;, &#39;Kitgum&#39;) . water_datsets=[agago_water_ts, lira_water_ts, kamwenge_water_ts] for df in water_datsets: df[&#39;opposite_crucialness&#39;]=100-df[&#39;crucialness&#39;] df[&#39;opposite_pressure&#39;]=100-df[&#39;pressure&#39;] . time_series(agago_water_ts, agago_conflict_ts, &#39;opposite_crucialness&#39;, &#39;fatalities&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;opposite_crucialness&#39;, &#39;fatalities&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;opposite_crucialness&#39;, &#39;fatalities&#39;, &#39;Kamwenge&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;opposite_crucialness&#39;, &#39;events&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;opposite_crucialness&#39;, &#39;events&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;opposite_crucialness&#39;, &#39;events&#39;, &#39;Kamwenge&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;opposite_pressure&#39;, &#39;fatalities&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;opposite_pressure&#39;, &#39;fatalities&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;opposite_pressure&#39;, &#39;fatalities&#39;, &#39;Kamwenge&#39;) . time_series(agago_water_ts, agago_conflict_ts, &#39;opposite_pressure&#39;, &#39;events&#39;, &#39;Agago&#39;) time_series(lira_water_ts, lira_conflict_ts, &#39;opposite_pressure&#39;, &#39;events&#39;, &#39;Lira&#39;) time_series(kamwenge_water_ts, kamwenge_conflict_ts, &#39;opposite_pressure&#39;, &#39;events&#39;, &#39;Kamwenge&#39;) . fatalities_date=working_conflict_df.groupby(&#39;event_date&#39;).sum() events_date=working_conflict_df.groupby(&#39;event_date&#39;).count() install_date=working_water_df.groupby(&#39;install_year&#39;).count() . fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=events_date.index, y=events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=install_date.index, y=install_date[&#39;wpdx_id&#39;], name=&#39;installations&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;installations&#39;, secondary_y=True) fig.update_layout(title=&#39;Uganda&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . agago_fatalities_date=agago_conflict_ts.groupby(&#39;event_date&#39;).sum() agago_events_date=agago_conflict_ts.groupby(&#39;event_date&#39;).count() agago_install_date=agago_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=agago_fatalities_date.index, y=agago_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=agago_install_date.index, y=agago_install_date[&#39;wpdx_id&#39;], name=&#39;installations&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;installations&#39;, secondary_y=True) fig.update_layout(title=&#39;Agago&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . lira_fatalities_date=lira_conflict_ts.groupby(&#39;event_date&#39;).sum() lira_events_date=lira_conflict_ts.groupby(&#39;event_date&#39;).count() lira_install_date=lira_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=lira_events_date.index, y=lira_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=lira_install_date.index, y=lira_install_date[&#39;wpdx_id&#39;], name=&#39;installations&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;installations&#39;, secondary_y=True) fig.update_layout(title=&#39;Lira&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . kamwenge_fatalities_date=kamwenge_conflict_ts.groupby(&#39;event_date&#39;).sum() kamwenge_events_date=kamwenge_conflict_ts.groupby(&#39;event_date&#39;).count() kamwenge_install_date=kamwenge_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=kamwenge_events_date.index, y=kamwenge_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=kamwenge_install_date.index, y=kamwenge_install_date[&#39;wpdx_id&#39;], name=&#39;installations&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;installations&#39;, secondary_y=True) fig.update_layout(title=&#39;Kamwenge&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . water_df[&#39;status_id&#39;].value_counts() #status and status clean? . water_df[&#39;functioning&#39;]=water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) . water_funct_year=water_df.groupby(&#39;install_year&#39;).sum() #installations and events fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=events_date.index, y=events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=water_funct_year.index, y=water_funct_year[&#39;functioning&#39;], name=&#39;functioning points&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;functioning points&#39;, secondary_y=True) fig.update_layout(title=&#39;Uganda&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . agago_fatalities_date=agago_conflict_ts.groupby(&#39;event_date&#39;).sum() agago_events_date=agago_conflict_ts.groupby(&#39;event_date&#39;).count() agago_water_df[&#39;functioning&#39;]=agago_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) agagowater_funct_year=agago_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=agago_events_date.index, y=agago_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=agagowater_funct_year.index, y=agagowater_funct_year[&#39;wpdx_id&#39;], name=&#39;functioning points&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;functioning points&#39;, secondary_y=True) fig.update_layout(title=&#39;Agago&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . lira_fatalities_date=lira_conflict_ts.groupby(&#39;event_date&#39;).sum() lira_events_date=lira_conflict_ts.groupby(&#39;event_date&#39;).count() lira_water_df[&#39;functioning&#39;]=lira_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) lirawater_funct_year=lira_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=lira_events_date.index, y=lira_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=lirawater_funct_year.index, y=lirawater_funct_year[&#39;wpdx_id&#39;], name=&#39;functioning points&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;functioning points&#39;, secondary_y=True) fig.update_layout(title=&#39;Lira&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() . kamwenge_fatalities_date=kamwenge_conflict_ts.groupby(&#39;event_date&#39;).sum() kamwenge_events_date=kamwenge_conflict_ts.groupby(&#39;event_date&#39;).count() kamwenge_water_df[&#39;functioning&#39;]=kamwenge_water_df[&#39;status_id&#39;].map({&#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0}) kamwengewater_funct_year=kamwenge_water_df.groupby(&#39;install_year&#39;).count() fig = make_subplots(specs=[[{&quot;secondary_y&quot;: True}]]) fig.add_trace( go.Scatter(x=kamwenge_events_date.index, y=kamwenge_events_date[&#39;fatalities&#39;], name=&#39;events&#39;), secondary_y=False, ) fig.add_trace( go.Scatter(x=kamwengewater_funct_year.index, y=kamwengewater_funct_year[&#39;wpdx_id&#39;], name=&#39;functioning points&#39;), secondary_y=True, ) # Set y-axes titles fig.update_yaxes(title_text=&#39;events&#39;, secondary_y=False) fig.update_yaxes(title_text=&#39;functioning points&#39;, secondary_y=True) fig.update_layout(title=&#39;Kamwenge&#39;) fig.update_xaxes(rangeslider_visible=True) fig.update_traces(opacity=0.65) fig.update_layout(xaxis_range=[datetime(1997,1,1),datetime(2022,12,31)]) fig.show() .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_99_ARCHIVED_eda.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_99_ARCHIVED_eda.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Model Comparison",
            "content": "Uganda Water Infrastructure . toc: false | branch: master | badges: true | comments: true | categories: [fastpages, jupyter] | hide: false | search_exclude: true | metadata_key1: metadata_value1 | metadata_key2: metadata_value2 | . Model comparison . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . path = model_filepath csv_files = glob.glob(path + &quot;/*.csv&quot;) #concatenate all files all_models_comparison = [] for file in csv_files: df = pd.read_csv(file, index_col=None, header=0) all_models_comparison.append(df) #make it into a dataframe model_comparison_df = pd.concat(all_models_comparison, axis=0, ignore_index=True) model_comparison_df=model_comparison_df.iloc[:,1:] #check model_comparison_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test ... ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test Functioning Test . 0 XGBoost | Max depth=6, Gamma=0, Learning rate=0.3, Numbe... | 0.841840 | 0.842494 | 0.841840 | 0.841765 | 0.924392 | 0.771517 | 0.813022 | 0.771517 | ... | 0.808766 | 19.921147 | 0.038439 | 0.45 | 0.65 | 0.53 | 0.90 | 0.80 | 0.85 | NaN | . 1 WPDx | Unknown | NaN | NaN | NaN | NaN | NaN | NaN | [0.80834636 0.80834439 0.8083527 ... 1. ... | [1.00000000e+00 9.99987281e-01 9.99987281e-01 ... | ... | 0.788902 | NaN | NaN | 0.54 | 0.40 | 0.46 | 0.87 | 0.92 | 0.89 | NaN | . 2 K Nearest Neighbors | Neighbors=4, Standard Scaler | 0.870462 | 0.884488 | 0.870462 | 0.869269 | 0.967214 | 0.678122 | 0.781206 | 0.678122 | ... | 0.720382 | 0.034317 | 0.166168 | 0.33 | 0.65 | 0.44 | 0.89 | 0.69 | 0.77 | NaN | . 3 Gaussian Naive Bayes | NaN | 0.612033 | 0.614446 | 0.612033 | 0.609977 | 0.658882 | 0.642347 | 0.727009 | 0.642347 | ... | 0.615479 | 0.140393 | 0.028196 | 0.27 | 0.47 | 0.34 | 0.84 | 0.69 | 0.75 | NaN | . 4 Neural Network | Hidden layer=16 nodes, Optimizer=Adam, Loss fu... | NaN | NaN | NaN | NaN | 0.858612 | NaN | NaN | NaN | ... | 0.788690 | 323.817263 | 0.787798 | 0.42 | 0.63 | 0.50 | 0.90 | 0.78 | NaN | 0.84 | . 5 Linear SVC | Penalty=l2, C=0.001, Standard Scaler | 0.652100 | 0.652120 | 0.652100 | 0.652089 | 0.710458 | 0.631198 | 0.74105 | 0.631198 | ... | 0.640733 | 1.170683 | 0.019465 | 0.28 | 0.55 | 0.37 | 0.85 | 0.65 | 0.74 | NaN | . 6 Decision Tree | Max depth=24, Min samples leaf=25, Criterion=e... | 0.840586 | 0.840826 | 0.840586 | 0.840558 | 0.929668 | 0.751038 | 0.798911 | 0.751038 | ... | 0.774382 | 3.789587 | 0.015336 | 0.41 | 0.62 | 0.49 | 0.89 | 0.78 | 0.83 | NaN | . 7 Random Forest | Max depth=31, Min samples leaf=11, Criterion=e... | 0.897099 | 0.897332 | 0.897099 | 0.897084 | 0.966498 | 0.792881 | 0.817337 | 0.792881 | ... | 0.823229 | 52.538480 | 0.515494 | 0.48 | 0.62 | 0.54 | 0.90 | 0.83 | 0.87 | NaN | . 8 AdaBoost | Learning rate=1, Number of trees=50 | 0.704895 | 0.706307 | 0.704895 | 0.704390 | 0.777469 | 0.657461 | 0.769839 | 0.657461 | ... | 0.708767 | 33.512388 | 0.300903 | 0.32 | 0.64 | 0.42 | 0.88 | 0.66 | 0.76 | NaN | . 9 Logistic Regression | Penalty=l2, C=0.1, Standard Scaler | 0.651419 | 0.651419 | 0.651419 | 0.651419 | 0.710467 | 0.626813 | 0.741167 | 0.626813 | ... | 0.640127 | 0.397975 | 0.001858 | 0.65 | 0.65 | 0.65 | 0.65 | 0.65 | 0.65 | NaN | . 10 rows × 21 columns . #logistic regression fpr_train_lr = np.load(model_filepath+&#39;logistic_regression_fpr_train_opt.npy&#39;) tpr_train_lr = np.load(model_filepath+&#39;logistic_regression_tpr_train_opt.npy&#39;) auc_train_lr = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Logistic Regression&#39;][&#39;ROC AUC Train&#39;] #k nearest neighbors fpr_train_knn = np.load(model_filepath+&#39;k_nearest_neighbors_fpr_train_opt.npy&#39;) tpr_train_knn = np.load(model_filepath+&#39;k_nearest_neighbors_tpr_train_opt.npy&#39;) auc_train_knn = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;K Nearest Neighbors&#39;][&#39;ROC AUC Train&#39;] #decision tree fpr_train_dt = np.load(model_filepath+&#39;decision_tree_fpr_train_opt.npy&#39;) tpr_train_dt = np.load(model_filepath+&#39;decision_tree_tpr_train_opt.npy&#39;) auc_train_dt = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Decision Tree&#39;][&#39;ROC AUC Train&#39;] #random forest fpr_train_rf = np.load(model_filepath+&#39;random_forest_fpr_train_opt.npy&#39;) tpr_train_rf = np.load(model_filepath+&#39;random_forest_tpr_train_opt.npy&#39;) auc_train_rf = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Random Forest&#39;][&#39;ROC AUC Train&#39;] #gaussian naive bayes fpr_train_gnb = np.load(model_filepath+&#39;gaussian_naive_bayes_fpr_train_base.npy&#39;) tpr_train_gnb = np.load(model_filepath+&#39;gaussian_naive_bayes_tpr_train_base.npy&#39;) auc_train_gnb = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Gaussian Naive Bayes&#39;][&#39;ROC AUC Train&#39;] #support vector machine fpr_train_svm = np.load(model_filepath+&#39;support_vector_machine_fpr_train_base.npy&#39;) tpr_train_svm = np.load(model_filepath+&#39;support_vector_machine_tpr_train_base.npy&#39;) auc_train_svm = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Linear SVC&#39;][&#39;ROC AUC Train&#39;] #adaboost fpr_train_ab = np.load(model_filepath+&#39;adaboost_fpr_train_base.npy&#39;) tpr_train_ab = np.load(model_filepath+&#39;adaboost_tpr_train_base.npy&#39;) auc_train_ab = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;AdaBoost&#39;][&#39;ROC AUC Train&#39;] #xgboost fpr_train_xg = np.load(model_filepath+&#39;xgboost_fpr_train_base.npy&#39;) tpr_train_xg = np.load(model_filepath+&#39;xgboost_tpr_train_base.npy&#39;) auc_train_xg = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;XGBoost&#39;][&#39;ROC AUC Train&#39;] #neural network fpr_train_nn = np.load(model_filepath+&#39;neural_network_fpr_train_opt.npy&#39;) tpr_train_nn = np.load(model_filepath+&#39;neural_network_tpr_train_opt.npy&#39;) auc_train_nn = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Neural Network&#39;][&#39;ROC AUC Train&#39;] . I had to save the arrays of our false positive and true positive rates for varying thresholds in specific numpy files. This was to keep the array format to more easily plot it. . #logistic regression fpr_test_lr = np.load(model_filepath+&#39;logistic_regression_fpr_test_opt.npy&#39;) tpr_test_lr = np.load(model_filepath+&#39;logistic_regression_tpr_test_opt.npy&#39;) auc_test_lr = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Logistic Regression&#39;][&#39;ROC AUC Test&#39;] #k nearest neighbors fpr_test_knn = np.load(model_filepath+&#39;k_nearest_neighbors_fpr_test_opt.npy&#39;) tpr_test_knn = np.load(model_filepath+&#39;k_nearest_neighbors_tpr_test_opt.npy&#39;) auc_test_knn = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;K Nearest Neighbors&#39;][&#39;ROC AUC Test&#39;] #decision tree fpr_test_dt = np.load(model_filepath+&#39;decision_tree_fpr_test_opt.npy&#39;) tpr_test_dt = np.load(model_filepath+&#39;decision_tree_tpr_test_opt.npy&#39;) auc_test_dt = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Decision Tree&#39;][&#39;ROC AUC Test&#39;] #random forest fpr_test_rf = np.load(model_filepath+&#39;random_forest_fpr_test_opt.npy&#39;) tpr_test_rf = np.load(model_filepath+&#39;random_forest_tpr_test_opt.npy&#39;) auc_test_rf = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Random Forest&#39;][&#39;ROC AUC Test&#39;] #gaussian naive bayes fpr_test_gnb = np.load(model_filepath+&#39;gaussian_naive_bayes_fpr_test_base.npy&#39;) tpr_test_gnb = np.load(model_filepath+&#39;gaussian_naive_bayes_tpr_test_base.npy&#39;) auc_test_gnb = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Gaussian Naive Bayes&#39;][&#39;ROC AUC Test&#39;] #support vector machine fpr_test_svm = np.load(model_filepath+&#39;support_vector_machine_fpr_test_base.npy&#39;) tpr_test_svm = np.load(model_filepath+&#39;support_vector_machine_tpr_test_base.npy&#39;) auc_test_svm = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Linear SVC&#39;][&#39;ROC AUC Test&#39;] #adaboost fpr_test_ab = np.load(model_filepath+&#39;adaboost_fpr_test_base.npy&#39;) tpr_test_ab = np.load(model_filepath+&#39;adaboost_tpr_test_base.npy&#39;) auc_test_ab = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;AdaBoost&#39;][&#39;ROC AUC Test&#39;] #xgboost fpr_test_xg = np.load(model_filepath+&#39;xgboost_fpr_test_base.npy&#39;) tpr_test_xg = np.load(model_filepath+&#39;xgboost_tpr_test_base.npy&#39;) auc_test_xg = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;XGBoost&#39;][&#39;ROC AUC Test&#39;] #neural network fpr_test_nn = np.load(model_filepath+&#39;neural_network_fpr_test_opt.npy&#39;) tpr_test_nn = np.load(model_filepath+&#39;neural_network_tpr_test_opt.npy&#39;) auc_test_nn = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;Neural Network&#39;][&#39;ROC AUC Test&#39;] #wpdx fpr_test_wpdx = np.load(model_filepath+&#39;wpdx_fpr_wpdx.npy&#39;) tpr_test_wpdx = np.load(model_filepath+&#39;wpdx_tpr_wpdx.npy&#39;) auc_test_wpdx = model_comparison_df[model_comparison_df[&#39;Model&#39;]==&#39;WPDx&#39;][&#39;ROC AUC Test&#39;] . ROC Curve for Train/Test . plt.figure(figsize=(20,10)) plt.plot([1,0], [1,0], color=&#39;black&#39;, linestyle=&#39;--&#39;) plt.title(&#39;Receiver Operating Characteristic (ROC) Curve - Train&#39;, size=20) #visualise each roc curve plt.plot(fpr_train_rf, tpr_train_rf, color=&#39;darkturquoise&#39;, lw=4, label=&#39;RF AUC = %0.2f&#39; % auc_train_rf) plt.plot(fpr_train_knn, tpr_train_knn, color=&#39;darkorange&#39;, lw=4, label=&#39;KNN AUC = %0.2f&#39; % auc_train_knn) plt.plot(fpr_train_dt, tpr_train_dt, color=&#39;limegreen&#39;, lw=4, label=&#39;DT AUC = %0.2f&#39; % auc_train_dt) plt.plot(fpr_train_xg, tpr_train_xg, color=&#39;peru&#39;, lw=4, label=&#39;XG AUC = %0.2f&#39; % auc_train_xg) plt.plot(fpr_train_nn, tpr_train_nn, color=&#39;darkkhaki&#39;, lw=4, label=&#39;NN AUC = %0.2f&#39; % auc_train_nn) plt.plot(fpr_train_ab, tpr_train_ab, color=&#39;palevioletred&#39;, lw=4, label=&#39;AB AUC = %0.2f&#39; % auc_train_ab) plt.plot(fpr_train_svm, tpr_train_svm, color=&#39;darkorchid&#39;, lw=4, label=&#39;SVM AUC = %0.2f&#39; % auc_train_svm) plt.plot(fpr_train_lr, tpr_train_lr, color=&#39;orangered&#39;, lw=4, label=&#39;LR AUC = %0.2f&#39; % auc_train_lr) plt.plot(fpr_train_gnb, tpr_train_gnb, color=&#39;mediumblue&#39;, lw=4, label=&#39;GNB AUC = %0.2f&#39; % auc_train_gnb) plt.xlabel(&#39;False Positive Rate&#39;, size=20) plt.ylabel(&#39;True Positive Rate&#39;, size=20) plt.xticks(size=20) plt.yticks(size=20) plt.legend(loc=&quot;best&quot;) plt.grid() . For the train dataset, the best performing models are KNN and Random Forest while the worst performing ones are the Naive Bayes and Logistic Regression. . plt.figure(figsize=(20,10)) plt.plot([1,0], [1,0], color=&#39;black&#39;, linestyle=&#39;--&#39;) plt.title(&#39;Receiver Operating Characteristic (ROC) Curve - Test&#39;, size=20) #visualise each roc curve plt.plot(fpr_test_rf, tpr_test_rf, color=&#39;darkturquoise&#39;, lw=4, label=&#39;RF AUC = %0.2f&#39; % auc_test_rf) plt.plot(fpr_test_xg, tpr_test_xg, color=&#39;peru&#39;, lw=4, label=&#39;XG AUC = %0.2f&#39; % auc_test_xg) plt.plot(fpr_test_nn, tpr_test_nn, color=&#39;darkkhaki&#39;, lw=4, label=&#39;NN AUC = %0.2f&#39; % auc_test_nn) plt.plot(fpr_test_wpdx, tpr_test_wpdx, color=&#39;Red&#39;, lw=4, label=&#39;WPDx AUC = %0.2f&#39; % auc_test_wpdx) plt.plot(fpr_test_dt, tpr_test_dt, color=&#39;limegreen&#39;, lw=4, label=&#39;DT AUC = %0.2f&#39; % auc_test_dt) plt.plot(fpr_test_knn, tpr_test_knn, color=&#39;darkorange&#39;, lw=4, label=&#39;KNN AUC = %0.2f&#39; % auc_test_knn) plt.plot(fpr_test_ab, tpr_test_ab, color=&#39;palevioletred&#39;, lw=4, label=&#39;AB AUC = %0.2f&#39; % auc_test_ab) plt.plot(fpr_test_lr, tpr_test_lr, color=&#39;sienna&#39;, lw=4, label=&#39;LR AUC = %0.2f&#39; % auc_test_lr) plt.plot(fpr_test_svm, tpr_test_svm, color=&#39;darkorchid&#39;, lw=4, label=&#39;SVM AUC = %0.2f&#39; % auc_test_svm) plt.plot(fpr_test_gnb, tpr_test_gnb, color=&#39;mediumblue&#39;, lw=4, label=&#39;GNB AUC = %0.2f&#39; % auc_test_gnb) plt.xlabel(&#39;False Positive Rate&#39;, size=20) plt.ylabel(&#39;True Positive Rate&#39;, size=20) plt.xticks(size=20) plt.yticks(size=20) plt.legend(loc=&quot;best&quot;) plt.grid() . Similarly to the training set, Random Forest has the largest AUC on the test set, followed closely by XGBoost and our Neural Network. KNN shows large overfitting as it did very well on the train set but not so well on the test set. Naive Bayes, Support Vector Machine and Logistic Regression all perform poorly on the test set. . Plot accuracy score for Train/Test . accuracies=[&#39;Accuracy Train&#39;, &#39;Accuracy Test&#39;] #visualise metrics plt.subplots(1,2, figsize=(20,15)) for i, accuracy in enumerate(accuracies, 1): plt.subplot(3,2,i) sns.barplot(data=model_comparison_df, x=accuracy, y=&#39;Model&#39;, palette=&#39;mako&#39;) plt.axvline(model_comparison_df[accuracy].mean(), c=&#39;gold&#39;, label=&#39;mean&#39;) plt.tight_layout() plt.show() . The visualisation above show us that the best performing models, in terms of accuracy on the test set, are Random Forest, XGBoost and Decision Tree. Support Vector Machine and Naive Bayes, again, have poor accuracy scores. . plt.plot() sns.lineplot(data=model_comparison_df, y=&#39;Accuracy Train&#39;, x=&#39;Model&#39;, palette=&#39;rocket&#39;, label=&#39;train&#39;, marker=&#39;o&#39;) sns.lineplot(data=model_comparison_df, y=&#39;Accuracy Test&#39;, x=&#39;Model&#39;, palette=&#39;rocket&#39;, label=&#39;test&#39;, marker=&#39;o&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.tight_layout() plt.grid() plt.legend() plt.xticks(rotation=80) plt.show() . The models which overfits the most are the ones with the largest gap between their train and test set accuracy scores. These are KNN and, to a lesser extent, Random Forest. . plt.plot() sns.barplot(data=model_comparison_df, x=&#39;Accuracy Train&#39;, y=&#39;Model&#39;, label=&#39;train&#39;, color=&#39;dodgerblue&#39;) sns.barplot(data=model_comparison_df, x=&#39;Accuracy Test&#39;, y=&#39;Model&#39; , label=&#39;test&#39;, color=&#39;darkorange&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.legend() plt.show() . Similarly, the blue bar tells us how much better a training set performs versus it&#39;s test set, and KNN clearly shows that it is the case, suggesting heavy overfitting. . Plot Precision/Recall/F1 for Functioning/Non-functioning Test . metrics=[&#39;Precision Non-functioning Test&#39;, &#39;Recall Non-functioning Test&#39;, &#39;F1 Non-functioning Test&#39;, &#39;Precision Functioning Test&#39;, &#39;Recall Functioning Test&#39;, &#39;F1 Functioning Test&#39;] #visualise through a subplot plt.subplots(3,2, figsize=(20,15)) for i, metric in enumerate(metrics, 1): plt.subplot(3,2,i) sns.barplot(data=model_comparison_df, x=metric, y=&#39;Model&#39;, palette=&#39;rocket&#39;) plt.axvline(model_comparison_df[metric].mean(), c=&#39;gold&#39;, label=&#39;mean&#39;) plt.tight_layout() plt.show() . We are the most interested in the recall for non-functioning water points. This is the proportion of non-functioning points we miss. For example, our best performing models have a recall on non-functioning water points of around 60%. This means that they miss 40% of non-functioning points. We exoplanined previously why this is our metric of choice: we&#39;d rather have false alarms (sending engineers for repair) than whole communities not having access to water. . XGBoost, KNN, AdaBoost and Logistic Regression all perform relatively well in this metric. We will have to look for other factors to choose our best model. . Time fit . plt.figure() sns.barplot(data=model_comparison_df, x=&#39;Time Fit&#39;, y=&#39;Model&#39;, palette=&#39;rocket&#39;) plt.xscale(&#39;log&#39;) plt.show() . The most expensive models to train are Neural Networks and Random Forests, closely followed by XGBoosts and AdaBoosts. KNN is very quick to train as it does not actually need much training. Note that this is a log scale, so the difference between models are relatively large. . Time predict . plt.figure() sns.barplot(data=model_comparison_df, x=&#39;Time Predict&#39;, y=&#39;Model&#39;, palette=&#39;mako&#39;) plt.xscale(&#39;log&#39;) plt.show() . The prediction time is similar to the fitting time, Neural Networks and Random Forests are very expensive. Note that KNN does need a much longer time to predict than train while it is the oppositfe for the Logistic Regression. . Final model choice . We will go step by step to choose our model of choice, we start with our 9 models and will eliminate them: . XGBoost | K Nearest Neighbors | Gaussian Naive Bayes | Neural Network | Linear SVC | Decision Tree | Random Forest | AdaBoost | Logistic Regression | A. Recall score for non-functioning water points on test set. This is our most important metric. All have very similar scores, except Naive Bays and SVM, which we drop. . XGBoost | K Nearest Neighbors | Neural Network | Decision Tree | Random Forest | AdaBoost | Logistic Regression | B. Overfitting. KNN overfits the training set and makes us doubt if it would a useful modle on another dataset, so we drop it. . XGBoost | Neural Network | Decision Tree | Random Forest | AdaBoost | Logistic Regression | C. Training and Predicting Time. Our neural network takes a very long time to both train and predict, and does not yield much better results, so we drop it. . XGBoost | Decision Tree | Random Forest | AdaBoost | Logistic Regression | D. Overall Accuracy scores on test set. Logistic Regression and AdaBoost perform especially poorly in this field, we drop them. . XGBoost | Decision Tree | Random Forest | E. AUC on test set. Decision Tree has a low AUC compared ot our other two models, so we drop it. . XGBoost | Random Forest | Looking at our various elimination metrics for XGBoost and Random Forest, XGBoost does better for metric A, B and C while Random Forest does better for D and E. Since XGBoost has better scores for the first three metrics (the most immportant ones), we decide to go with XGBoost as our final model of choice. . WPDx Model Comparison . plt.figure(figsize=(10,8)) plt.plot([1,0], [1,0], color=&#39;black&#39;, linestyle=&#39;--&#39;) plt.title(&#39;Receiver Operating Characteristic (ROC) Curve&#39;) #visualise each roc curve plt.plot(fpr_test_xg, tpr_test_xg, color=&#39;peru&#39;, lw=2, label=&#39;XG AUC = %0.2f&#39; % auc_test_xg) plt.plot(fpr_test_wpdx, tpr_test_wpdx, color=&#39;Red&#39;, lw=2, label=&#39;WPDx AUC = %0.2f&#39; % auc_test_wpdx) plt.xlabel(&#39;False Positive Rate&#39;) plt.ylabel(&#39;True Positive Rate&#39;) plt.legend(loc=&quot;best&quot;) plt.grid() . Our best model outperforms the WPDx model by a relatively small amount, if we look at the AUC. . merged_df=model_comparison_df.iloc[0:2,:] #choose relevant metric merged_df[[&#39;Model&#39;, &#39;Precision Non-functioning Test&#39;, &#39;Recall Non-functioning Test&#39;, &#39;F1 Non-functioning Test&#39;, &#39;Precision Functioning Test&#39;, &#39;Recall Functioning Test&#39;, &#39;F1 Functioning Test&#39;]] . Model Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 XGBoost | 0.45 | 0.65 | 0.53 | 0.90 | 0.80 | 0.85 | . 1 WPDx | 0.54 | 0.40 | 0.46 | 0.87 | 0.92 | 0.89 | . We creata a dataframe to make it easier to visualise in the way we want it. . d = {&#39;Accuracy Metrics&#39;: [&#39;Precision Non-functioning Test&#39;, &#39;Recall Non-functioning Test&#39;, &#39;F1 Non-functioning Test&#39;, &#39;Precision Functioning Test&#39;, &#39;Recall Functioning Test&#39;, &#39;F1 Functioning Test&#39;, &#39;Precision Non-functioning Test&#39;, &#39;Recall Non-functioning Test&#39;, &#39;F1 Non-functioning Test&#39;, &#39;Precision Functioning Test&#39;, &#39;Recall Functioning Test&#39;, &#39;F1 Functioning Test&#39;], &#39;Model&#39;: [&#39;XGBoost&#39;, &#39;XGBoost&#39;, &#39;XGBoost&#39;,&#39;XGBoost&#39;, &#39;XGBoost&#39;, &#39;XGBoost&#39;, &#39;WPDx&#39;, &#39;WPDx&#39;, &#39;WPDx&#39;, &#39;WPDx&#39;, &#39;WPDx&#39;, &#39;WPDx&#39;], &#39;Score&#39;:[0.45, 0.65, 0.53, 0.90, 0.8, 0.85, 0.54, 0.4, 0.46, 0.87, 0.92, 0.89]} #create datafrane for easier visualistion comparison_df=pd.DataFrame(data=d) #check comparison_df . Accuracy Metrics Model Score . 0 Precision Non-functioning Test | XGBoost | 0.45 | . 1 Recall Non-functioning Test | XGBoost | 0.65 | . 2 F1 Non-functioning Test | XGBoost | 0.53 | . 3 Precision Functioning Test | XGBoost | 0.90 | . 4 Recall Functioning Test | XGBoost | 0.80 | . 5 F1 Functioning Test | XGBoost | 0.85 | . 6 Precision Non-functioning Test | WPDx | 0.54 | . 7 Recall Non-functioning Test | WPDx | 0.40 | . 8 F1 Non-functioning Test | WPDx | 0.46 | . 9 Precision Functioning Test | WPDx | 0.87 | . 10 Recall Functioning Test | WPDx | 0.92 | . 11 F1 Functioning Test | WPDx | 0.89 | . plt.figure() sns.catplot(data=comparison_df, kind=&#39;bar&#39;, x=&#39;Accuracy Metrics&#39;, y=&#39;Score&#39;, hue=&#39;Model&#39;, height=6) plt.legend(loc=&#39;best&#39;) plt.xticks(rotation=70) plt.show() . &lt;Figure size 432x288 with 0 Axes&gt; . Our model performs much better on the recall for non-functioning water points, ours is more than 20 percentage points higher. This is the metric we care the most about. We also perform better on the precision of functioning points. . On the other hand, our model performs not as well on the precision of non-functioning points and recall of functioning points. . Overall, our model outperforms WPDx model and is a net improvement. We will quantify these improvements in our subsequent analysis. . model_comparison_df.to_csv(data_filepath+&#39;model_comparison_df.csv&#39;) comparison_df.to_csv(data_filepath+&#39;comparison_df.csv&#39;) . Limitations . The main limitation we have with our dataset is the data. Although we have a wide range of variables, we are still missing more granular and precise variables, especially regarding health outcomes. It would be important to know the mortality rate of each region/water point, especially for children and in general diarrehea and other water-inducing sickness. . Another thing is that I have done a quite heavy feature engineering before running any model. One possibility would not to do those and let the model and regularization choose which features are better at predicting water functionality. I did this heavy feature engineering in an attempt to introduce more qualitative analysis in the project. . Leading on from this, it would be worth spending more time on neural networks, and test more complex architectures with a much larger dataset with more features and see if we can find better accuracy metrics. C7rrently, the limited number of features and the relatively &quot;simple&quot; problem I have posed makes me think that more complex modelling (including neural networks) is not giving us much of an edge. This is also probably why tuning hyperparameters is not helping us much. . In addition, an obvious extension is attempting to use this model in other regions and see if our model has a strong predictive power there. I would expect not as a lot of variables include country-specific features and unobservables. . Finally, the direction of causation between water point functionality, health/education/poverty (in general development indicators) outcomes and conflict is multi-directional, and we may be over-simplifying the problem or just getting the relationhip directions wrong. .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_17_model_comparison.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_17_model_comparison.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "WPDx Model",
            "content": "WPDx Predictions Dataset . The Water Point Data Exchange have come up with their own predictor of water point functionality, with a much more limited dataset and using basic ML models. We will extract key accuracy metrics to be compared to our other models. . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . %run /Users/thomasadler/Desktop/futuristic-platipus/keys.py . socrata_domain = &#39;data.waterpointdata.org&#39; socrata_dataset_identifier = &#39;9pn9-g5u4&#39; socrata_token = os.environ.get(water_api_key) client = Socrata(socrata_domain, socrata_token, timeout=10) . WARNING:root:Requests made without an app_token will be subject to strict throttling limits. . water_uganda_query = &quot;&quot;&quot; select * limit 200000 &quot;&quot;&quot; . results = client.get(socrata_dataset_identifier, query=water_uganda_query) wpdx_prediction_df_raw = pd.DataFrame.from_records(results) . wpdx_prediction_df = wpdx_prediction_df_raw.copy() . wpdx_prediction_df.head() . row_id country_name status_id management install_year age source adm1 adm2 wpdx_id ... location count notes prediction prediction_level geocoded_column :@computed_region_7zzf_xi3x water_source pay water_tech . 0 212904 | Uganda | True | Community Management | 2000 | 9 | Ministry of Water and Environment, Uganda | APAC | KWANIA | wpdx-00212904 | ... | (1.85898, 32.5605) | 1 | Village=AJAR | 0.775195278 | Low Risk | {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: [32.5605, 1.8... | 164 | NaN | NaN | NaN | . 1 223181 | Uganda | True | Community Management | NaN | NaN | Ministry of Water and Environment, Uganda | KOTIDO | JIE | wpdx-00223181 | ... | (2.99382, 34.1998) | 1 | Village=LORIU | 0.744118007 | Low Risk | {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: [34.1998, 2.9... | 164 | Dam | NaN | NaN | . 2 203413 | Uganda | True | Community Management | 2009 | 0 | Ministry of Water and Environment, Uganda | ARUA | AYIVU | wpdx-00203413 | ... | (3.0963, 30.9006) | 1 | Village=OMI | 0.531849859 | Medium Risk | {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: [30.9006, 3.0... | 164 | Shallow well | NaN | NaN | . 3 203353 | Uganda | True | Community Management | 1987 | 22 | Ministry of Water and Environment, Uganda | ARUA | AYIVU | wpdx-00203353 | ... | (3.0128, 30.8331) | 1 | Village=ANDRU | 0.641468187 | Medium Risk | {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: [30.8331, 3.0... | 164 | Protected spring | NaN | NaN | . 4 203801 | Uganda | True | Community Management | 2006 | 3 | Ministry of Water and Environment, Uganda | ARUA | AYIVU | wpdx-00203801 | ... | (2.986, 30.9401) | 1 | Village=Ogayi | 0.839493928 | Low Risk | {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: [30.9401, 2.9... | 164 | Protected spring | NaN | NaN | . 5 rows × 27 columns . wpdx_prediction_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 97268 entries, 0 to 97267 Data columns (total 27 columns): # Column Non-Null Count Dtype -- -- 0 row_id 97268 non-null object 1 country_name 97268 non-null object 2 status_id 97268 non-null bool 3 management 97268 non-null object 4 install_year 92790 non-null object 5 age 92790 non-null object 6 source 97268 non-null object 7 adm1 97268 non-null object 8 adm2 97268 non-null object 9 wpdx_id 97268 non-null object 10 report_date 97268 non-null object 11 country_id 97268 non-null object 12 activity_id 97268 non-null object 13 data_lnk 97268 non-null object 14 converted 97268 non-null object 15 lat_deg 97268 non-null object 16 lon_deg 97268 non-null object 17 location 97268 non-null object 18 count 97268 non-null object 19 notes 97268 non-null object 20 prediction 97268 non-null object 21 prediction_level 97268 non-null object 22 geocoded_column 97268 non-null object 23 :@computed_region_7zzf_xi3x 97268 non-null object 24 water_source 82630 non-null object 25 pay 37540 non-null object 26 water_tech 14097 non-null object dtypes: bool(1), object(26) memory usage: 19.4+ MB . wpdx_prediction_df=wpdx_prediction_df[[&#39;status_id&#39;, &#39;prediction&#39; ]] #check wpdx_prediction_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 97268 entries, 0 to 97267 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 status_id 97268 non-null bool 1 prediction 97268 non-null object dtypes: bool(1), object(1) memory usage: 855.0+ KB . wpdx_prediction_df.isna().sum().sum() . 0 . for col in [&#39;prediction&#39;]: float_converter(wpdx_prediction_df, col) # check wpdx_prediction_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 97268 entries, 0 to 97267 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 status_id 97268 non-null bool 1 prediction 97268 non-null float32 dtypes: bool(1), float32(1) memory usage: 475.1 KB . wpdx_prediction_df[&#39;status_id&#39;] = np.where(wpdx_prediction_df[&#39;status_id&#39;]==True, 1, 0) # check wpdx_prediction_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 97268 entries, 0 to 97267 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 status_id 97268 non-null int64 1 prediction 97268 non-null float32 dtypes: float32(1), int64(1) memory usage: 1.1 MB . wpdx_prediction_df[&#39;y_prediction_wpdx&#39;]=np.where(wpdx_prediction_df[&#39;prediction&#39;]&gt;0.5,1,0) wpdx_prediction_df[&#39;y_prediction_wpdx&#39;].value_counts(normalize=True) . 1 0.858515 0 0.141485 Name: y_prediction_wpdx, dtype: float64 . wpdx_prediction_df.rename(columns={&#39;status_id&#39;:&quot;y_real_wpdx&quot;, &#39;prediction&#39;:&#39;y_proba_wpdx&#39;}, inplace=True) #check wpdx_prediction_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 97268 entries, 0 to 97267 Data columns (total 3 columns): # Column Non-Null Count Dtype -- -- 0 y_real_wpdx 97268 non-null int64 1 y_proba_wpdx 97268 non-null float32 2 y_prediction_wpdx 97268 non-null int64 dtypes: float32(1), int64(2) memory usage: 1.9 MB . Image(images_filepath+&quot;WPDx_Methodology.png&quot;) . fpr_wpdx, tpr_wpdx, thresholds_roc_wpdx = roc_curve(wpdx_prediction_df[&#39;y_real_wpdx&#39;], wpdx_prediction_df[&#39;y_proba_wpdx&#39;]) #getting precision/recall scores precision_wpdx, recall_wpdx, thresholds_pr_wpdx = precision_recall_curve(wpdx_prediction_df[&#39;y_real_wpdx&#39;], wpdx_prediction_df[&#39;y_proba_wpdx&#39;]) # storing values roc_auc_wpdx = auc(fpr_wpdx, tpr_wpdx) pr_auc_wpdx=auc(recall_wpdx, precision_wpdx) # seeing model results print(f&#39;ROC AUC: {roc_auc_wpdx}&#39;) print(f&#39;PR AUC: {pr_auc_wpdx}&#39;) print(classification_report(wpdx_prediction_df[&#39;y_real_wpdx&#39;], wpdx_prediction_df[&#39;y_prediction_wpdx&#39;])) . ROC AUC: 0.7889022407467154 PR AUC: 0.9347006100621323 precision recall f1-score support 0 0.54 0.40 0.46 18645 1 0.87 0.92 0.89 78623 accuracy 0.82 97268 macro avg 0.70 0.66 0.68 97268 weighted avg 0.80 0.82 0.81 97268 . Their documentation states that they have had the same goal as us: not missing non-functioning water points. They attempted to do so by optimising their model to have a high recall score. They end up with a recall score for non-functioning water points of 0.4. . cf_matrix=confusion_matrix(wpdx_prediction_df[&#39;y_real_wpdx&#39;], wpdx_prediction_df[&#39;y_prediction_wpdx&#39;]) group_names = [&#39;True Neg&#39;,&#39;False Pos&#39;,&#39;False Neg&#39;,&#39;True Pos&#39;] group_counts = [&quot;{0:0.0f}&quot;.format(value) for value in cf_matrix.flatten()] group_percentages = [&quot;{0:.2%}&quot;.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)] labels = [f&quot;{v1} n{v2} n{v3}&quot; for v1, v2, v3 in zip(group_names,group_counts,group_percentages)] labels = np.asarray(labels).reshape(2,2) ax = sns.heatmap(cf_matrix, annot=labels, fmt=&#39;&#39;, cmap=&#39;Greens&#39;) ax.set_xlabel(&#39; nPredicted Values&#39;) ax.set_ylabel(&#39;Actual Values &#39;); ax.xaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) ax.yaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) plt.show() . Similar to our models, the precision and recall score for functioning water points are very high. This is because the sample data is very balanced and has a high number of functioning water points (around 85% are functioning). . d = {&#39;Model&#39;:[&#39;WPDx&#39;], &#39;Parameters&#39;:[&#39;Unknown&#39;], &#39;Accuracy Train&#39;: [None], &#39;Precision Train&#39;: [None], &#39;Recall Train&#39;: [None], &#39;F1 Train&#39;: [None], &#39;ROC AUC Train&#39;:[None], &#39;Accuracy Test&#39;: None, &#39;Precision Test&#39;: [precision_wpdx], &#39;Recall Test&#39;: [recall_wpdx], &#39;F1 Test&#39;: [None], &#39;ROC AUC Test&#39;:[roc_auc_wpdx],&#39;Time Fit&#39;: [None], &#39;Time Predict&#39;: [None], &quot;Precision Non-functioning Test&quot;:0.54, &quot;Recall Non-functioning Test&quot;:0.40, &quot;F1 Non-functioning Test&quot;:0.46, &quot;Precision Functioning Test&quot;:0.87, &quot;Recall Functioning Test&quot;:0.92,&quot;F1 Functioning Test&quot;:0.89} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 WPDx | Unknown | None | None | None | None | None | None | [0.8083463563086034, 0.8083443858404532, 0.808... | [1.0, 0.9999872810755123, 0.9999872810755123, ... | None | 0.788902 | None | None | 0.54 | 0.4 | 0.46 | 0.87 | 0.92 | 0.89 | . best_model_result_df.to_csv(model_filepath + &#39;wpdx_model.csv&#39;) . np.save(model_filepath+f&#39;wpdx_fpr_wpdx&#39;, fpr_wpdx) np.save(model_filepath+f&#39;wpdx_tpr_wpdx&#39;, tpr_wpdx) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_16_wpdx_model_extract.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_16_wpdx_model_extract.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Neural Network",
            "content": "Neural Network . We will be running a neural network with various architectures to attempt to optimise its performance. . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.2% non-functioning water points and 80.8% functioning Original train set has 19.7% non-functioning water points and 80.3% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . X_train_res_scaled, X_test_scaled = scaling(StandardScaler(), X_train_res, X_test) . We also need to scale the data as this should improve the accuracy of our neural network. . We will be testing various neural networks with different parameters and attempt to infer which ones respond best and provide the best accuracy score on the test set. . 1. Baseline model: choosing loss function and metric . We will try running a neural network for our classification problem. Neural networks are good at identifying non-linear and complex relationships between things. Let&#39;s see if they add anything to our problem. . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . 2022-08-04 17:29:06.631191: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. . Accuracy score on Train set: 0.7586790323257446 Accuracy score on Test set: 0.7305592894554138 . We try a first model with baseline, common parameters such as the Adam optimiser, Binary cross entropy as the loss function and the binary accuracy as our metric. The model has no hidden layer and just one input and output layer. One thing we can see is that the difference between the train and test accuracy is very low. . 2. Choosing layers . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7769299745559692 Accuracy score on Test set: 0.7187572717666626 . We add a hidden layer of 16 nodes and the accuracy score for test set improves by around 3 percentage points. . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layers NN.add(layers.Dense(16, activation=&quot;relu&quot;)) NN.add(layers.Dense(8, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7799791097640991 Accuracy score on Test set: 0.7273872494697571 . We add a second hidden layer of 8 nodes, but the accuracy score does not improve. . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) # #hidden layer NN.add(layers.Dense(8, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7725886702537537 Accuracy score on Test set: 0.7399822473526001 . We look at a single hidden layer of 8 nodes instead of 16, the accuracy score is not better. . 3. Choosing optimiser . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7678698301315308 Accuracy score on Test set: 0.7461864948272705 . Using a different optimiser, SGD, does not improve our model, we will stick the Adam optimiser. . 4. Choosing regularization . #sequential model NN = keras.Sequential() #set regularization regularizer = keras.regularizers.l2(0.01) #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;, kernel_regularizer=regularizer)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;, kernel_regularizer=regularizer)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7316510081291199 Accuracy score on Test set: 0.6628259420394897 . #sequential model NN = keras.Sequential() #set regularization regularizer = keras.regularizers.l1(0.01) #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;, kernel_regularizer=regularizer)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;, kernel_regularizer=regularizer)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.646124005317688 Accuracy score on Test set: 0.6440266966819763 . Adding any kind of regulariser (l1-Lasso or l2-Ridge) hurts our neural network heavily. Regularization attempts to prevent overfitting in a model, here it does not do a good job. . 5. Choosing dropout rate . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) NN.add(layers.Dropout(0.2)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7600075602531433 Accuracy score on Test set: 0.7217894196510315 . Adding a dropout rate of 20% for our hidden layer means that 80% of nodes are taken into account when running the neural network at every epoch. Using this technique does improve our accuracy scores. . 6. Choosing batch normalization . #sequential model NN = keras.Sequential() #INPUT layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) NN.add(layers.BatchNormalization()) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7657862901687622 Accuracy score on Test set: 0.7311190962791443 . Applying batch normalization on our hidden layer also does not improve our scores. . 7. Choosing activation function . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;sigmoid&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7798120975494385 Accuracy score on Test set: 0.7426412105560303 . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;sigmoid&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;sigmoid&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7718336582183838 Accuracy score on Test set: 0.7479591369628906 . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;relu&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;relu&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7488929033279419 Accuracy score on Test set: 0.6999580264091492 . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;sigmoid&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;relu&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;relu&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7412629127502441 Accuracy score on Test set: 0.7148854732513428 . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;sigmoid&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;sigmoid&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;relu&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.5 Accuracy score on Test set: 0.19172458350658417 . We test different combinations of activation functions for our input, hidden and output layers. We see that the best combinations is using a sigmoid function for all three of these layers. The accuracy score for that model is not terrific, but better than anything else we&#39;ve gotten so far. . 8. Trying more epochs . #sequential model NN = keras.Sequential() #input layer NN.add(layers.Dense(32, activation=&quot;sigmoid&quot;)) #hidden layer NN.add(layers.Dense(16, activation=&quot;sigmoid&quot;)) #output layer NN.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #fit on training set results = NN.fit(X_train_res_scaled, y_train_res, epochs=200, verbose=0) #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Accuracy score on Train set: 0.7868831157684326 Accuracy score on Test set: 0.7378830909729004 . Optimal Model . NN_opt = keras.Sequential() #input layer NN_opt.add(layers.Dense(32, activation=&quot;sigmoid&quot;)) #hidden layer NN_opt.add(layers.Dense(16, activation=&quot;sigmoid&quot;)) #output layer NN_opt.add(layers.Dense(1, activation=&quot;sigmoid&quot;)) #compile NN_opt.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) #time process start=time.time() #fit on training set results = NN_opt.fit(X_train_res_scaled, y_train_res, epochs=50, verbose=0, validation_data=(X_test, y_test)) end=time.time() time_fit_opt=end-start #get scores from neural network train_accuracy = results.history[&quot;binary_accuracy&quot;][-1] result = NN_opt.evaluate(X_test_scaled, y_test, verbose=0) print(f&quot;Time to fit the model on the training set is {round(time_fit_opt,3)} seconds&quot;) print(f&quot;Accuracy score on Train set: {train_accuracy}&quot;) print(f&quot;Accuracy score on Test set: {result[1]}&quot;) . Time to fit the model on the training set is 201.178 seconds Accuracy score on Train set: 0.7708027958869934 Accuracy score on Test set: 0.7360638380050659 . We re-run our optimal model, it does not achieve the same accuracy score as before as the neural networks starts with random weight every time. . Analysis . plt.figure() plt.plot(results.epoch, results.history[&#39;binary_accuracy&#39;]) plt.plot(results.epoch, results.history[&#39;val_binary_accuracy&#39;]) plt.title(&#39;Binary Accuracy&#39;) plt.ylabel(&#39;Accuracy&#39;) plt.xlabel(&#39;Epoch&#39;) plt.legend([&#39;train&#39;, &#39;validation&#39;]) plt.grid() plt.show() . The highest accuracy is achieved at around the 12th epoch. It seems like our dataset and relationships are not complex enough to be needing that many epochs to achieve a high accuracy score. . plt.figure() plt.plot(results.epoch, results.history[&#39;loss&#39;]) plt.plot(results.epoch, results.history[&#39;val_loss&#39;]) plt.title(&#39;Model Loss&#39;) plt.ylabel(&#39;Loss&#39;) plt.xlabel(&#39;Epoch&#39;) plt.legend([&#39;train&#39;, &#39;validation&#39;]) plt.grid() plt.show() . Similarly the loss is minimised around the 12th epoch. . predictions_train_proba=NN_opt.predict(X_train_res_scaled) #convert to class predictions_train=np.where(predictions_train_proba&gt;0.5, 1, 0) . 4305/4305 [==============================] - 4s 749us/step . fpr_train_opt, tpr_train_opt, thresholds_roc_train_opt = roc_curve(y_train_res, predictions_train_proba) #getting precision/recall scores precision_train_opt_plot, recall_train_opt_plot, thresholds_pr_train_opt = precision_recall_curve(y_train_res, predictions_train_proba) # storing values roc_auc_train_opt = auc(fpr_train_opt, tpr_train_opt) pr_auc_train_opt = auc(recall_train_opt_plot, precision_train_opt_plot) # seeing model results print(f&#39;ROC AUC: {roc_auc_train_opt}&#39;) print(f&#39;PR AUC: {pr_auc_train_opt}&#39;) print(classification_report(y_train_res, predictions_train)) #print confusion matrix cf_matrix=confusion_matrix(y_train_res, predictions_train) group_names = [&#39;True Neg&#39;,&#39;False Pos&#39;,&#39;False Neg&#39;,&#39;True Pos&#39;] group_counts = [&quot;{0:0.0f}&quot;.format(value) for value in cf_matrix.flatten()] group_percentages = [&quot;{0:.2%}&quot;.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)] labels = [f&quot;{v1} n{v2} n{v3}&quot; for v1, v2, v3 in zip(group_names,group_counts,group_percentages)] labels = np.asarray(labels).reshape(2,2) ax = sns.heatmap(cf_matrix, annot=labels, fmt=&#39;&#39;, cmap=&#39;Greens&#39;) ax.set_xlabel(&#39; nPredicted Values&#39;) ax.set_ylabel(&#39;Actual Values &#39;); ax.xaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) ax.yaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) plt.show() . ROC AUC: 0.8581960705709735 PR AUC: 0.8654983269292414 precision recall f1-score support 0 0.77 0.77 0.77 68873 1 0.77 0.77 0.77 68873 accuracy 0.77 137746 macro avg 0.77 0.77 0.77 137746 weighted avg 0.77 0.77 0.77 137746 . All of our accuracy metrics for our train set are just under the 80% mark. . start=time.time() # prediction of our model on test set predictions_test_proba=NN_opt.predict(X_test_scaled) #convert to class predictions_test=np.where(predictions_test_proba&gt;0.5, 1, 0) end=time.time() time_predict_opt=end-start print(f&quot;Time to predict the model on the test set is {round(time_predict_opt,3)} seconds&quot;) . 670/670 [==============================] - 1s 1ms/step Time to predict the model on the test set is 0.936 seconds . We can see that the time it takes to predict a class is relatively long compared to other models. We also need to add an additional step as Keras does not enable us to directly predict the class of an observation. . fpr_test_opt, tpr_test_opt, thresholds_roc_test_opt = roc_curve(y_test, predictions_test_proba) #getting precision/recall scores precision_test_opt_plot, recall_test_opt_plot, thresholds_pr_test_opt = precision_recall_curve(y_test, predictions_test_proba) # storing values roc_auc_test_opt = auc(fpr_test_opt, tpr_test_opt) pr_auc_test_opt = auc(recall_test_opt_plot, precision_test_opt_plot) # seeing model results print(f&#39;ROC AUC: {roc_auc_test_opt}&#39;) print(f&#39;PR AUC: {pr_auc_test_opt}&#39;) print(classification_report(y_test, predictions_test)) #print confusion matrix cf_matrix=confusion_matrix(y_test, predictions_test) group_names = [&#39;True Neg&#39;,&#39;False Pos&#39;,&#39;False Neg&#39;,&#39;True Pos&#39;] group_counts = [&quot;{0:0.0f}&quot;.format(value) for value in cf_matrix.flatten()] group_percentages = [&quot;{0:.2%}&quot;.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)] labels = [f&quot;{v1} n{v2} n{v3}&quot; for v1, v2, v3 in zip(group_names,group_counts,group_percentages)] labels = np.asarray(labels).reshape(2,2) ax = sns.heatmap(cf_matrix, annot=labels, fmt=&#39;&#39;, cmap=&#39;Greens&#39;) ax.set_xlabel(&#39; nPredicted Values&#39;) ax.set_ylabel(&#39;Actual Values &#39;); ax.xaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) ax.yaxis.set_ticklabels([&#39;Not functioning&#39;,&#39;Functioning&#39;]) plt.show() . ROC AUC: 0.7834369436221573 PR AUC: 0.9328626720545525 precision recall f1-score support 0 0.39 0.66 0.49 4110 1 0.90 0.76 0.82 17327 accuracy 0.74 21437 macro avg 0.65 0.71 0.66 21437 weighted avg 0.80 0.74 0.76 21437 . The model performs relatively well in the recall for non-functioning water points. It is not &quot;missing&quot; as many of them as other models. As expected, the model performs very well for functioning water points, 90% of its functioning labels are correct. . Comparing results . plt.plot(figsize=(10,15)) plt.plot([0,1], [0,1], color=&#39;black&#39;, linestyle=&#39;--&#39;) plt.title(&#39;Receiver Operating Characteristic (ROC) Curve - NN&#39;) plt.plot(fpr_train_opt, tpr_train_opt, color=&#39;blueviolet&#39;, lw=2, label=&#39;Train AUC = %0.2f&#39; % roc_auc_train_opt) plt.plot(fpr_test_opt, tpr_test_opt, color=&#39;crimson&#39;, lw=2, label=&#39;Test AUC = %0.2f&#39; % roc_auc_test_opt) plt.xlabel(&#39;False Positive Rate&#39;) plt.ylabel(&#39;True Positive Rate&#39;) plt.legend(loc=&quot;best&quot;) plt.tight_layout() plt.grid() . The test set has a smaller, as expected, AUC compared to the train set, as it is an unseen dataset. . Similarly to our KNN model, we do not visualise the feature importance of our optimal neural network model. The reason is that we need to use SHAP, and it is computationally extremely expensive (it took nearly 10min for one run, it is recommended to run 50-100). We will consider using SHAP later on, when comparing models, if the neural network or KNN model is the best performing one. In this case, it might be worth using SHAP. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . joblib.dump(NN_opt, model_filepath+&#39;neural_network_model.sav&#39;) . INFO:tensorflow:Assets written to: ram://45c52fa5-5c0f-4151-8e9d-0ee96db1ecc4/assets . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/neural_network_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;Neural Network&#39;], &#39;Parameters&#39;:[&#39;Hidden layer=16 nodes, Optimizer=Adam, Loss function=BinaryCrossentropy, Metric=BinaryAccuracy&#39;], &#39;Accuracy Train&#39;: None, &#39;Precision Train&#39;: None, &#39;Recall Train&#39;: None, &#39;F1 Train&#39;: None, &#39;ROC AUC Train&#39;:[roc_auc_train_opt], &#39;Accuracy Test&#39;: None, &#39;Precision Test&#39;: None, &#39;Recall Test&#39;: None, &#39;F1 Test&#39;: None, &#39;ROC AUC Test&#39;:[roc_auc_test_opt], &#39;Time Fit&#39;: time_fit_opt, &#39;Time Predict&#39;: time_predict_opt, &quot;Precision Non-functioning Test&quot;:0.42, &quot;Recall Non-functioning Test&quot;:0.63, &quot;F1 Non-functioning Test&quot;:0.50, &quot;Precision Functioning Test&quot;:0.90, &quot;Recall Functioning Test&quot;:0.78,&quot;Functioning Test&quot;:0.84} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test Functioning Test . 0 Neural Network | Hidden layer=16 nodes, Optimizer=Adam, Loss fu... | None | None | None | None | 0.858196 | None | None | None | None | 0.783437 | 201.177973 | 0.935681 | 0.42 | 0.63 | 0.5 | 0.9 | 0.78 | 0.84 | . best_model_result_df.to_csv(model_filepath + &#39;neural_network_model.csv&#39;) . metrics=[fpr_train_opt, tpr_train_opt, fpr_test_opt, tpr_test_opt] metrics_name=[&#39;fpr_train_opt&#39;, &#39;tpr_train_opt&#39;, &#39;fpr_test_opt&#39;, &#39;tpr_test_opt&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;neural_network_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_15_neural_networks.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_15_neural_networks.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "AdaBoost",
            "content": "AdaBoost . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.7% non-functioning water points and 80.3% functioning Original train set has 19.5% non-functioning water points and 80.5% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . Note that we do not scale our data because AdaBoost is essentially and ensemble of decision trees: decision rules are made in isolation and do not compare different features when making a decision. It is not a distance-based model and thus does not need scaled data. . Running baseline model . start=time.time() #instantiate and fit AB_base = AdaBoostClassifier(n_estimators=100, random_state=rand_seed).fit(X_train_res, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base,3)} seconds&quot;) . Time to fit the model on the training set is 33.512 seconds . The AdaBoost classifier is much quicker than our previous models (decision tree, random forest). . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(AB_base, X_train_res, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(AB_base, X_train_res, y_train_res) . ROC AUC: 0.7774688074133068 PR AUC: 0.784960413878645 precision recall f1-score support 0 0.69 0.75 0.72 68984 1 0.72 0.66 0.69 68984 accuracy 0.70 137968 macro avg 0.71 0.70 0.70 137968 weighted avg 0.71 0.70 0.70 137968 . Our training set has an accuracy score of 70%, this is very low for a training set and does not bode well for the test set scores. The model has an especially low precision score for its non-functioning labels. It labelled a lot of functioning points as non-functioning. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(AB_base, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(AB_base, X_test, y_test) . ROC AUC: 0.7087672475822341 PR AUC: 0.9061790563962455 precision recall f1-score support 0 0.32 0.64 0.42 4221 1 0.88 0.66 0.76 17216 accuracy 0.66 21437 macro avg 0.60 0.65 0.59 21437 weighted avg 0.77 0.66 0.69 21437 . Time to predict the outcome variable for the test set is 0.301 seconds . Our test set also has a low accuracy score of 66%. Similarly to the training set, its precision score for non-functioning points is incredibly low (only a third of points labelled as non-functioning actually were truly non-functioning). However, the points labelled as functioning are right 87% of the time. . Narrowing down parameters . # set range of sample leaf learning_rate_range = np.arange(0.1, 5, 0.5) #empty dataframe to store accuracy scores accuracy_scores = pd.DataFrame() for lr in learning_rate_range: #instantiate and fit AB = AdaBoostClassifier(learning_rate=lr, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = AB.score(X_train_res, y_train_res) test_score = AB.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Learning rate&#39;: lr, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between min sample leaf and accuracy plt.figure() plt.plot(accuracy_scores[&#39;Learning rate&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Learning rate&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Learning rate&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Ideal learning rate is less than 1.5&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . The learning rate tells the model how quickly it sould adapt to its errors. If the learning rate is high, it will make larger jumps after making an error. . We see that a learning rate of more than 1.5 becomes counterproductive as the accuracy scores fall. This is because if the learning rate is too high, usually lead to overfitting the training set. . # set range of depth max n_estimators_range = [2, 50, 100, 200] #empty dataframe to store results accuracy_scores = pd.DataFrame() #for gini for n_est in n_estimators_range: #instantiate and fit AB = AdaBoostClassifier(n_estimators=n_est, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = AB.score(X_train_res, y_train_res) test_score = AB.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Number trees&#39;: n_est, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between number of trees and accuracy scores plt.figure() plt.plot(accuracy_scores[&#39;Number trees&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Number trees&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Number of trees&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Higher number of trees improves accuracy but risks overfitting&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . AdaBoost is an ensemble of decision trees. After calculating each tree, adaboost tweaks its loss function to try to correct for the mistakes (misclassifications) its made in the previous tree. The idea is that the more trees you have the more precise the model will become as it will find a way to classify correctly as many points as possible. We clearly see, here, that the more trees the model has, the more accurate. However, we should consider that this is computationally very expensive. This is especially expensive if we run grid searches or train on large amounts of data. In adittion, the more trees we have, the larger the chance is that we are overfitting our training set. As a result, we choose to stick to the default number of trees (50) as it has acceptable accuracy scores and will enable us to optimise other hyperparameters more quickly. . Finding optimal hyperparameters . We run a randomised cross validation through a pipeline to find the optimal hyperparameters. We choose a randomised as opposed to a grid search because adaboost models are very expensive. For the same reasons mentioned above, we stick to the default number of trees, 50. . learning_rate_range = np.arange(0.1, 1.5, 0.1) # setting up which models/scalers we want to grid search estimator = [(&#39;reduce_dim&#39;, PCA()), (&#39;AB&#39;, AdaBoostClassifier(n_estimators=100, random_state=rand_seed))] # defining distribution of parameters we want to compare param_distrib = {&#39;AB__learning_rate&#39;: learning_rate_range, &#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_random(estimator, param_distrib, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;reduce_dim__n_components&#39;: None, &#39;AB__learning_rate&#39;: 1.1}. The best model has an accuracy score of 0.6783598451275832 on the test set . The best model has a learning rate of 1.1, note that the default learning rate is 1 in our baseline model. Let&#39;s see how that improves our accuracy. . Note how the time it took to run a randomised cross validation was extremely high, even when setting the number of trees to 50. . Running optimised model . start=time.time() #instantiate and fit AB_opt = AdaBoostClassifier(learning_rate=1.1, random_state=rand_seed).fit(X_train_res, y_train_res) end=time.time() time_fit_opt=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_opt, 3)} seconds&quot;) . Time to fit the model on the training set is 15.508 seconds . The time to fit the model is similar to the baseline model. The only thing we really changed here is to increase the learning rate from 1 to 1.3. . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(AB_opt, X_train_res, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(AB_opt, X_train_res, y_train_res) . ROC AUC: 0.7650327333389693 PR AUC: 0.7714155442434323 precision recall f1-score support 0 0.68 0.74 0.71 68984 1 0.72 0.65 0.68 68984 accuracy 0.70 137968 macro avg 0.70 0.70 0.70 137968 weighted avg 0.70 0.70 0.70 137968 . The baseline and optimised model on our training set are near identical. It seems that the increased learning rate did not have a large effect on our accuracy metrics. . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(AB_opt, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(AB_opt, X_test, y_test) . ROC AUC: 0.6966180820869101 PR AUC: 0.9014353303111194 precision recall f1-score support 0 0.31 0.63 0.41 4221 1 0.88 0.65 0.75 17216 accuracy 0.65 21437 macro avg 0.59 0.64 0.58 21437 weighted avg 0.77 0.65 0.68 21437 . Time to predict the outcome variable for the test set is 0.152 seconds . Similarly to the training set, the baseline has a very slight edge in that it has a higher recall score for non-functioning water points. This means that it is identifying a larger number of non-functioning water points, which is preferable. The time it took the predict the outcome variable and all other accuracy scores on the test are nearly the same in the baseline and optimised model. . Comparing results . plot_curve_roc(&#39;AB&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . The optimised and baseline model have near identical AUCs. We go with the baseline model with a learning rate of 1 as it performs very slightly better on its recall score for non-functioning water points. . Visualising feature importance . coeff_bar_chart(AB_base.feature_importances_, X.columns, t=False) . For the first time, the number of conflicts/violent events becomes an important feature in a model. Maybe the fact that this is a boosting model enables it to find more hidden links with water point functionality. This is definitely something we should explore next with a more powerful boosting method, XGBoost. We see that most demographic variables are not given any importance in the model. It is mostly water point features such as usage capacity, crucialness and public management. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . joblib.dump(AB_base, model_filepath+&#39;adaboost_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/adaboost_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;AdaBoost&#39;], &#39;Parameters&#39;:[&#39;Learning rate=1, Number of trees=50&#39;], &#39;Accuracy Train&#39;: [accuracy_train_base], &#39;Precision Train&#39;: [precision_train_base], &#39;Recall Train&#39;: [recall_train_base], &#39;F1 Train&#39;: [f1_train_base], &#39;ROC AUC Train&#39;:[roc_auc_train_base], &#39;Accuracy Test&#39;: accuracy_test_base, &#39;Precision Test&#39;: [precision_test_base], &#39;Recall Test&#39;: [recall_test_base], &#39;F1 Test&#39;: [f1_test_base], &#39;ROC AUC Test&#39;:[roc_auc_test_base],&#39;Time Fit&#39;: time_fit_base, &#39;Time Predict&#39;: time_predict_test_base, &quot;Precision Non-functioning Test&quot;:0.32, &quot;Recall Non-functioning Test&quot;:0.64, &quot;F1 Non-functioning Test&quot;:0.42, &quot;Precision Functioning Test&quot;:0.88, &quot;Recall Functioning Test&quot;:0.66,&quot;F1 Functioning Test&quot;:0.76} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 AdaBoost | Learning rate=1, Number of trees=50 | 0.704895 | 0.706307 | 0.704895 | 0.70439 | 0.777469 | 0.657461 | 0.769839 | 0.657461 | 0.690728 | 0.708767 | 33.512388 | 0.300903 | 0.32 | 0.64 | 0.42 | 0.88 | 0.66 | 0.76 | . best_model_result_df.to_csv(model_filepath + &#39;adaboost_model.csv&#39;) . metrics=[fpr_train_base, tpr_train_base, fpr_test_base, tpr_test_base] metrics_name=[&#39;fpr_train_base&#39;, &#39;tpr_train_base&#39;, &#39;fpr_test_base&#39;, &#39;tpr_test_base&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;adaboost_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_13_adaboost.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_13_adaboost.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Support Vector Machine",
            "content": "Support Vector Machine . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.7% non-functioning water points and 80.3% functioning Original train set has 19.5% non-functioning water points and 80.5% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . X_train_res_scaled, X_test_scaled = scaling(StandardScaler(), X_train_res, X_test) . We need to scale our data to prevent features with bigger scales to bias our estimates. . Running baseline model . start=time.time() #instantiate and fit SVC_base = LinearSVC(max_iter=500, random_state=rand_seed).fit(X_train_res_scaled, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base, 3)} seconds&quot;) print(f&quot;Accuracy score for train set is is: {SVC_base.score(X_train_res_scaled, y_train_res)}&quot;) print(f&quot;Accuracy score for test set is is:{SVC_base.score(X_test_scaled, y_test)}&quot;) . Time to fit the model on the training set is 24.858 seconds Accuracy score for train set is is: 0.6506798677954309 Accuracy score for test set is is:0.6219620282688809 . Accuracy score for our baseline model is low, at 62%. SVMs are margin margin classifiers: they try to pick a decision boundary which is as far apart from the two classes as possible. It makes that decision boundary more generalisable and hopefully better on unseen datasets. . SVC_base_clf = LinearSVC(max_iter=500, random_state=rand_seed) #get probabilities CLF_base = CalibratedClassifierCV(SVC_base_clf).fit(X_train_res_scaled, y_train_res) . We convert the SVM&#39;s decision rule into probabilities using the Calibrated Classifier. It uses cross validation to estimate the probabilities of each observation being a 1 (functioning water point). . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(CLF_base, X_train_res_scaled, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(CLF_base, X_train_res_scaled, y_train_res) . ROC AUC: 0.7104575976682433 PR AUC: 0.7071331417357499 precision recall f1-score support 0 0.65 0.65 0.65 68984 1 0.65 0.66 0.65 68984 accuracy 0.65 137968 macro avg 0.65 0.65 0.65 137968 weighted avg 0.65 0.65 0.65 137968 . This conversion enables us to calculate the confusion matrix and accuracy metrics for a SVM model. Here the training set is equally divided between predicted functioning and non-functioning. As our dataset is perfectly balanced, there is an equal proportion of TP/TF and FP/FN. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(CLF_base, X_test_scaled, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(CLF_base, X_test_scaled, y_test) . ROC AUC: 0.6407327354641204 PR AUC: 0.870834632919976 precision recall f1-score support 0 0.28 0.55 0.37 4221 1 0.85 0.65 0.74 17216 accuracy 0.63 21437 macro avg 0.57 0.60 0.55 21437 weighted avg 0.74 0.63 0.67 21437 . Time to predict the outcome variable for the test set is 0.019 seconds . The model performs badly on the test set. We clearly see that the way in which our model classifies water points is not accurate. Only two thirds of total functioning water points are correctly identified. . Narrowing down parameters . # set range of penalties c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000] accuracy_scores = pd.DataFrame() for c in c_range: #instantiate and fit SVC = LinearSVC(C=c, max_iter=500, random_state=rand_seed).fit( X_train_res_scaled, y_train_res) # store accuracy scores train_score = SVC.score(X_train_res_scaled, y_train_res) test_score = SVC.score(X_test_scaled, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Penalty&#39;: c, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between penalty and accuracy plt.figure() plt.plot(accuracy_scores[&#39;Penalty&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Penalty&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xscale(&#39;log&#39;) plt.xlabel(&#39;Penalty&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Increasing the penalty reduces accuracy score dramatically&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . We see that increasing the penalty (meaning we prevent overfitting and make our model more general) hurts the accuracy scores for the train and test scores. There is an especially big drop when the penalty gets larger than 1. . Finding optimal hyperparameters . We run a grid search cross validation to attempt to find the best combination of hyperparameters for our model. . estimator = [(&#39;scaler&#39;, StandardScaler()), (&#39;SVC&#39;, LinearSVC(max_iter=500))] # defining distribution of parameters we want to compare param = {&quot;SVC__C&quot;: c_range, &quot;SVC__penalty&quot;:[&#39;l1&#39;, &#39;l2&#39;]} # run cross validation pipeline_cross_val_grid(estimator, param, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;SVC__C&#39;: 0.001, &#39;SVC__penalty&#39;: &#39;l2&#39;}. The best model has an accuracy score of 0.6236880160470215 on the test set . The optimal model has a penalty of 0.001, using the Ridge regularisation. The penalty added to the cost function is the coefficients squared (Ridge), as opposed to taking their absolute value (Lasso). This penalty is very small and we expect it not to affect our model too strongly. . Running optimised model . start=time.time() #instantiate and fit SVC_opt = LinearSVC(max_iter=500, C=0.001, penalty=&#39;l2&#39;, random_state=rand_seed).fit(X_train_res_scaled, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base, 3)} seconds&quot;) print(f&quot;Accuracy score for train set is is: {SVC_opt.score(X_train_res_scaled, y_train_res)}&quot;) print(f&quot;Accuracy score for test set is is:{SVC_opt.score(X_test_scaled, y_test)}&quot;) . Time to fit the model on the training set is 1.171 seconds Accuracy score for train set is is: 0.6506073872202249 Accuracy score for test set is is:0.6236880160470215 . The accuracy score on the test very slightly increases. Let&#39;s see if it improves any of our precision/recall scores. The fitting time is substantially reduced (15x shorter!). . SVC_opt_clf = LinearSVC(max_iter=500, C=0.001, penalty=&#39;l2&#39;, random_state=rand_seed) #get probabilities CLF_opt = CalibratedClassifierCV(SVC_opt_clf).fit(X_train_res_scaled, y_train_res) . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(CLF_opt, X_train_res_scaled, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(CLF_opt, X_train_res_scaled, y_train_res) . ROC AUC: 0.7103580646408449 PR AUC: 0.7070612637150856 precision recall f1-score support 0 0.65 0.65 0.65 68984 1 0.65 0.66 0.65 68984 accuracy 0.65 137968 macro avg 0.65 0.65 0.65 137968 weighted avg 0.65 0.65 0.65 137968 . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(CLF_opt, X_test_scaled, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(CLF_opt, X_test_scaled, y_test) . ROC AUC: 0.6401459218996186 PR AUC: 0.8706500211846758 precision recall f1-score support 0 0.28 0.55 0.37 4221 1 0.85 0.65 0.74 17216 accuracy 0.63 21437 macro avg 0.57 0.60 0.55 21437 weighted avg 0.74 0.63 0.67 21437 . Time to predict the outcome variable for the test set is 0.007 seconds . Both of the training and test set all perform exactly the same. It seems that our data is not ideal for a linear SVC. Overall accuracy scores are very low. . Comparing results . plot_curve_roc(&#39;SVC&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . As seen above the performance of the baseline and optimised model is the same. We go with the baseline one in the hope that it more generalisable to other datasets. . Exporting . joblib.dump(SVC_base, model_filepath+&#39;support_vector_machine_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/support_vector_machine_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;Linear SVC&#39;], &#39;Parameters&#39;:[&#39;Penalty=l2, C=0.001, Standard Scaler&#39;], &#39;Accuracy Train&#39;: [accuracy_train_base], &#39;Precision Train&#39;: [precision_train_base], &#39;Recall Train&#39;: [recall_train_base], &#39;F1 Train&#39;: [f1_train_base], &#39;ROC AUC Train&#39;:[roc_auc_train_base], &#39;Accuracy Test&#39;: accuracy_test_base, &#39;Precision Test&#39;: [precision_test_base], &#39;Recall Test&#39;: [recall_test_base], &#39;F1 Test&#39;: [f1_test_base], &#39;ROC AUC Test&#39;:[roc_auc_test_base],&#39;Time Fit&#39;: time_fit_base, &#39;Time Predict&#39;: time_predict_test_base, &quot;Precision Non-functioning Test&quot;:0.28, &quot;Recall Non-functioning Test&quot;:0.55, &quot;F1 Non-functioning Test&quot;:0.37,&quot;Precision Functioning Test&quot;:0.85, &quot;Recall Functioning Test&quot;:0.65,&quot;F1 Functioning Test&quot;:0.74} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 Linear SVC | Penalty=l2, C=0.001, Standard Scaler | 0.6521 | 0.65212 | 0.6521 | 0.652089 | 0.710458 | 0.631198 | 0.74105 | 0.631198 | 0.666512 | 0.640733 | 1.170683 | 0.019465 | 0.28 | 0.55 | 0.37 | 0.85 | 0.65 | 0.74 | . best_model_result_df.to_csv(model_filepath + &#39;support_vector_machine_model.csv&#39;) . metrics=[fpr_train_base, tpr_train_base, fpr_test_base, tpr_test_base] metrics_name=[&#39;fpr_train_base&#39;, &#39;tpr_train_base&#39;, &#39;fpr_test_base&#39;, &#39;tpr_test_base&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;support_vector_machine_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_12_support_vector_machine.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_12_support_vector_machine.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Naive Bayes",
            "content": "Gaussian Naive Bayes . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.7% non-functioning water points and 80.3% functioning Original train set has 19.5% non-functioning water points and 80.5% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . Note that we do not scale our data because the estimator in a Gaussian Naive Bayes computes the mean and standard deviation of a feature, then assumes that this feature follows a Normal distribution. It then uses the distance of each observation from the mean of that distribution to calculate the conditional probability of that observation with that feature value to be in a certain class. . Running baseline model . start=time.time() #instantiate and fit GNB_base = GaussianNB().fit(X_train_res, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base,3)} seconds&quot;) . Time to fit the model on the training set is 0.14 seconds . We use a Gaussian Naive Bayes as it can deal with our features being continuous variables. . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(GNB_base, X_train_res, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(GNB_base, X_train_res, y_train_res) . ROC AUC: 0.6588822704010048 PR AUC: 0.6412104746168411 precision recall f1-score support 0 0.63 0.54 0.58 68984 1 0.60 0.68 0.64 68984 accuracy 0.61 137968 macro avg 0.61 0.61 0.61 137968 weighted avg 0.61 0.61 0.61 137968 . Our training set has a relatively low accuracy metrics. It has an especially high number of False Positives. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(GNB_base, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(GNB_base, X_test, y_test) . ROC AUC: 0.6154788215939245 PR AUC: 0.8574385395873867 precision recall f1-score support 0 0.27 0.47 0.34 4221 1 0.84 0.69 0.75 17216 accuracy 0.64 21437 macro avg 0.55 0.58 0.55 21437 weighted avg 0.73 0.64 0.67 21437 . Time to predict the outcome variable for the test set is 0.028 seconds . Suprisingly our test set has a better accuracy score of 64%. However, it achieves this by having a very low precision score for non-functioning points. It mislabelled a lot of functioning points as non-functioning. . Finding optimal hyperparameters . We run a grid search cross validation through a pipeline to find the optimal hyperparameters. The grid search looks at every combination of hyperparameters to find the one with the best cross-validation score. . # setting up which models/scalers we want to grid search estimator = [(&#39;reduce_dim&#39;, PCA()), (&#39;GNB&#39;, GaussianNB())] # defining distribution of parameters we want to compare param = {&#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_grid(estimator, param, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;reduce_dim&#39;: None}. The best model has an accuracy score of 0.6423473433782713 on the test set . We only test dimensionality reduction using PCA, and the best model is where we do not apply it. As a result, we do not have an optimised model to compare with, as the baseline was already the best we could find. . Comparing results . plt.plot(figsize=(10,15)) plt.plot([0,1], [0,1], color=&#39;black&#39;, linestyle=&#39;--&#39;) plt.title(&#39;Receiver Operating Characteristic (ROC) Curve - GNB&#39;) plt.plot(fpr_train_base, tpr_train_base, color=&#39;blueviolet&#39;, lw=2, label=&#39;Train AUC = %0.2f&#39; % roc_auc_train_base) plt.plot(fpr_test_base, tpr_test_base, color=&#39;crimson&#39;, lw=2, label=&#39;Test AUC = %0.2f&#39; % roc_auc_test_base) plt.xlabel(&#39;False Positive Rate&#39;) plt.ylabel(&#39;True Positive Rate&#39;) plt.legend(loc=&quot;best&quot;) plt.tight_layout() plt.grid() . Overall, although the test has a better accuracy score than the train set, it has a lower AUC. This is because when we look at various thresholds, the training set still performs better on the whole. It seems that the test set performed especially well for the specific threshold level we looked at. . Visualising feature importance . imps = permutation_importance(GNB_base, X_test, y_test) #visualising coefficient importance coeff_bar_chart(imps.importances_mean, X.columns, t=False) . We see that water points which are installed after 2006 and those that are in regions with a high rate of access to toilets increases the probability of that water point functioning. . It is peculiar, however, that high rates of electricity access, bank account ownership and house ownership are associated with a water point not functioning. This may show the limitation of naive bayes in taking into many other features at the same time to identify patterns in the data. . Similarly to previous models the number of conflicts/violent events are not very important in our model. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . joblib.dump(GNB_base, model_filepath+&#39;gaussian_naive_bayes_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/gaussian_naive_bayes_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;Gaussian Naive Bayes&#39;], &#39;Parameters&#39;:[&#39;&#39;], &#39;Accuracy Train&#39;: [accuracy_train_base], &#39;Precision Train&#39;: [precision_train_base], &#39;Recall Train&#39;: [recall_train_base], &#39;F1 Train&#39;: [f1_train_base], &#39;ROC AUC Train&#39;:[roc_auc_train_base], &#39;Accuracy Test&#39;: accuracy_test_base, &#39;Precision Test&#39;: [precision_test_base], &#39;Recall Test&#39;: [recall_test_base], &#39;F1 Test&#39;: [f1_test_base], &#39;ROC AUC Test&#39;:[roc_auc_test_base],&#39;Time Fit&#39;: time_fit_base, &#39;Time Predict&#39;: time_predict_test_base, &quot;Precision Non-functioning Test&quot;:0.27, &quot;Recall Non-functioning Test&quot;:0.47, &quot;F1 Non-functioning Test&quot;:0.34, &quot;Precision Functioning Test&quot;:0.84, &quot;Recall Functioning Test&quot;:0.69,&quot;F1 Functioning Test&quot;:0.75} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 Gaussian Naive Bayes | | 0.612033 | 0.614446 | 0.612033 | 0.609977 | 0.658882 | 0.642347 | 0.727009 | 0.642347 | 0.673018 | 0.615479 | 0.140393 | 0.028196 | 0.27 | 0.47 | 0.34 | 0.84 | 0.69 | 0.75 | . best_model_result_df.to_csv(model_filepath + &#39;gaussian_naive_bayes_model.csv&#39;) . metrics=[fpr_train_base, tpr_train_base, fpr_test_base, tpr_test_base] metrics_name=[&#39;fpr_train_base&#39;, &#39;tpr_train_base&#39;, &#39;fpr_test_base&#39;, &#39;tpr_test_base&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;gaussian_naive_bayes_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_11_gaussian_naive_bayes.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_11_gaussian_naive_bayes.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Random Forest",
            "content": "Random Forest . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.7% non-functioning water points and 80.3% functioning Original train set has 19.5% non-functioning water points and 80.5% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . Note that we do not scale our data as random forest is not a distance-based ML model. . Running baseline model . start=time.time() #instantiate and fit RF_base = RandomForestClassifier(random_state=rand_seed).fit(X_train_res, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base,3)} seconds&quot;) . Time to fit the model on the training set is 39.165 seconds . We can already see that random forests are potentially very expensive. They are essentially multiple decision tress, which are already expensive by themselves. . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(RF_base, X_train_res, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(RF_base, X_train_res, y_train_res) . ROC AUC: 0.9999471663215214 PR AUC: 0.999946859354941 precision recall f1-score support 0 1.00 1.00 1.00 68984 1 1.00 1.00 1.00 68984 accuracy 1.00 137968 macro avg 1.00 1.00 1.00 137968 weighted avg 1.00 1.00 1.00 137968 . As expected, our training set has close to perfect accuracy metrics. Random forests are composed of muktiple decision trees, which continue to make decision rules to be able to put all (or close to all) observations in the right classification bucket. For example, we only end up with 80 water points misclassified, representing less than 0.1% of the training dataset. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(RF_base, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(RF_base, X_test, y_test) . ROC AUC: 0.8150178916005915 PR AUC: 0.9410516490791991 precision recall f1-score support 0 0.52 0.56 0.54 4221 1 0.89 0.87 0.88 17216 accuracy 0.81 21437 macro avg 0.70 0.71 0.71 21437 weighted avg 0.82 0.81 0.81 21437 . Time to predict the outcome variable for the test set is 0.527 seconds . Our test set has an accuracy score of 81%. This is a very good score for a first run, baseline model. The precision and recall scores for non-functioning water points is quite low though while those for functioning points is close to 90%. . Narrowing down parameters . We have seen in the decision tree model, that the choice of criterion (gini-purity or entropy-information gain) does not yield very different results. As a result, for this exploratory analysis we will not differentiate between the two. . # set range of sample leaf m_sample_leaf = [2**i for i in range(1,8,1)] #empty dataframe to store accuracy scores accuracy_scores = pd.DataFrame() for msf in m_sample_leaf: #instantiate and fit RF = RandomForestClassifier(n_estimators=50, min_samples_leaf=msf, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = RF.score(X_train_res, y_train_res) test_score = RF.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Min sample leaf&#39;: msf, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between min sample leaf and accuracy plt.figure() plt.plot(accuracy_scores[&#39;Min sample leaf&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Min sample leaf&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Minimum sample per leaf&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Increasing minimum samples per leaf decreases accuracy&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . As the minimum sample per leaf increases, the model accuracy decreases. This has the same shape and trend than single decision trees. Higher minimum samples per leaf might, however, prevent overfitting as it is more general and does not perfectly match the training set. . # set range of depth max m_depth = [2**i for i in range(1, 8,1)] #empty dataframe to store accuracy scores accuracy_scores = pd.DataFrame() for md in m_depth: #instantiate and fit RF = RandomForestClassifier(max_depth=md, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = RF.score(X_train_res, y_train_res) test_score = RF.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Max depth&#39;: md, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between accuracy and max depth plt.figure() plt.plot(accuracy_scores[&#39;Max depth&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Max depth&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Maximum depth&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Benefits of increasing max depth stop after 32&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . After the maximum depth passes the 32 mark, the model starts overfitting. As the max depth increases after 32, it seems the model does not need that big of a depth. This might make sense as we only have 32 features and the model is making one decision rule for each feature. . # set range of depth max n_estimators_range = [2, 4, 16, 25, 50, 100] #empty dataframe to store results accuracy_scores = pd.DataFrame() #for gini for n_est in n_estimators_range: #instantiate and fit RF = RandomForestClassifier(n_estimators=n_est, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = RF.score(X_train_res, y_train_res) test_score = RF.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Number trees&#39;: n_est, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between number of trees and accuracy scores plt.figure() plt.plot(accuracy_scores[&#39;Number trees&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Number trees&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Number of trees&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;More than 25 trees does not increase accuracy&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . A random forest is an ensemble of decision trees. Each of these trees are labelling each observation in a certain way. Then the random forest averages/takes a vote for each observation to make its final classification decision. We are looking at the number of decision trees that the random forest is running. It seems that after 25 trees, accuracy scores start to stagnate around 82% for the test set. . Finding optimal hyperparameters . We run a randomised cross validation through a pipeline to find the optimal hyperparameters. We choose a randomised as opposed to a grid search because decision trees and random forest models are very expensive. . max_depth_range = range(0,40,1) min_samples_leaf_range = range(1,50,1) # setting up which models/scalers we want to grid search estimator = [(&#39;reduce_dim&#39;, PCA()), (&#39;RF&#39;, RandomForestClassifier(n_estimators=25, random_state=rand_seed))] # defining distribution of parameters we want to compare param_dist = {&quot;RF__criterion&quot;: [&#39;gini&#39;, &#39;entropy&#39;], &#39;RF__max_depth&#39;: max_depth_range, &#39;RF__min_samples_leaf&#39;: min_samples_leaf_range, &#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_random(estimator, param_dist, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;reduce_dim__n_components&#39;: None, &#39;RF__min_samples_leaf&#39;: 29, &#39;RF__max_depth&#39;: 38, &#39;RF__criterion&#39;: &#39;gini&#39;}. The best model has an accuracy score of 0.7790269160796753 on the test set . The best model has a max depth of 31 (vs 32 for the previous individual decision tree model) and minimum samples per leaf of 11, similar to our previous decision tree (9). It also chose the &#39;entropy&#39; criterion, just like the individual decision tree. . Running optimised model . start=time.time() #instantiate and fit RF_opt = RandomForestClassifier(bootstrap=True, oob_score=True, min_samples_leaf=11, max_depth=31, n_estimators=100, criterion=&#39;entropy&#39;, random_state=rand_seed).fit(X_train_res, y_train_res) end=time.time() time_fit_opt=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_opt, 3)} seconds&quot;) . Time to fit the model on the training set is 52.538 seconds . The time to fit the model is shorter compared to the baseline model. We set the bootstrap and oob_score parameters to True so we can extract the importance of individual features later on. . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(RF_opt, X_train_res, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(RF_opt, X_train_res, y_train_res) . ROC AUC: 0.9664984154752732 PR AUC: 0.96806732148952 precision recall f1-score support 0 0.89 0.91 0.90 68984 1 0.91 0.89 0.90 68984 accuracy 0.90 137968 macro avg 0.90 0.90 0.90 137968 weighted avg 0.90 0.90 0.90 137968 . The various accuracy metrics for the training set have all decreased (down to around 94%) compared to the baseline model (all at 100%). This is a good sign because the baseline model was hugely overfitting the training set while the optimised model i hopefully not. . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(RF_opt, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(RF_opt, X_test, y_test) . ROC AUC: 0.8232286784236897 PR AUC: 0.9453738479171763 precision recall f1-score support 0 0.48 0.62 0.54 4221 1 0.90 0.83 0.87 17216 accuracy 0.79 21437 macro avg 0.69 0.73 0.70 21437 weighted avg 0.82 0.79 0.80 21437 . Time to predict the outcome variable for the test set is 0.515 seconds . The accuracy score is slightly lower for our optimised model. It has worsened its precision score for non-functioning points while improving its recall score. This means it is getting better at identifying more non-functioning water points, at the expense of labelling more functioning water points as functioning. As a result, we go with the optimised model as the recall score for non-functioning water points is what we care most about. . Comparing results . plot_curve_roc(&#39;RF&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . The optimised model has a worse AUC on the train set because it is being prevented from overfitting. We are more concerned with the test set AUC. Here the optimised model performs the same as the baseline model. . Visualising feature importance . coeff_bar_chart(RF_opt.feature_importances_, X.columns, t=False) . We see a water points&#39; importance to their crucial to their communities and the proportion of the community being served by the community are two very important features for the decision tree&#39;s splitting. The latitude and longitude of the points are also very important, which is probably why the region dummy columns are not given much importance. We see, notably, that the number of conflicts/violent events are not very important for our model. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . #joblib.dump(RF_opt, model_filepath+&#39;random_forest_model.sav&#39;) . d = {&#39;Model&#39;:[&#39;Random Forest&#39;], &#39;Parameters&#39;:[&#39;Max depth=31, Min samples leaf=11, Criterion=entropy, Number trees=100&#39;], &#39;Accuracy Train&#39;: [accuracy_train_opt], &#39;Precision Train&#39;: [precision_train_opt], &#39;Recall Train&#39;: [recall_train_opt], &#39;F1 Train&#39;: [f1_train_opt], &#39;ROC AUC Train&#39;:[roc_auc_train_opt], &#39;Accuracy Test&#39;: accuracy_test_opt, &#39;Precision Test&#39;: [precision_test_opt], &#39;Recall Test&#39;: [recall_test_opt], &#39;F1 Test&#39;: [f1_test_opt], &#39;ROC AUC Test&#39;:[roc_auc_test_opt],&#39;Time Fit&#39;: time_fit_opt, &#39;Time Predict&#39;: time_predict_test_opt, &quot;Precision Non-functioning Test&quot;:0.48, &quot;Recall Non-functioning Test&quot;:0.62, &quot;F1 Non-functioning Test&quot;:0.54, &quot;Precision Functioning Test&quot;:0.90, &quot;Recall Functioning Test&quot;:0.83,&quot;F1 Functioning Test&quot;:0.87} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 Random Forest | Max depth=31, Min samples leaf=11, Criterion=e... | 0.897099 | 0.897332 | 0.897099 | 0.897084 | 0.966498 | 0.792881 | 0.817337 | 0.792881 | 0.802324 | 0.823229 | 52.53848 | 0.515494 | 0.48 | 0.62 | 0.54 | 0.9 | 0.83 | 0.87 | . best_model_result_df.to_csv(model_filepath + &#39;random_forest_model.csv&#39;) . metrics=[fpr_train_opt, tpr_train_opt, fpr_test_opt, tpr_test_opt] metrics_name=[&#39;fpr_train_opt&#39;, &#39;tpr_train_opt&#39;, &#39;fpr_test_opt&#39;, &#39;tpr_test_opt&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;random_forest_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_10_random_forest.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_10_random_forest.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Decision Tree",
            "content": "Decision Tree . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.7% non-functioning water points and 80.3% functioning Original train set has 19.5% non-functioning water points and 80.5% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . Note that we do not scale our data as decision tree is not a distance-based ML model. . Running baseline model . start=time.time() #instantiate and fit DT_base = DecisionTreeClassifier(random_state=rand_seed).fit(X_train_res, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base,3)} seconds&quot;) . Time to fit the model on the training set is 3.921 seconds . We can already see that decision trees are potentially very expensive. . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(DT_base, X_train_res, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(DT_base, X_train_res, y_train_res) . ROC AUC: 0.9999970581821507 PR AUC: 0.999997061944803 precision recall f1-score support 0 1.00 1.00 1.00 68984 1 1.00 1.00 1.00 68984 accuracy 1.00 137968 macro avg 1.00 1.00 1.00 137968 weighted avg 1.00 1.00 1.00 137968 . As expected, our training set has close to perfect accuracy metrics. Decision trees continue to make decision rules to be able to put all (or close to all) observations in the right classification bucket. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(DT_base, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(DT_base, X_test, y_test) . ROC AUC: 0.6808847273743691 PR AUC: 0.921920345028445 precision recall f1-score support 0 0.42 0.54 0.48 4221 1 0.88 0.82 0.85 17216 accuracy 0.76 21437 macro avg 0.65 0.68 0.66 21437 weighted avg 0.79 0.76 0.78 21437 . Time to predict the outcome variable for the test set is 0.019 seconds . Our test set has an accuracy score of 77%. The precision and recall scores for non-functioning water points are especially low. The model only got 43% of its non-functioning predictions correct (precision). In addition, it only identified 55% of all non-functioning points (recall). . Narrowing down parameters . We have tried to see if the behaviour of our model changes based on which criterion it chooses: gini (purity) and entropy (information gain). The criterion is the metric that the model looks at when deciding how and whether to split a sample and make a decision rule/leaf. Overall, we see no significant difference between the two criterions. Sometimes, the graph only shows one of them, that is just because they superimposed and one is just hiding the curve. This is a good representation of how similar they are. . # set range of min sample leaf m_sample_leaf = [2**i for i in range(1,8,1)] #testing for two criterions, gini and entropy accuracy_scores_gini = pd.DataFrame() accuracy_scores_entropy = pd.DataFrame() #for gini for msf in m_sample_leaf: #instantiate and fit DT = DecisionTreeClassifier(min_samples_leaf=msf, criterion=&#39;gini&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_gini = accuracy_scores_gini.append( {&#39;Min sample leaf&#39;: msf, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) #for entropy for msf in m_sample_leaf: #instantiate and fit DT = DecisionTreeClassifier(min_samples_leaf=msf, criterion=&#39;gini&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_entropy = accuracy_scores_entropy.append( {&#39;Min sample leaf&#39;: msf, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between accuracy and max depth and criterion plt.figure() plt.plot(accuracy_scores_entropy[&#39;Min sample leaf&#39;], accuracy_scores_entropy[&#39;Train_score&#39;], label=&#39;train score entropy&#39;, color=&#39;red&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_entropy[&#39;Min sample leaf&#39;], accuracy_scores_entropy[&#39;Test_score&#39;], label=&#39;test score entropy&#39;, color=&#39;indianred&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Min sample leaf&#39;], accuracy_scores_gini[&#39;Train_score&#39;], label=&#39;train score gini&#39;, color=&#39;royalblue&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Min sample leaf&#39;], accuracy_scores_gini[&#39;Test_score&#39;], label=&#39;test score gini&#39;, color=&#39;navy&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Minimum sample per leaf&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Higher minimum sample per leaf hurts accuracy&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . As the minimum sample per leaf increases, the model accuracy decreases. The higher this number is, the more restrictive the model is and the less leaves it can create, and thus classify each observation in their correct &quot;buckets&quot;. This might be able to prevent overfitting as it is more general and does not perfectly match the training set. . # set range of depth max m_depth = [2**i for i in range(1, 8,1)] #testing for two criterions, gini and entropy accuracy_scores_gini = pd.DataFrame() accuracy_scores_entropy = pd.DataFrame() #for gini for md in m_depth: #instantiate and fit DT = DecisionTreeClassifier(max_depth=md, criterion=&#39;gini&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_gini = accuracy_scores_gini.append( {&#39;Max depth&#39;: md, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) #for criterion for md in m_depth: #instantiate and fit DT = DecisionTreeClassifier(max_depth=md, criterion=&#39;entropy&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_entropy = accuracy_scores_entropy.append( {&#39;Max depth&#39;: md, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between accuracy and max depth and criterion plt.figure() plt.plot(accuracy_scores_entropy[&#39;Max depth&#39;], accuracy_scores_entropy[&#39;Train_score&#39;], label=&#39;train score entropy&#39;, color=&#39;red&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_entropy[&#39;Max depth&#39;], accuracy_scores_entropy[&#39;Test_score&#39;], label=&#39;test score entropy&#39;, color=&#39;indianred&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Max depth&#39;], accuracy_scores_gini[&#39;Train_score&#39;], label=&#39;train score gini&#39;, color=&#39;royalblue&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Max depth&#39;], accuracy_scores_gini[&#39;Test_score&#39;], label=&#39;test score gini&#39;, color=&#39;navy&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Maximum depth&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Max depth higher than 30 shows large overfitting&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . After the maximum depth passes the 32 mark, the model starts hugely overfitting, with a gap between train and test scores of close to 25 percentage points. As the max depth increases more, the scores start to stay constant, probably because the model does not need that big of a depth anyway. It seems that the region where accuracy scores are high and the gap between train and test scores are acceptable is between 8 to 32. . # set range of feature max m_features = [2**i for i in range(1,5,1)] #testing for two criterions, gini and entropy accuracy_scores_gini = pd.DataFrame() accuracy_scores_entropy = pd.DataFrame() #for gini for mf in m_features: #instantiate and fit DT = DecisionTreeClassifier(max_features=mf, criterion=&#39;gini&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_gini = accuracy_scores_gini.append( {&#39;Max features&#39;: mf, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) #for criterion for mf in m_features: #instantiate and fit DT = DecisionTreeClassifier(max_features=mf, criterion=&#39;entropy&#39;, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = DT.score(X_train_res, y_train_res) test_score = DT.score(X_test, y_test) # append to list accuracy_scores_entropy = accuracy_scores_entropy.append( {&#39;Max features&#39;: mf, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between accuracy and max depth and criterion plt.figure() plt.plot(accuracy_scores_entropy[&#39;Max features&#39;], accuracy_scores_entropy[&#39;Train_score&#39;], label=&#39;train score entropy&#39;, color=&#39;red&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_entropy[&#39;Max features&#39;], accuracy_scores_entropy[&#39;Test_score&#39;], label=&#39;test score entropy&#39;, color=&#39;indianred&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Max features&#39;], accuracy_scores_gini[&#39;Train_score&#39;], label=&#39;train score gini&#39;, color=&#39;royalblue&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores_gini[&#39;Max features&#39;], accuracy_scores_gini[&#39;Test_score&#39;], label=&#39;test score gini&#39;, color=&#39;navy&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Maximum number of features&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Setting a feature limit has no effect on accuracy&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . We see that max features has not effect on the accuracy scores of our model. We will refrain from using that parameter when tuning our model to save computational power. . Finding optimal hyperparameters . We run a randomised cross validation through a pipeline to find the optimal hyperparameters. We choose a randomised as opposed to a grid search because decision tree models are very expensive. . max_depth_range = range(8,40,1) min_samples_leaf_range = range(16,64,1) # setting up which models/scalers we want to grid search estimator = [(&#39;reduce_dim&#39;, PCA()), (&#39;DT&#39;, DecisionTreeClassifier())] # defining distribution of parameters we want to compare param_dist = {&quot;DT__criterion&quot;: [&#39;gini&#39;, &#39;entropy&#39;], &#39;DT__max_depth&#39;: max_depth_range, &#39;DT__min_samples_leaf&#39;: min_samples_leaf_range, &#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_random(estimator, param_dist, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;reduce_dim&#39;: None, &#39;DT__min_samples_leaf&#39;: 17, &#39;DT__max_depth&#39;: 31, &#39;DT__criterion&#39;: &#39;gini&#39;}. The best model has an accuracy score of 0.7541633624107851 on the test set . The best model has a max depth of 32 and minimum samples per leaf of 35. It also chose the &#39;entropy&#39; criterion, althought this is probably not as important as we have seen above. . Running optimised model . start=time.time() #instantiate and fit DT_opt = DecisionTreeClassifier(min_samples_leaf=25, max_depth=24, criterion=&#39;entropy&#39;).fit(X_train_res, y_train_res) end=time.time() time_fit_opt=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_opt, 3)} seconds&quot;) . Time to fit the model on the training set is 3.79 seconds . The time to fit the model is just as long as the baseline model. . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(DT_opt, X_train_res, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(DT_opt, X_train_res, y_train_res) . ROC AUC: 0.9296680559908854 PR AUC: 0.9348323789697837 precision recall f1-score support 0 0.83 0.85 0.84 68984 1 0.85 0.83 0.84 68984 accuracy 0.84 137968 macro avg 0.84 0.84 0.84 137968 weighted avg 0.84 0.84 0.84 137968 . The various accuracy metrics for the training set have all decreased (down to around 83%) compared to the baseline model (all at 100%). This is great, because the baseline model was hugely overfitting the training set, as it had near perfect accuracy scores. Due to parameter tuning, we manage to prevent too large of an overfit. . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(DT_opt, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(DT_opt, X_test, y_test) . ROC AUC: 0.774381929527438 PR AUC: 0.9289184627381762 precision recall f1-score support 0 0.41 0.62 0.50 4221 1 0.89 0.78 0.83 17216 accuracy 0.75 21437 macro avg 0.65 0.70 0.66 21437 weighted avg 0.80 0.75 0.77 21437 . Time to predict the outcome variable for the test set is 0.015 seconds . Although the accuracy score is slightly lower for our optimised model, it has much better recall scores. This means the model is getting better at recognising functioning and non-functioning water points. For example, it has decreased the number of false positives by nearly 2 percentage points. . Comparing results . plot_curve_roc(&#39;DT&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . The optimised model has a worse AUC on the train set because it is being prevented from overfitting. We are more concerned with the test set AUC. Here the optimised model performs significantly better. The model is performing so much better on test, unseen, data. As a result, the optimised model is our best one here. . Visualising feature importance . coeff_bar_chart(DT_opt.feature_importances_, X.columns, t=False) . We see that water points which are installed after 2006 and how crucial they are are two very important features for the decision tree&#39;s splitting. The latitude and longitude of the points are also very important, which is probably why the region dummy columns are not given much importance. . We see, notably, that the number of conflicts/violent events are not very important for our model. . Public management and water point complexity are also important drivers for our model&#39;s accuracy. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . joblib.dump(DT_opt, model_filepath+&#39;decision_tree_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/decision_tree_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;Decision Tree&#39;], &#39;Parameters&#39;:[&#39;Max depth=24, Min samples leaf=25, Criterion=entropy&#39;], &#39;Accuracy Train&#39;: [accuracy_train_opt], &#39;Precision Train&#39;: [precision_train_opt], &#39;Recall Train&#39;: [recall_train_opt], &#39;F1 Train&#39;: [f1_train_opt], &#39;ROC AUC Train&#39;:[roc_auc_train_opt], &#39;Accuracy Test&#39;: accuracy_test_opt, &#39;Precision Test&#39;: [precision_test_opt], &#39;Recall Test&#39;: [recall_test_opt], &#39;F1 Test&#39;: [f1_test_opt], &#39;ROC AUC Test&#39;:[roc_auc_test_opt], &#39;Time Fit&#39;: time_fit_opt, &#39;Time Predict&#39;: time_predict_test_opt, &quot;Precision Non-functioning Test&quot;:0.41, &quot;Recall Non-functioning Test&quot;:0.62, &quot;F1 Non-functioning Test&quot;:0.49, &quot;Precision Functioning Test&quot;:0.89, &quot;Recall Functioning Test&quot;:0.78,&quot;F1 Functioning Test&quot;:0.83} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 Decision Tree | Max depth=24, Min samples leaf=25, Criterion=e... | 0.840586 | 0.840826 | 0.840586 | 0.840558 | 0.929668 | 0.751038 | 0.798911 | 0.751038 | 0.767915 | 0.774382 | 3.789587 | 0.015336 | 0.41 | 0.62 | 0.49 | 0.89 | 0.78 | 0.83 | . best_model_result_df.to_csv(model_filepath + &#39;decision_tree_model.csv&#39;) . metrics=[fpr_train_opt, tpr_train_opt, fpr_test_opt, tpr_test_opt] metrics_name=[&#39;fpr_train_opt&#39;, &#39;tpr_train_opt&#39;, &#39;fpr_test_opt&#39;, &#39;tpr_test_opt&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;decision_tree_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_09_decision_tree.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_09_decision_tree.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "K Nearest Neighbours",
            "content": "K Nearest Neighbors . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . modelling_df_sample = modelling_df.sample(n=round(len(modelling_df) * 0.3), random_state=rand_seed) #shape of sample modelling_df_sample[&#39;is_functioning&#39;].value_counts() . 1 25996 0 6159 Name: is_functioning, dtype: int64 . We take a subsample of our dataset because KNN models take a very long time to fit, train and predict. We make sure that both of our outcome variables are still present in our subsample. We go through the same process with our subsample as if it was our normal dataset. . X =modelling_df_sample.loc[:, modelling_df_sample.columns != &#39;is_functioning&#39;] y = modelling_df_sample[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (32155, 31) (32155,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.6% non-functioning water points and 80.4% functioning Original train set has 19.1% non-functioning water points and 80.9% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . X_train_res_scaled, X_test_scaled = scaling(StandardScaler(), X_train_res, X_test) . Running baseline model . start=time.time() #instantiate and fit KNN_base = KNeighborsClassifier().fit(X_train_res_scaled, y_train_res) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base,3)} seconds&quot;) . Time to fit the model on the training set is 0.003 seconds . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(KNN_base, X_train_res_scaled, y_train_res) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(KNN_base, X_train_res_scaled, y_train_res) . ROC AUC: 0.9691396173245337 PR AUC: 0.9708571411642523 precision recall f1-score support 0 0.86 0.94 0.90 20823 1 0.93 0.85 0.89 20823 accuracy 0.89 41646 macro avg 0.90 0.89 0.89 41646 weighted avg 0.90 0.89 0.89 41646 . Our first KNN has a relatively good accuracy score of 89% on the training set. However, this is only because our model is currently labelling nearly all water points as functioning. Errors mostly come from not recognising functioning water points, shown by the low recall score of 85% for functioning water points. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(KNN_base, X_test_scaled, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(KNN_base, X_test_scaled, y_test) . ROC AUC: 0.7129366832861221 PR AUC: 0.9133937334986582 precision recall f1-score support 0 0.37 0.53 0.44 1258 1 0.87 0.78 0.82 5173 accuracy 0.73 6431 macro avg 0.62 0.66 0.63 6431 weighted avg 0.77 0.73 0.75 6431 . Time to predict the outcome variable for the test set is 7.161 seconds . Our test set has an accuracy score of 74%. Similarly to the training set, it misses quite a lot of functioning water points (mislabels around a fifth of all functioning points) and also non-functioning points (around a third of all non-functioning points). . Narrowing down parameters . # set range of neighbors k_range = [2, 5, 15, 50, 100, 500] accuracy_scores = pd.DataFrame() for k in k_range: #instantiate and fit KNN = KNeighborsClassifier(n_neighbors=k).fit( X_train_res_scaled, y_train_res) # store accuracy scores train_score = KNN.score(X_train_res_scaled, y_train_res) test_score = KNN.score(X_test_scaled, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Neighbors&#39;: k, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between neighbors and accuracy plt.figure() plt.plot(accuracy_scores[&#39;Neighbors&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Neighbors&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xlabel(&#39;Neighbors&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;More neighbors decreases accuracy&quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . As the number of neighbors we take into account increases, the accuracy of our model decreases. We need a good middle ground where the gap between the train and test set is not too high (opposite of that is when k=2) and the test accuracy scores are still relatively high (opposite is when k=500). It seems that this middle ground is when k is lower than 100 neighbors . Finding optimal hyperparameters . We run a randomised cross validation through a pipeline to find the optimal hyperparameters. We choose a randomised as opposed to a grid search because KNN models are very expensive. . estimator = [(&#39;scaling&#39;, StandardScaler()), (&#39;reduce_dim&#39;, PCA()), (&#39;KNN&#39;, KNeighborsClassifier())] # defining distribution of parameters we want to compare param_dist = {&quot;KNN__n_neighbors&quot;: range(1, 50, 1), &#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_random(estimator, param_dist, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;reduce_dim__n_components&#39;: 0.7, &#39;KNN__n_neighbors&#39;: 7}. The best model has an accuracy score of 0.710464935468823 on the test set . The best model here seems to have a very similar accuracy score, but hopefully it scores better on its precision and recall scores. It seems that the optimal number of neighbors is 4. This is just below the default number of k neighbors that the model had taken in our baseline model. The optimal model also chooses to reduce dimensions (using PCA) to the minimum number of features which can explain 60% of the variance in the dataset. . Running optimised model . X_train_res_scaled_PCA, X_test_scaled_PCA=run_PCA(0.6, X_train_res_scaled, X_test_scaled) . train shape: (41646, 7) test shape: (6431, 7) . Note that the PCA transformer should be fitted on the training set and then should be used to transform the training and test set. We end up with 10 features that explain 60% of the variance in our dataset. . start=time.time() #instantiate and fit KNN_opt = KNeighborsClassifier(n_neighbors=4).fit(X_train_res_scaled_PCA, y_train_res) end=time.time() time_fit_opt=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_opt, 3)} seconds&quot;) . Time to fit the model on the training set is 0.035 seconds . The time to fit the model with our optimal parameter is 10x longer than in the baseline model. . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(KNN_opt, X_train_res_scaled_PCA, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(KNN_opt, X_train_res_scaled_PCA, y_train_res) . ROC AUC: 0.9684302091261268 PR AUC: 0.970738276849189 precision recall f1-score support 0 0.82 0.97 0.88 20823 1 0.96 0.78 0.86 20823 accuracy 0.87 41646 macro avg 0.89 0.87 0.87 41646 weighted avg 0.89 0.87 0.87 41646 . With PCA transformation, we end up with much more false negatives and less false negatives. It seems ot overidentify non-functioning water points. . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(KNN_opt, X_test_scaled_PCA, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(KNN_opt, X_test_scaled_PCA, y_test) . ROC AUC: 0.6975742643178765 PR AUC: 0.9099437918289577 precision recall f1-score support 0 0.33 0.61 0.43 1258 1 0.88 0.70 0.78 5173 accuracy 0.68 6431 macro avg 0.61 0.66 0.61 6431 weighted avg 0.77 0.68 0.71 6431 . Time to predict the outcome variable for the test set is 0.138 seconds . On the whole, the optimised model actually performs worse than the baseline model. We infer this from the accuracy score which is lower by 6 percentage points and all accuracy metrics decreasing, apart from the precision score for functioning points. However, the optimised model does have a higher recall score, and this is the metric we are most interested in. As a result we go with the optimised model. In addition, it took much less time to predict the outcome variable for the test set (&lt;1sec vs &gt;4sec). . Comparing results . plot_curve_roc(&#39;KNN&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . The baseline model performs overall best on the test set, which is the score we care the most about. Since PCA makes our results less interpretable and doesn&#39;t improve the model, we choose the baseline model to be our best one. . Exporting . joblib.dump(KNN_opt, model_filepath+&#39;k_nearest_neighbors_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/k_nearest_neighbors_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;K Nearest Neighbors&#39;], &#39;Parameters&#39;:[&#39;Neighbors=4, Standard Scaler&#39;], &#39;Accuracy Train&#39;: [accuracy_train_opt], &#39;Precision Train&#39;: [precision_train_opt], &#39;Recall Train&#39;: [recall_train_opt], &#39;F1 Train&#39;: [f1_train_opt], &#39;ROC AUC Train&#39;:[roc_auc_train_opt], &#39;Accuracy Test&#39;: accuracy_test_opt, &#39;Precision Test&#39;: [precision_test_opt], &#39;Recall Test&#39;: [recall_test_opt], &#39;F1 Test&#39;: [f1_test_opt], &#39;ROC AUC Test&#39;:[roc_auc_test_opt], &#39;Time Fit&#39;: time_fit_opt, &#39;Time Predict&#39;: time_predict_test_opt, &quot;Precision Non-functioning Test&quot;:0.33, &quot;Recall Non-functioning Test&quot;:0.65, &quot;F1 Non-functioning Test&quot;:0.44,&quot;Precision Functioning Test&quot;:0.89, &quot;Recall Functioning Test&quot;:0.69,&quot;F1 Functioning Test&quot;:0.77} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 K Nearest Neighbors | Neighbors=4, Standard Scaler | 0.873481 | 0.886708 | 0.873481 | 0.87239 | 0.96843 | 0.684808 | 0.77368 | 0.684808 | 0.713324 | 0.697574 | 0.035145 | 0.137945 | 0.33 | 0.65 | 0.44 | 0.89 | 0.69 | 0.77 | . best_model_result_df.to_csv(model_filepath + &#39;k_nearest_neighbors_model.csv&#39;) . metrics=[fpr_train_opt, tpr_train_opt, fpr_test_opt, tpr_test_opt] metrics_name=[&#39;fpr_train_opt&#39;, &#39;tpr_train_opt&#39;, &#39;fpr_test_opt&#39;, &#39;tpr_test_opt&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;k_nearest_neighbors_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_08_k_nearest_neighbors.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_08_k_nearest_neighbors.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Logistic Regression",
            "content": "Aim . The aim of our model is, of course to get a high accuracy score. However, the most important thing is that we do not want to miss non-functioning water points. We would rather have more false negatives (point labelled as non-functioning is actually fine) than false positives (point labelled as functioning is actually not). This will be calculated by the recall score for the 0/negative class. We want it to be as high as possible. . The intuition is that we would rather send an engineer to a functioning water point by mistake than not repair a non-functioning water point because we missed it. Both are costly and not ideal, but the cost to a whole community prevented from accessing water is worse than paying for an engineer for a repair that does not need to be made. . Random Guess . Our very first &quot;model&quot; or benchmark is the accuracy score we would get if guessed blindly. Since our outcome variable is binary, if we randomly tried to predict each observation, we would get, on average an accuracy score of 50%. Any model close to this blind guess would probably be close to useless (if not worse!) . This 50% accuracy score would happen if we did not have any prior knowledge about the distribution of our outcome variable. However, if we know that the distribution of our outcome variable (in this case 80% are 1s), we could get an accuracy score of 80%, without any kind of computation . Logistic Regression . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . Preparing data . modelling_df=pd.read_csv(data_filepath + &#39;master_modelling_df.csv&#39;, index_col=0) #check modelling_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 107184 entries, 0 to 108905 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 lat_deg 107184 non-null float64 1 lon_deg 107184 non-null float64 2 is_functioning 107184 non-null int64 3 distance_to_primary 107184 non-null float64 4 distance_to_secondary 107184 non-null float64 5 distance_to_tertiary 107184 non-null float64 6 distance_to_city 107184 non-null float64 7 distance_to_town 107184 non-null float64 8 usage_cap 107184 non-null float64 9 is_complex_tech 107184 non-null int64 10 is_installed_after_2006 107184 non-null int64 11 is_public_management 107184 non-null int64 12 crucialness 107184 non-null float64 13 perc_hh_head_male 107184 non-null float64 14 perc_pop1318_secondary 107184 non-null float64 15 perc_pop017_certificate 107184 non-null float64 16 perc_pop017_both_parents 107184 non-null float64 17 perc_pop2p_disability 107184 non-null float64 18 perc_pop1017_married 107184 non-null float64 19 perc_pop1217_birth 107184 non-null float64 20 perc_pop1464_working 107184 non-null float64 21 perc_hh_temp_dwelling 107184 non-null float64 22 perc_hh_mosquito_net 107184 non-null float64 23 perc_hh_toilet 107184 non-null float64 24 perc_hh_own_house 107184 non-null float64 25 perc_hh_bank_acc 107184 non-null float64 26 perc_hh_electricity 107184 non-null float64 27 total_events_adm4 107184 non-null float64 28 perc_local_served 107184 non-null float64 29 is_central 107184 non-null int64 30 is_eastern 107184 non-null int64 31 is_western 107184 non-null int64 dtypes: float64(25), int64(7) memory usage: 27.0 MB . Image(dictionary_filepath+&quot;5-Modelling-Data-Dictionary.png&quot;) . X =modelling_df.loc[:, modelling_df.columns != &#39;is_functioning&#39;] y = modelling_df[&#39;is_functioning&#39;] #check print(X.shape) print(y.shape) . (107184, 31) (107184,) . Our independent variable (X) should have the same number of rows (107,184) than our dependent variable (y). y should only have one column as it is the outcome variable. . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=rand_seed) . print(f&quot;Test set has {round(y_test.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_test.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Test set has 19.2% non-functioning water points and 80.8% functioning Train set has 19.7% non-functioning water points and 80.3% functioning . Our distribution of the outcome variable might increase the risk of our model recognising and labelling functioning water points much more often and better than non-functioning one. This might be an issue to resolve later on. . Running baseline model . start=time.time() #instantiate and fit LR_base = LogisticRegression(random_state=rand_seed).fit(X_train, y_train) end=time.time() time_fit_base=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_base, 3)} seconds&quot;) . Time to fit the model on the training set is 0.558 seconds . fpr_train_base, tpr_train_base, roc_auc_train_base, precision_train_base_plot, recall_train_base_plot, pr_auc_train_base, time_predict_train_base = print_report(LR_base, X_train, y_train) #storing accuracy scores accuracy_train_base, precision_train_base, recall_train_base, f1_train_base = get_scores(LR_base, X_train, y_train) . ROC AUC: 0.6315099570688278 PR AUC: 0.8674406643080401 precision recall f1-score support 0 0.34 0.00 0.00 16874 1 0.80 1.00 0.89 68873 accuracy 0.80 85747 macro avg 0.57 0.50 0.45 85747 weighted avg 0.71 0.80 0.72 85747 . Our basic logistic regression has a relatively good accuracy score of 80% on the training set. However, this is only because our model is currently labelling nearly all water points as functioning. This is how we end up with a huge False Positive Rate (FPR) of close to 20%. This makes our recall and f1 score for non-functioning water points go down to 0. . fpr_test_base, tpr_test_base, roc_auc_test_base, precision_test_base_plot, recall_test_base_plot, pr_auc_test_base, time_predict_test_base = print_report(LR_base, X_test, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_base,3)} seconds&quot;) #storing accuracy scores accuracy_test_base, precision_test_base, recall_test_base, f1_test_base = get_scores(LR_base, X_test, y_test) . ROC AUC: 0.623163643313243 PR AUC: 0.8678263254769776 precision recall f1-score support 0 0.23 0.00 0.00 4110 1 0.81 1.00 0.89 17327 accuracy 0.81 21437 macro avg 0.52 0.50 0.45 21437 weighted avg 0.70 0.81 0.72 21437 . Time to predict the outcome variable for the test set is 0.006 seconds . Similarly to the training set, the model predictions for the test set are pretty useless. One could just label all points functioning and end up with the same result, without actually doing a single calculation. As mentioned above, this is due to our sample being unbalanced, where 80% of our water point observations are functioning. As a result, it does not identify any kind of patterns for non-functioning water points. . Upsampling non-functioning water points . sm = SMOTE(random_state=rand_seed) X_train_res, y_train_res = sm.fit_resample(X_train, y_train) #compre resampled dataset print(f&quot;Original train set has {round(y_train.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) print(f&quot;Resampled train set has {round(y_train_res.value_counts(normalize=True)[0]*100,1)}% non-functioning water points and {round(y_train_res.value_counts(normalize=True)[1]*100,1)}% functioning&quot;) . Original train set has 19.7% non-functioning water points and 80.3% functioning Resampled train set has 50.0% non-functioning water points and 50.0% functioning . We over-sample the minority class, non-functioning water points, to get an equal distribution of our outcome variable. Note this should be done on the train set and not the test set as we should not tinker with the latter. . Narrowing down parameters . # set range of penalties c_range = [10**i for i in np.arange(-7, 7, 0.5)] accuracy_scores = pd.DataFrame() for c in c_range: #instantiate and fit LR = LogisticRegression(C=c, random_state=rand_seed).fit( X_train_res, y_train_res) # store accuracy scores train_score = LR.score(X_train_res, y_train_res) test_score = LR.score(X_test, y_test) # append to list accuracy_scores = accuracy_scores.append( {&#39;Penalty&#39;: c, &#39;Train_score&#39;: train_score, &#39;Test_score&#39;: test_score}, ignore_index=True) # visualise relationship between penalty and accuracy plt.figure() plt.plot(accuracy_scores[&#39;Penalty&#39;], accuracy_scores[&#39;Train_score&#39;], label=&#39;train score&#39;, marker=&#39;.&#39;) plt.plot(accuracy_scores[&#39;Penalty&#39;], accuracy_scores[&#39;Test_score&#39;], label=&#39;test score&#39;, marker=&#39;.&#39;) plt.xscale(&#39;log&#39;) plt.xlabel(&#39;Penalty&#39;) plt.ylabel(&quot;Accuracy&quot;) plt.title(&quot;Penalty effect on train and test accuracy scores is unclear &quot;) plt.legend(loc=&#39;best&#39;) plt.grid() plt.show() . There is not a very clear trend between the accuracy scores on the train and test sets and the magnitude of the penalty. The penalty should help with preventing overfitting, keeping these two curves closer to each other. We see that this might be happening after we pass the penalty threshold of $10^-4$. If we had more granular data points, we might see that the curves are much closer to each other more consistently. . PCA Analysis . Principal Component Analysis (PCA) is a method reduce the dimensions in a dataset, while keeping the accuracy score/performance high. The idea is that it excludes Principal Components which do not explain much of the variance in the dataset. . pca = PCA(n_components = None).fit(X_train_res) . We fit our PCA to our training set. . components = len(X.columns) # plot a scree plot plt.plot(range(1,components+1), np.cumsum(pca.explained_variance_ratio_ * 100)) plt.xlabel(&quot;Number of components&quot;) plt.ylabel(&quot;Explained variance (%)&quot;) plt.title(&quot;Half of our components explains the majority of our data&quot;) plt.grid() plt.show() . The scree plot above shows us the percentage of variance explained by each number of principal components. For example, the first principal component explains close to 3/4ths of the variance. As we add more principal components, the marginal improvement in explained variance slowly decreases. We get to around 100% of explained variance at around the 15th principal component (out of 32 principal components, as we have 32 features) . It seems that most of our principal components are important in explaining the variance in our dataset. This is probably due to the thorough feature engineering we did to cut down from more than 70 columns to our current 32. Although we will test whether reducing dimensions through PCA will improves our model accuracy, we do not expect it as all variables seem important in explaining the variance in our data. . Finding optimal hyperparameters . We run a grid search cross validation through a pipeline to find the optimal hyperparameters for our logistic regression. We choose the default scoring method of accuracy for our grid search. I tried different scoring methods and it did not change anything to the grid search. Since most models were run with the default the first time, we stick to accuracy as the scoring method for our grid search to optimise. . c_range = [10**i for i in np.arange(-6, 6, 0.5)] c_range.insert(0, 0) # setting up which models/scalers we want to grid search estimator = [(&#39;scaling&#39;, StandardScaler()), (&#39;reduce_dim&#39;, PCA()), (&#39;LR&#39;, LogisticRegression(random_state=rand_seed))] # defining parameters we want to compare param = {&#39;LR__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;], &#39;LR__C&#39;: c_range, &#39;reduce_dim__n_components&#39;: [0.5, 0.6, 0.7, 0.8, 0.9, None]} # run cross validation pipeline_cross_val_grid(estimator, param, X_train_res, y_train_res, X_test, y_test) . The model with the best CV score has the following parameters: {&#39;LR__C&#39;: 0.01, &#39;LR__penalty&#39;: &#39;l2&#39;, &#39;reduce_dim__n_components&#39;: None}. The best model has an accuracy score of 0.8750768092934949 on the test set . The best model here seems to have a much lower accuracy score, but hopefully it scores better on its precision and recall scores for non-functioning water points. Interestingly, the best model does not use PCA to reduce dimensions. . Running optimised model . X_train_res_scaled, X_test_scaled = scaling(StandardScaler(), X_train_res, X_test) . Note that the scaler should be fitted on the training set and then should be used to transform the training and test set. . start=time.time() #instantiate and fit LR_opt = LogisticRegression(penalty=&#39;l2&#39;, C=0.01, random_state=rand_seed).fit(X_train_res_scaled, y_train_res) end=time.time() time_fit_opt=end-start print(f&quot;Time to fit the model on the training set is {round(time_fit_opt,3)} seconds&quot;) . Time to fit the model on the training set is 0.403 seconds . The time to fit the model with our optimal parameter is similar to the baseline model, around 0.4 seconds. . fpr_train_opt, tpr_train_opt, roc_auc_train_opt, precision_train_opt_plot, recall_train_opt_plot, pr_auc_train_opt, time_predict_train_opt = print_report(LR_opt, X_train_res_scaled, y_train_res) #storing accuracy scores accuracy_train_opt, precision_train_opt, recall_train_opt, f1_train_opt = get_scores(LR_opt, X_train_res_scaled, y_train_res) . ROC AUC: 0.7094187724618326 PR AUC: 0.7066881913423855 precision recall f1-score support 0 0.65 0.65 0.65 68873 1 0.65 0.65 0.65 68873 accuracy 0.65 137746 macro avg 0.65 0.65 0.65 137746 weighted avg 0.65 0.65 0.65 137746 . The accuracy score for the training set has plummeted from 80 to 65%. However, the precision, recall and f1 scores have all improved dramatically, all of them at the 65% mark. . fpr_test_opt, tpr_test_opt, roc_auc_test_opt, precision_test_opt_plot, recall_test_opt_plot, pr_auc_test_opt, time_predict_test_opt = print_report(LR_opt, X_test_scaled, y_test) print(f&quot;Time to predict the outcome variable for the test set is {round(time_predict_test_opt,3)} seconds&quot;) #storing accuracy scores accuracy_test_opt, precision_test_opt, recall_test_opt, f1_test_opt = get_scores(LR_opt, X_test_scaled, y_test) . ROC AUC: 0.6392664388742826 PR AUC: 0.8750596739454459 precision recall f1-score support 0 0.27 0.55 0.36 4110 1 0.86 0.65 0.74 17327 accuracy 0.63 21437 macro avg 0.56 0.60 0.55 21437 weighted avg 0.75 0.63 0.67 21437 . Time to predict the outcome variable for the test set is 0.003 seconds . The various accuracy metrics for functioning water points in our optimised model has decreased compared to our baseline model. However, these metrics for non-functioning water points have increased substantially. For example, only 9% of predictions are false positives, comapred to 20% previously. Our false negatives have increased to nearly a third, which is not great. The time to predict the test set has slightly improved from our base model, even though we specified more parameters. . Comparing results . plot_curve_roc(&#39;LR&#39;, fpr_train_base, tpr_train_base, roc_auc_train_base, fpr_train_opt, tpr_train_opt, roc_auc_train_opt, fpr_test_base, tpr_test_base, roc_auc_test_base, fpr_test_opt, tpr_test_opt, roc_auc_test_opt) . The ROC curve shows us the performance of our models at different thresholds. Our optimised model performs much better than our baseline model on our training set. Our resampling and parameter optimization seems to have made the model better at identifying trends in the data. On the other hand, this improvement in accuracy is much smaller in our test set, although still there. . plot_curve_prec_recall(&#39;LR&#39;, recall_train_base_plot, precision_train_base_plot, pr_auc_train_base, recall_train_opt_plot, precision_train_opt_plot, pr_auc_train_opt, recall_test_base_plot, precision_test_base_plot, pr_auc_test_base, recall_test_opt_plot, precision_test_opt_plot, pr_auc_test_opt) . The precision/recall curve is not a very useful visualisation so we will refrain from visualising these plots in the future. . Visualising feature importance . coeff_bar_chart(LR_opt.coef_, X.columns, t=True) . The colors in the bar chart below represent the initial hypotheses that we have made. Positive (blue) means that we expect there to be a positive relationship between that variable and the functionality of a water point. Grey is neutral, as we believe the relationship might be more complex and red is a negative relationship. This enables us to assess whether our hypotheses has been validated or not. . Water points which were installed after 2006 have a much higher probability of being functioning. Not being in the Northern region and being in one where the bank account ownership rate is high also increases that probability. Being publicly managed and being of complex technology is also a sign of a functioning water point. . Interestingly, violent events and conflicts are low predictors of water point functionality. This might suggest that demographic and regional factors are the main drivers, and violence might just also be a result of these regional differences. . Health and prosperity metrics have little explanatory power in the functioning of a water point. . Finally, points which serve a large percentage of their local population and those which are very crucial to its neighboring communities increases the probability of that water point not functioning. We can imagine that overuse might be a major cause of this. . Regarding our hypotheses, we were especially wrong with the proportion of people in temporary dwelling. It seems to be associated with functioning water points. We also thought that higher rates of secondary school enrollment would be positively correlated with functionality, however, in this model, we find the opposite. . Image(dictionary_filepath+&quot;6-Hypotheses.png&quot;) . Exporting . joblib.dump(LR_opt, model_filepath+&#39;logistic_regression_model.sav&#39;) . [&#39;/Users/thomasadler/Desktop/futuristic-platipus/models/logistic_regression_model.sav&#39;] . d = {&#39;Model&#39;:[&#39;Logistic Regression&#39;], &#39;Parameters&#39;:[&#39;Penalty=l2, C=0.01, Standard Scaler&#39;], &#39;Accuracy Train&#39;: [accuracy_train_opt], &#39;Precision Train&#39;: [precision_train_opt], &#39;Recall Train&#39;: [recall_train_opt], &#39;F1 Train&#39;: [f1_train_opt], &#39;ROC AUC Train&#39;:[roc_auc_train_opt], &#39;Accuracy Test&#39;: accuracy_test_opt, &#39;Precision Test&#39;: [precision_test_opt], &#39;Recall Test&#39;: [recall_test_opt], &#39;F1 Test&#39;: [f1_test_opt], &#39;ROC AUC Test&#39;:[roc_auc_test_opt], &#39;Time Fit&#39;: time_fit_opt, &#39;Time Predict&#39;: time_predict_test_opt, &quot;Precision Non-functioning Test&quot;: 0.27, &quot;Recall Non-functioning Test&quot;: 0.55, &quot;F1 Non-functioning Test&quot;: 0.36,&quot;Precision Functioning Test&quot;: 0.86, &quot;Recall Functioning Test&quot;: 0.65,&quot;F1 Functioning Test&quot;: 0.74} #to dataframe best_model_result_df=pd.DataFrame(data=d) #check best_model_result_df . Model Parameters Accuracy Train Precision Train Recall Train F1 Train ROC AUC Train Accuracy Test Precision Test Recall Test F1 Test ROC AUC Test Time Fit Time Predict Precision Non-functioning Test Recall Non-functioning Test F1 Non-functioning Test Precision Functioning Test Recall Functioning Test F1 Functioning Test . 0 Logistic Regression | Penalty=l2, C=0.01, Standard Scaler | 0.65056 | 0.650571 | 0.65056 | 0.650553 | 0.709419 | 0.627606 | 0.74543 | 0.627606 | 0.665148 | 0.639266 | 0.403007 | 0.003307 | 0.27 | 0.55 | 0.36 | 0.86 | 0.65 | 0.74 | . best_model_result_df.to_csv(model_filepath + &#39;logistic_regression_model.csv&#39;) . metrics=[fpr_train_opt, tpr_train_opt, fpr_test_opt, tpr_test_opt] metrics_name=[&#39;fpr_train_opt&#39;, &#39;tpr_train_opt&#39;, &#39;fpr_test_opt&#39;, &#39;tpr_test_opt&#39;] #save numpy arrays for model comparison for metric, metric_name in zip(metrics, metrics_name): np.save(model_filepath+f&#39;logistic_regression_{metric_name}&#39;, metric) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_07_logistic_regression.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_07_logistic_regression.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Master dataframe",
            "content": "Master Dataframe . We will be combining our water, conflict and demographic data into one master dataframe to be used for analysis and modelling. . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . Loading datasets . water_df=pd.read_csv(data_filepath + &#39;ta_1_uganda_water_df_clean.csv&#39;, index_col=0) #check water_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 108906 entries, 0 to 108905 Data columns (total 35 columns): # Column Non-Null Count Dtype -- -- 0 row_id 108906 non-null int64 1 source 108906 non-null object 2 lat_deg 108906 non-null float64 3 lon_deg 108906 non-null float64 4 report_date 108906 non-null object 5 status_id 108906 non-null int64 6 facility_type 108906 non-null object 7 clean_country_name 108906 non-null object 8 clean_adm1 108906 non-null object 9 clean_adm2 108906 non-null object 10 clean_adm3 108906 non-null object 11 clean_adm4 108906 non-null object 12 distance_to_primary 108906 non-null float64 13 distance_to_secondary 108906 non-null float64 14 distance_to_tertiary 108906 non-null float64 15 distance_to_city 108906 non-null float64 16 distance_to_town 108906 non-null float64 17 usage_cap 108906 non-null float64 18 staleness_score 108906 non-null float64 19 is_latest 108906 non-null int64 20 location_id 108906 non-null int64 21 cluster_size 108906 non-null float64 22 new_georeferenced_column_ 108906 non-null object 23 lat_lon_deg 108906 non-null object 24 count 108906 non-null float64 25 water_source_clean 91467 non-null object 26 water_source_category 91467 non-null object 27 wpdx_id 107814 non-null object 28 served_population 108906 non-null float64 29 local_population 108906 non-null float64 30 crucialness 108906 non-null float64 31 pressure 108906 non-null float64 32 install_year 89181 non-null object 33 management_clean 92281 non-null object 34 status_clean 89408 non-null object dtypes: float64(15), int64(4), object(16) memory usage: 29.9+ MB . conflict_df=pd.read_csv(data_filepath +&#39;ta_3_conflict_df_clean.csv&#39;, index_col=0) #check conflict_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 7854 entries, 0 to 7853 Data columns (total 21 columns): # Column Non-Null Count Dtype -- -- 0 data_id 7854 non-null int64 1 event_date 7854 non-null object 2 event_type 7854 non-null object 3 sub_event_type 7854 non-null object 4 actor1 7854 non-null object 5 assoc_actor_1 1963 non-null object 6 inter1 7854 non-null int64 7 actor2 6605 non-null object 8 assoc_actor_2 1669 non-null object 9 inter2 7854 non-null int64 10 interaction 7854 non-null int64 11 clean_adm1 7854 non-null object 12 clean_adm2 7854 non-null object 13 clean_adm3 7854 non-null object 14 clean_adm4 7854 non-null object 15 latitude 7854 non-null float64 16 longitude 7854 non-null float64 17 source 7854 non-null object 18 source_scale 7854 non-null object 19 notes 7772 non-null object 20 fatalities 7854 non-null float64 dtypes: float64(3), int64(4), object(14) memory usage: 1.3+ MB . demographic_df=pd.read_csv(data_filepath +&#39;ta_2_subcounty_demographic_clean.csv&#39;, index_col=0) #check demographic_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1382 entries, 0 to 1381 Data columns (total 28 columns): # Column Non-Null Count Dtype -- -- 0 clean_adm4 1382 non-null object 1 perc_hh_head_male 1382 non-null float64 2 perc_pop612_primary 1382 non-null float64 3 perc_pop1318_secondary 1382 non-null float64 4 perc_pop18p_illiterate 1382 non-null float64 5 perc_pop017_certificate 1382 non-null float64 6 perc_pop017_both_parents 1382 non-null float64 7 perc_pop2p_disability 1382 non-null float64 8 perc_pop1017_married 1382 non-null float64 9 perc_pop1217_birth 1382 non-null float64 10 perc_pop1464_working 1382 non-null float64 11 perc_pop10p_mobile_phone 1382 non-null float64 12 perc_hh_temp_dwelling 1382 non-null float64 13 perc_pop_5km_dist_primary 1382 non-null float64 14 perc_pop_5km_dist_secondary 1382 non-null float64 15 perc_pop_5km_dist_health 1382 non-null float64 16 perc_pop_5km_dist_police 1382 non-null float64 17 perc_hh_mosquito_net 1382 non-null float64 18 perc_hh_piped_water 1382 non-null float64 19 perc_hh_borehole 1382 non-null float64 20 perc_hh_toilet 1382 non-null float64 21 perc_hh_own_house 1382 non-null float64 22 perc_hh_own_tv 1382 non-null float64 23 perc_hh_bank_acc 1382 non-null float64 24 perc_hh_subs_farm 1382 non-null float64 25 perc_hh_less2meals 1382 non-null float64 26 perc_hh_electricity 1382 non-null float64 27 tot_pop_subcounty 1382 non-null float64 dtypes: float64(27), object(1) memory usage: 313.1+ KB . Merge datasets . We want to get demographic information for each water point at its most local level. . master_df=pd.merge(water_df, demographic_df, how=&#39;left&#39;, left_on=water_df[&#39;clean_adm4&#39;], right_on=demographic_df[&#39;clean_adm4&#39;], suffixes=[&#39;x&#39;, &#39;y&#39;]) #check master_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 108906 entries, 0 to 108905 Data columns (total 64 columns): # Column Non-Null Count Dtype -- -- 0 key_0 108906 non-null object 1 row_id 108906 non-null int64 2 source 108906 non-null object 3 lat_deg 108906 non-null float64 4 lon_deg 108906 non-null float64 5 report_date 108906 non-null object 6 status_id 108906 non-null int64 7 facility_type 108906 non-null object 8 clean_country_name 108906 non-null object 9 clean_adm1 108906 non-null object 10 clean_adm2 108906 non-null object 11 clean_adm3 108906 non-null object 12 clean_adm4x 108906 non-null object 13 distance_to_primary 108906 non-null float64 14 distance_to_secondary 108906 non-null float64 15 distance_to_tertiary 108906 non-null float64 16 distance_to_city 108906 non-null float64 17 distance_to_town 108906 non-null float64 18 usage_cap 108906 non-null float64 19 staleness_score 108906 non-null float64 20 is_latest 108906 non-null int64 21 location_id 108906 non-null int64 22 cluster_size 108906 non-null float64 23 new_georeferenced_column_ 108906 non-null object 24 lat_lon_deg 108906 non-null object 25 count 108906 non-null float64 26 water_source_clean 91467 non-null object 27 water_source_category 91467 non-null object 28 wpdx_id 107814 non-null object 29 served_population 108906 non-null float64 30 local_population 108906 non-null float64 31 crucialness 108906 non-null float64 32 pressure 108906 non-null float64 33 install_year 89181 non-null object 34 management_clean 92281 non-null object 35 status_clean 89408 non-null object 36 clean_adm4y 104624 non-null object 37 perc_hh_head_male 104624 non-null float64 38 perc_pop612_primary 104624 non-null float64 39 perc_pop1318_secondary 104624 non-null float64 40 perc_pop18p_illiterate 104624 non-null float64 41 perc_pop017_certificate 104624 non-null float64 42 perc_pop017_both_parents 104624 non-null float64 43 perc_pop2p_disability 104624 non-null float64 44 perc_pop1017_married 104624 non-null float64 45 perc_pop1217_birth 104624 non-null float64 46 perc_pop1464_working 104624 non-null float64 47 perc_pop10p_mobile_phone 104624 non-null float64 48 perc_hh_temp_dwelling 104624 non-null float64 49 perc_pop_5km_dist_primary 104624 non-null float64 50 perc_pop_5km_dist_secondary 104624 non-null float64 51 perc_pop_5km_dist_health 104624 non-null float64 52 perc_pop_5km_dist_police 104624 non-null float64 53 perc_hh_mosquito_net 104624 non-null float64 54 perc_hh_piped_water 104624 non-null float64 55 perc_hh_borehole 104624 non-null float64 56 perc_hh_toilet 104624 non-null float64 57 perc_hh_own_house 104624 non-null float64 58 perc_hh_own_tv 104624 non-null float64 59 perc_hh_bank_acc 104624 non-null float64 60 perc_hh_subs_farm 104624 non-null float64 61 perc_hh_less2meals 104624 non-null float64 62 perc_hh_electricity 104624 non-null float64 63 tot_pop_subcounty 104624 non-null float64 dtypes: float64(42), int64(4), object(18) memory usage: 54.0+ MB . We then want to to know how violent and unstable a region is. We sum up the total number of fatalities and events/conflicts a region has had since 1997 and merge them with our water point and demographic data. . conflict_fatal_grouped=conflict_df[[&#39;clean_adm4&#39;, &#39;fatalities&#39;]].groupby(&#39;clean_adm4&#39;).sum() conflict_fatal_grouped.columns=[&#39;total_fatalities_adm4&#39;] conflict_fatal_grouped.reset_index(inplace=True) #check conflict_fatal_grouped . clean_adm4 total_fatalities_adm4 . 0 Abala Parish | 17.0 | . 1 Abalodyang | 5.0 | . 2 Abanga | 0.0 | . 3 Abarilera | 22.0 | . 4 Abayita Ababiri | 0.0 | . ... ... | ... | . 1275 Yumbe | 6.0 | . 1276 Zeu | 7.0 | . 1277 Zoka | 1.0 | . 1278 Zoka Forest | 1.0 | . 1279 Zombo | 5.0 | . 1280 rows × 2 columns . conflict_events_grouped=conflict_df[[&#39;clean_adm4&#39;, &#39;data_id&#39;]].groupby([&#39;clean_adm4&#39;]).count() conflict_events_grouped.columns=[&#39;total_events_adm4&#39;] conflict_events_grouped.reset_index(inplace=True) #check conflict_events_grouped . clean_adm4 total_events_adm4 . 0 Abala Parish | 9 | . 1 Abalodyang | 1 | . 2 Abanga | 1 | . 3 Abarilera | 7 | . 4 Abayita Ababiri | 1 | . ... ... | ... | . 1275 Yumbe | 11 | . 1276 Zeu | 1 | . 1277 Zoka | 1 | . 1278 Zoka Forest | 3 | . 1279 Zombo | 1 | . 1280 rows × 2 columns . del master_df[master_df.columns[0]] #merge water dataset with fatalities dataset master_df=pd.merge(master_df, conflict_fatal_grouped, how=&#39;left&#39;, left_on=master_df[&#39;clean_adm4x&#39;], right_on=conflict_fatal_grouped[&#39;clean_adm4&#39;],suffixes=(&#39;z&#39;, &#39;w&#39;)) #check master_df.head() . key_0 row_id source lat_deg lon_deg report_date status_id facility_type clean_country_name clean_adm1 ... perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty clean_adm4 total_fatalities_adm4 . 0 Kabambiro | 652212 | Water For People | 0.158537 | 30.490643 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 1.317831 | 87.942373 | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | 15484.0 | NaN | NaN | . 1 Nyabbani | 653304 | Water For People | 0.070597 | 30.415651 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 0.866692 | 88.482012 | 2.614604 | 14.573029 | 92.319897 | 4.458575 | 7.565426 | 21953.0 | NaN | NaN | . 2 Kabambiro | 655356 | Water For People | 0.158667 | 30.490551 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 1.317831 | 87.942373 | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | 15484.0 | NaN | NaN | . 3 Bwizi | 655725 | Water For People | 0.430480 | 30.751951 | 2005-09-07 | 0 | Improved | Uganda | Western | ... | 2.031564 | 82.706261 | 1.033757 | 6.879652 | 95.096440 | 5.003880 | 8.693308 | 28764.0 | NaN | NaN | . 4 Kicheche | 661237 | Water For People | -0.134680 | 30.351593 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 0.983537 | 89.721699 | 4.054211 | 20.201299 | 87.522511 | 4.271490 | 9.606041 | 26338.0 | NaN | NaN | . 5 rows × 66 columns . del master_df[master_df.columns[0]] #merge water dataset with fatalities dataset master_df=pd.merge(master_df, conflict_events_grouped, how=&#39;left&#39;, left_on=master_df[&#39;clean_adm4x&#39;], right_on=conflict_events_grouped[&#39;clean_adm4&#39;], suffixes=(&#39;a&#39;, &#39;b&#39;)) #check master_df.head() . key_0 row_id source lat_deg lon_deg report_date status_id facility_type clean_country_name clean_adm1 ... perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty clean_adm4a total_fatalities_adm4 clean_adm4b total_events_adm4 . 0 Kabambiro | 652212 | Water For People | 0.158537 | 30.490643 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | 15484.0 | NaN | NaN | NaN | NaN | . 1 Nyabbani | 653304 | Water For People | 0.070597 | 30.415651 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 2.614604 | 14.573029 | 92.319897 | 4.458575 | 7.565426 | 21953.0 | NaN | NaN | NaN | NaN | . 2 Kabambiro | 655356 | Water For People | 0.158667 | 30.490551 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | 15484.0 | NaN | NaN | NaN | NaN | . 3 Bwizi | 655725 | Water For People | 0.430480 | 30.751951 | 2005-09-07 | 0 | Improved | Uganda | Western | ... | 1.033757 | 6.879652 | 95.096440 | 5.003880 | 8.693308 | 28764.0 | NaN | NaN | NaN | NaN | . 4 Kicheche | 661237 | Water For People | -0.134680 | 30.351593 | 2005-09-07 | 1 | Improved | Uganda | Western | ... | 4.054211 | 20.201299 | 87.522511 | 4.271490 | 9.606041 | 26338.0 | NaN | NaN | NaN | NaN | . 5 rows × 68 columns . master_df.columns . Index([&#39;key_0&#39;, &#39;row_id&#39;, &#39;source&#39;, &#39;lat_deg&#39;, &#39;lon_deg&#39;, &#39;report_date&#39;, &#39;status_id&#39;, &#39;facility_type&#39;, &#39;clean_country_name&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4x&#39;, &#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;, &#39;distance_to_town&#39;, &#39;usage_cap&#39;, &#39;staleness_score&#39;, &#39;is_latest&#39;, &#39;location_id&#39;, &#39;cluster_size&#39;, &#39;new_georeferenced_column_&#39;, &#39;lat_lon_deg&#39;, &#39;count&#39;, &#39;water_source_clean&#39;, &#39;water_source_category&#39;, &#39;wpdx_id&#39;, &#39;served_population&#39;, &#39;local_population&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;install_year&#39;, &#39;management_clean&#39;, &#39;status_clean&#39;, &#39;clean_adm4y&#39;, &#39;perc_hh_head_male&#39;, &#39;perc_pop612_primary&#39;, &#39;perc_pop1318_secondary&#39;, &#39;perc_pop18p_illiterate&#39;, &#39;perc_pop017_certificate&#39;, &#39;perc_pop017_both_parents&#39;, &#39;perc_pop2p_disability&#39;, &#39;perc_pop1017_married&#39;, &#39;perc_pop1217_birth&#39;, &#39;perc_pop1464_working&#39;, &#39;perc_pop10p_mobile_phone&#39;, &#39;perc_hh_temp_dwelling&#39;, &#39;perc_pop_5km_dist_primary&#39;, &#39;perc_pop_5km_dist_secondary&#39;, &#39;perc_pop_5km_dist_health&#39;, &#39;perc_pop_5km_dist_police&#39;, &#39;perc_hh_mosquito_net&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;, &#39;perc_hh_own_house&#39;, &#39;perc_hh_own_tv&#39;, &#39;perc_hh_bank_acc&#39;, &#39;perc_hh_subs_farm&#39;, &#39;perc_hh_less2meals&#39;, &#39;perc_hh_electricity&#39;, &#39;tot_pop_subcounty&#39;, &#39;clean_adm4a&#39;, &#39;total_fatalities_adm4&#39;, &#39;clean_adm4b&#39;, &#39;total_events_adm4&#39;], dtype=&#39;object&#39;) . We choose columns which may potentially be able to help us predict whether a water point is functioning or not. . master_df_clean = master_df[[&#39;wpdx_id&#39;, &#39;lat_deg&#39;, &#39;lon_deg&#39;, &#39;status_id&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4x&#39;, &#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;, &#39;distance_to_town&#39;, &#39;usage_cap&#39;, &#39;staleness_score&#39;, &#39;cluster_size&#39;, &#39;water_source_clean&#39;,&#39;install_year&#39;, &#39;management_clean&#39;, &#39;served_population&#39;, &#39;local_population&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;perc_hh_head_male&#39;, &#39;perc_pop612_primary&#39;, &#39;perc_pop1318_secondary&#39;, &#39;perc_pop18p_illiterate&#39;, &#39;perc_pop017_certificate&#39;, &#39;perc_pop017_both_parents&#39;, &#39;perc_pop2p_disability&#39;, &#39;perc_pop1017_married&#39;, &#39;perc_pop1217_birth&#39;, &#39;perc_pop1464_working&#39;, &#39;perc_pop10p_mobile_phone&#39;, &#39;perc_hh_temp_dwelling&#39;, &#39;perc_hh_mosquito_net&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;, &#39;perc_hh_own_house&#39;, &#39;perc_hh_own_tv&#39;, &#39;perc_hh_bank_acc&#39;, &#39;perc_hh_subs_farm&#39;, &#39;perc_hh_less2meals&#39;, &#39;perc_hh_electricity&#39;, &#39;total_fatalities_adm4&#39;, &#39;total_events_adm4&#39; ]] #check master_df_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 108906 entries, 0 to 108905 Data columns (total 47 columns): # Column Non-Null Count Dtype -- -- 0 wpdx_id 107814 non-null object 1 lat_deg 108906 non-null float64 2 lon_deg 108906 non-null float64 3 status_id 108906 non-null int64 4 clean_adm1 108906 non-null object 5 clean_adm2 108906 non-null object 6 clean_adm3 108906 non-null object 7 clean_adm4x 108906 non-null object 8 distance_to_primary 108906 non-null float64 9 distance_to_secondary 108906 non-null float64 10 distance_to_tertiary 108906 non-null float64 11 distance_to_city 108906 non-null float64 12 distance_to_town 108906 non-null float64 13 usage_cap 108906 non-null float64 14 staleness_score 108906 non-null float64 15 cluster_size 108906 non-null float64 16 water_source_clean 91467 non-null object 17 install_year 89181 non-null object 18 management_clean 92281 non-null object 19 served_population 108906 non-null float64 20 local_population 108906 non-null float64 21 crucialness 108906 non-null float64 22 pressure 108906 non-null float64 23 perc_hh_head_male 104624 non-null float64 24 perc_pop612_primary 104624 non-null float64 25 perc_pop1318_secondary 104624 non-null float64 26 perc_pop18p_illiterate 104624 non-null float64 27 perc_pop017_certificate 104624 non-null float64 28 perc_pop017_both_parents 104624 non-null float64 29 perc_pop2p_disability 104624 non-null float64 30 perc_pop1017_married 104624 non-null float64 31 perc_pop1217_birth 104624 non-null float64 32 perc_pop1464_working 104624 non-null float64 33 perc_pop10p_mobile_phone 104624 non-null float64 34 perc_hh_temp_dwelling 104624 non-null float64 35 perc_hh_mosquito_net 104624 non-null float64 36 perc_hh_piped_water 104624 non-null float64 37 perc_hh_borehole 104624 non-null float64 38 perc_hh_toilet 104624 non-null float64 39 perc_hh_own_house 104624 non-null float64 40 perc_hh_own_tv 104624 non-null float64 41 perc_hh_bank_acc 104624 non-null float64 42 perc_hh_subs_farm 104624 non-null float64 43 perc_hh_less2meals 104624 non-null float64 44 perc_hh_electricity 104624 non-null float64 45 total_fatalities_adm4 35033 non-null float64 46 total_events_adm4 35033 non-null float64 dtypes: float64(38), int64(1), object(8) memory usage: 39.9+ MB . Clean data . print(f&#39;There are {master_df_clean.isna().sum().sum()} null values&#39;) . There are 296831 null values . master_df_clean[&#39;clean_adm1&#39;].value_counts() . Western 41030 Eastern 25181 Northern 25052 Central 17643 Name: clean_adm1, dtype: int64 . master_df_clean[[&#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;]].describe().T . count mean std min 25% 50% 75% max . distance_to_primary 108906.0 | 17303.595989 | 16320.742663 | 0.169448 | 4380.71400 | 13009.2125 | 26147.321000 | 113267.730 | . distance_to_secondary 108906.0 | 5474.409666 | 6338.274052 | 0.034171 | 1147.75660 | 3472.1523 | 7400.876525 | 48801.574 | . distance_to_tertiary 108906.0 | 2846.930649 | 3547.441610 | 0.021833 | 475.77956 | 1606.8709 | 3822.951925 | 33601.773 | . distance_to_city 108906.0 | 42050.468544 | 30474.890401 | 55.531650 | 20122.05250 | 35971.3700 | 57459.347500 | 222690.450 | . The distances are evidently in metres, as we know that the area of Uganda is 241,000 km $^2$. So we want transform these columns into kilometres, to make our analysis and interpretation easier. . distances=[&#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;, &#39;distance_to_town&#39;] #transform into kilometres master_df_clean[distances]=master_df_clean[distances]/1000 #check master_df_clean[[&#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;]].describe().T . count mean std min 25% 50% 75% max . distance_to_primary 108906.0 | 17.303596 | 16.320743 | 0.000169 | 4.380714 | 13.009213 | 26.147321 | 113.267730 | . distance_to_secondary 108906.0 | 5.474410 | 6.338274 | 0.000034 | 1.147757 | 3.472152 | 7.400877 | 48.801574 | . distance_to_tertiary 108906.0 | 2.846931 | 3.547442 | 0.000022 | 0.475780 | 1.606871 | 3.822952 | 33.601773 | . distance_to_city 108906.0 | 42.050469 | 30.474890 | 0.055532 | 20.122052 | 35.971370 | 57.459347 | 222.690450 | . master_df_clean_numerical = master_df_clean[ master_df_clean.select_dtypes(exclude=&#39;object&#39;).columns] # check master_df_clean_numerical.head() . lat_deg lon_deg status_id distance_to_primary distance_to_secondary distance_to_tertiary distance_to_city distance_to_town usage_cap staleness_score ... perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity total_fatalities_adm4 total_events_adm4 . 0 0.158537 | 30.490643 | 1 | 37.666023 | 4.875484 | 0.023399 | 45.104836 | 32.223873 | 250.0 | 14.327719 | ... | 34.360863 | 1.317831 | 87.942373 | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | NaN | NaN | . 1 0.070597 | 30.415651 | 1 | 35.843273 | 2.602279 | 0.971238 | 38.419560 | 24.194055 | 250.0 | 14.327719 | ... | 13.201162 | 0.866692 | 88.482012 | 2.614604 | 14.573029 | 92.319897 | 4.458575 | 7.565426 | NaN | NaN | . 2 0.158667 | 30.490551 | 1 | 37.651727 | 4.860170 | 0.034916 | 45.094210 | 32.236693 | 250.0 | 14.327719 | ... | 34.360863 | 1.317831 | 87.942373 | 1.249238 | 10.259377 | 91.358551 | 4.212975 | 4.461754 | NaN | NaN | . 3 0.430480 | 30.751951 | 0 | 14.592108 | 16.548334 | 1.269275 | 58.369610 | 23.365746 | 250.0 | 14.327719 | ... | 16.919476 | 2.031564 | 82.706261 | 1.033757 | 6.879652 | 95.096440 | 5.003880 | 8.693308 | NaN | NaN | . 4 -0.134680 | 30.351593 | 1 | 29.073130 | 6.369318 | 3.270907 | 45.044160 | 16.042707 | 250.0 | 14.327719 | ... | 2.450680 | 0.983537 | 89.721699 | 4.054211 | 20.201299 | 87.522511 | 4.271490 | 9.606041 | NaN | NaN | . 5 rows × 39 columns . null_cols = master_df_clean_numerical.isna().sum() cols_to_impute = null_cols[null_cols &gt; 0].index cols_to_impute = cols_to_impute.drop([&#39;total_events_adm4&#39;,&#39;total_fatalities_adm4&#39;]) # check cols_to_impute . Index([&#39;perc_hh_head_male&#39;, &#39;perc_pop612_primary&#39;, &#39;perc_pop1318_secondary&#39;, &#39;perc_pop18p_illiterate&#39;, &#39;perc_pop017_certificate&#39;, &#39;perc_pop017_both_parents&#39;, &#39;perc_pop2p_disability&#39;, &#39;perc_pop1017_married&#39;, &#39;perc_pop1217_birth&#39;, &#39;perc_pop1464_working&#39;, &#39;perc_pop10p_mobile_phone&#39;, &#39;perc_hh_temp_dwelling&#39;, &#39;perc_hh_mosquito_net&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;, &#39;perc_hh_own_house&#39;, &#39;perc_hh_own_tv&#39;, &#39;perc_hh_bank_acc&#39;, &#39;perc_hh_subs_farm&#39;, &#39;perc_hh_less2meals&#39;, &#39;perc_hh_electricity&#39;], dtype=&#39;object&#39;) . We have missing values because not all regions from our water point dataset match the official administrative regions. Water points for which the region is not recognisable ends up with a missing value. Here, we will first fill the null values for the demographic data with the median of its lowest level region we can attribute it to. We start with adm4. . for col in cols_to_impute: plt.figure() sns.distplot(master_df_clean_numerical[col]) plt.axvline(master_df_clean_numerical[col].mean(), c=&#39;r&#39;, label=&#39;mean&#39;) plt.axvline(master_df_clean_numerical[col].median(), c=&#39;gold&#39;, label=&#39;median&#39;) plt.legend() plt.title(f&#39;Density plot of {col}&#39;) plt.show() . These graphs show us that the median is a better alternative to mean as it is more representative of our dataset. . for col in cols_to_impute: missing_to_regional_median(master_df_clean, col, &#39;clean_adm4x&#39;) #checking remaining null values master_df_clean.isna().sum().sum() . 296831 . Since we still have missing values we fill missing values with the median of next lowest administrative leel, adm3. We go on until we do not have any more missing values. . for col in cols_to_impute: missing_to_regional_median(master_df_clean, col, &#39;clean_adm3&#39;) #checking remaining null values master_df_clean.isna().sum().sum() . 208721 . for col in cols_to_impute: missing_to_regional_median(master_df_clean, col, &#39;clean_adm2&#39;) #checking remaining null values master_df_clean.isna().sum().sum() . 202627 . for col in cols_to_impute: missing_to_regional_median(master_df_clean, col, &#39;clean_adm1&#39;) #checking remaining null values master_df_clean.isna().sum().sum() . 202627 . We end up inputting the country&#39;s median for the few remaining missing values. . for col in cols_to_impute: master_df_clean[col] = master_df_clean[col].fillna( master_df_clean[col].median()) # check remaining null values master_df_clean.isna().sum().sum() . 202627 . Missing values for fatalities/events essentially mean there were no conflicts or fatalities for that region since 1997. We assume that the conflict dataset we accessed was extensive and included all conflicts since 1997. . master_df_clean.isna().sum() for col in [&#39;total_fatalities_adm4&#39;,&#39;total_events_adm4&#39;]: master_df_clean[col] = master_df_clean[col].fillna(0) # check remaining null values master_df_clean.isna().sum().sum() . 54881 . date_converter(master_df_clean, &#39;install_year&#39;) #converting to year master_df_clean[&#39;install_year&#39;]=master_df_clean[&#39;install_year&#39;].dt.year #visualising distribution of installation year plt.figure() sns.histplot(master_df_clean[&#39;install_year&#39;]) plt.axvline(master_df_clean[&#39;install_year&#39;].mean(), c=&#39;r&#39;, label=&#39;mean&#39;) plt.axvline(master_df_clean[&#39;install_year&#39;].median(), c=&#39;gold&#39;, label=&#39;median&#39;) plt.legend() plt.title(f&#39;Density plot for installation year&#39;) plt.show() . We choose to create a binary column for the installation year. All water points constructed after 2006 are encoded with a 1, and all before are encoded 0. We choose 2006 because it was the first multi-party election in Uganda for 25 years. We consider this a an important enough turning point to differentiate between water points. As we see on the distribution above, we have a healthy balance of constructions before and after 2006. In addition, water points with missing installation year information are encoded with 0. We assume that if the installation year was unknown, it was probably because it was old (when bookeeping and official records were not as good). We would expect to see that water points constructed after 2006 might be of better quality due to a more democratic government and better technology. . Ideally we would look at how our binarisation impacts the correlation with our outcome variable. However, because of missing values, the install_year and status_id are of different lengths, making that analysis not possible. . master_df_clean[&#39;install_year&#39;] = np.where( master_df_clean[&#39;install_year&#39;] &gt;= 2006, 1, 0) #fill unknown years to 0 master_df_clean[&#39;install_year&#39;] = master_df_clean[&#39;install_year&#39;].fillna(0) #check master_df_clean[&#39;install_year&#39;].value_counts() . 0 70322 1 38584 Name: install_year, dtype: int64 . We consider entities from the government, public institutionsa to be a form of &quot;public&quot; management. We also include community management as we assume they are, in some way, related to local governments or governance structures. We also assume that they have similar goals and incentives to the more formal government institutions. Religious, health and medical facilities follow the same reasoning. It is interesting to see whether public or private management structures aremore likely to keep a water point functioning: although their goals are different, their incentives might still make them want to keep a water point working. . public_management=[&#39;Other Institutional Management&#39;, &#39;Direct Government Operation&#39;, &#39;Community Management&#39;, &#39;School Management&#39;,&#39;Religious Institution&#39;,&#39;Health Care Facility&#39; ] #dummy column into binary, public(1) or not public(0) master_df_clean[&#39;management_clean&#39;] = np.where( master_df_clean[&#39;management_clean&#39;].isin(public_management), 1, 0) #check master_df_clean[&#39;management_clean&#39;].value_counts() . 1 81283 0 27623 Name: management_clean, dtype: int64 . master_df_clean[&#39;water_source_clean&#39;].value_counts() . Borehole 40491 Protected Spring 28959 Rainwater Harvesting 16406 Protected Shallow Well 3137 Protected Well 1734 Piped Water 285 Undefined Shallow Well 207 Undefined Spring 161 Delivered Water 85 Sand or Sub-surface Dam 1 Packaged Water 1 Name: water_source_clean, dtype: int64 . We create a binary column identifying whether the water point technology is complex or not. We use analysis made by Ravi &amp; Rogger, 2021 to make this decision. . complex_tech=[&#39;Borehole&#39;, &#39;Piped Water&#39;, &#39;Sand or Sub-surface Dam&#39;, &#39;Packaged Water&#39;, &#39;Delivered Water&#39;] #dummy column into binary, complex techology(1) or not not(0) master_df_clean[&#39;water_source_clean&#39;] = np.where( master_df_clean[&#39;water_source_clean&#39;].isin(complex_tech), 1, 0) #check master_df_clean[&#39;water_source_clean&#39;].value_counts() . 0 68043 1 40863 Name: water_source_clean, dtype: int64 . master_df_clean.isna().sum().sum() . 1092 . master_df_clean.columns . Index([&#39;wpdx_id&#39;, &#39;lat_deg&#39;, &#39;lon_deg&#39;, &#39;status_id&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4x&#39;, &#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;, &#39;distance_to_town&#39;, &#39;usage_cap&#39;, &#39;staleness_score&#39;, &#39;cluster_size&#39;, &#39;water_source_clean&#39;, &#39;install_year&#39;, &#39;management_clean&#39;, &#39;served_population&#39;, &#39;local_population&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;perc_hh_head_male&#39;, &#39;perc_pop612_primary&#39;, &#39;perc_pop1318_secondary&#39;, &#39;perc_pop18p_illiterate&#39;, &#39;perc_pop017_certificate&#39;, &#39;perc_pop017_both_parents&#39;, &#39;perc_pop2p_disability&#39;, &#39;perc_pop1017_married&#39;, &#39;perc_pop1217_birth&#39;, &#39;perc_pop1464_working&#39;, &#39;perc_pop10p_mobile_phone&#39;, &#39;perc_hh_temp_dwelling&#39;, &#39;perc_hh_mosquito_net&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;, &#39;perc_hh_own_house&#39;, &#39;perc_hh_own_tv&#39;, &#39;perc_hh_bank_acc&#39;, &#39;perc_hh_subs_farm&#39;, &#39;perc_hh_less2meals&#39;, &#39;perc_hh_electricity&#39;, &#39;total_fatalities_adm4&#39;, &#39;total_events_adm4&#39;], dtype=&#39;object&#39;) . master_df_clean.rename(columns = {&#39;status_id&#39;:&#39;is_functioning&#39;, &#39;install_year&#39;:&#39;is_installed_after_2006&#39;, &#39;water_source_clean&#39;:&#39;is_complex_tech&#39;, &#39;management_clean&#39;:&#39;is_public_management&#39;,&#39;clean_adm4x&#39;:&#39;clean_adm4&#39; }, inplace = True) . We want to calculate what proportion of the local population is being served by the water point. . master_df_clean[&#39;perc_local_served&#39;]=(master_df_clean[&#39;served_population&#39;]/master_df_clean[&#39;local_population&#39;])*100 #check master_df_clean[[&#39;served_population&#39;, &#39;local_population&#39;, &#39;perc_local_served&#39;]].head() . served_population local_population perc_local_served . 0 18.5 | 283.5 | 6.525573 | . 1 35.0 | 274.0 | 12.773723 | . 2 18.5 | 283.5 | 6.525573 | . 3 1.0 | 25.0 | 4.000000 | . 4 34.0 | 366.0 | 9.289617 | . master_df_clean[&#39;perc_local_served&#39;].isna().sum() . 5332 . These are null values because the water point is essentially not servicing any of the local population. We can safely fill those null values with 0. . master_df_clean[&#39;perc_local_served&#39;]=master_df_clean[&#39;perc_local_served&#39;].fillna(0) #check master_df_clean[&#39;perc_local_served&#39;].isna().sum() . 0 . master_df_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 108906 entries, 0 to 108905 Data columns (total 48 columns): # Column Non-Null Count Dtype -- -- 0 wpdx_id 107814 non-null object 1 lat_deg 108906 non-null float64 2 lon_deg 108906 non-null float64 3 is_functioning 108906 non-null int64 4 clean_adm1 108906 non-null object 5 clean_adm2 108906 non-null object 6 clean_adm3 108906 non-null object 7 clean_adm4 108906 non-null object 8 distance_to_primary 108906 non-null float64 9 distance_to_secondary 108906 non-null float64 10 distance_to_tertiary 108906 non-null float64 11 distance_to_city 108906 non-null float64 12 distance_to_town 108906 non-null float64 13 usage_cap 108906 non-null float64 14 staleness_score 108906 non-null float64 15 cluster_size 108906 non-null float64 16 is_complex_tech 108906 non-null int64 17 is_installed_after_2006 108906 non-null int64 18 is_public_management 108906 non-null int64 19 served_population 108906 non-null float64 20 local_population 108906 non-null float64 21 crucialness 108906 non-null float64 22 pressure 108906 non-null float64 23 perc_hh_head_male 108906 non-null float64 24 perc_pop612_primary 108906 non-null float64 25 perc_pop1318_secondary 108906 non-null float64 26 perc_pop18p_illiterate 108906 non-null float64 27 perc_pop017_certificate 108906 non-null float64 28 perc_pop017_both_parents 108906 non-null float64 29 perc_pop2p_disability 108906 non-null float64 30 perc_pop1017_married 108906 non-null float64 31 perc_pop1217_birth 108906 non-null float64 32 perc_pop1464_working 108906 non-null float64 33 perc_pop10p_mobile_phone 108906 non-null float64 34 perc_hh_temp_dwelling 108906 non-null float64 35 perc_hh_mosquito_net 108906 non-null float64 36 perc_hh_piped_water 108906 non-null float64 37 perc_hh_borehole 108906 non-null float64 38 perc_hh_toilet 108906 non-null float64 39 perc_hh_own_house 108906 non-null float64 40 perc_hh_own_tv 108906 non-null float64 41 perc_hh_bank_acc 108906 non-null float64 42 perc_hh_subs_farm 108906 non-null float64 43 perc_hh_less2meals 108906 non-null float64 44 perc_hh_electricity 108906 non-null float64 45 total_fatalities_adm4 108906 non-null float64 46 total_events_adm4 108906 non-null float64 47 perc_local_served 108906 non-null float64 dtypes: float64(39), int64(4), object(5) memory usage: 40.7+ MB . print(f&quot;There are {master_df_clean.duplicated().sum()} duplicated rows.&quot;) master_df_clean_final=master_df_clean.drop_duplicates() print(f&quot;There are now {master_df_clean_final.duplicated().sum()} duplicated rows.&quot;) . There are 1722 duplicated rows. There are now 0 duplicated rows. . Our dataset is now ready for EDA, feature selection and modelling. We have no missing values, no duplicate rows, every column is interpretable and can be modelled. . master_df_clean_final.to_csv(data_filepath + &#39;ta_4_master_df.csv&#39;) . Image(dictionary_filepath+&quot;4A-Master-Dictionary.png&quot;) . Image(dictionary_filepath+&quot;4B-Master-Dictionary.png&quot;) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_05_master_dataframe.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_05_master_dataframe.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Conflict data",
            "content": "Accessing Conflict Data . Armed Conflict Location &amp; Event Data Website | API Guide | Dictionary | Codebook | Full Documentation | . Here, we are cleaning data from inidividual conflict events from the ACLED API. . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . %run /Users/thomasadler/Desktop/futuristic-platipus/keys.py . conflict_api_endpoint = &quot;https://api.acleddata.com/acled/read&quot; . We want to get every single conflict event that happened in Uganda since 1997 (the start of the dataset). . uganda_iso = 800 . conflict_r = requests.get( f&#39;{conflict_api_endpoint}?key={conflict_api_key}&amp;email={conflict_api_email}&amp;limit=0&amp;iso={uganda_iso}.csv&#39; ) #saving as json data data = conflict_r.json() #extract events information events = data[&#39;data&#39;] #save to a dataframe uganda_conflict = pd.DataFrame(events) . uganda_conflict_df = uganda_conflict.copy() . uganda_conflict_df.tail() . data_id iso event_id_cnty event_id_no_cnty event_date year time_precision event_type sub_event_type actor1 ... location latitude longitude geo_precision source source_scale notes fatalities timestamp iso3 . 7849 6876098 | 800 | UGA5 | 5 | 1997-01-11 | 1997 | 1 | Violence against civilians | Abduction/forced disappearance | LRA: Lords Resistance Army | ... | Acholi-Bur | 3.1258 | 32.9197 | 1 | New York Times | International | LRA abduct an unknown number of people taking ... | 0 | 1618581922 | UGA | . 7850 6876117 | 800 | UGA4 | 4 | 1997-01-08 | 1997 | 1 | Battles | Armed clash | Military Forces of Uganda (1986-) | ... | Kasese | 0.1833 | 30.0833 | 3 | Local Source | Subnational | Battle between Ugandan army and ADF rebels - 2... | 2 | 1618581759 | UGA | . 7851 6876122 | 800 | UGA3 | 3 | 1997-01-07 | 1997 | 1 | Battles | Armed clash | Military Forces of Uganda (1986-) | ... | Nyabani | 0.1358 | 30.3636 | 1 | Local Source | Subnational | 5 ADF rebels were killed when the Ugandan army... | 5 | 1618581598 | UGA | . 7852 6876154 | 800 | UGA1 | 1 | 1997-01-01 | 1997 | 3 | Battles | Armed clash | Military Forces of Uganda (1986-) | ... | Gulu | 2.7667 | 32.3056 | 3 | Africa Research Bulletin | Other | Ugandan army battled with LRA rebels - 4 rebel... | 4 | 1618581296 | UGA | . 7853 6876155 | 800 | UGA2 | 2 | 1997-01-01 | 1997 | 3 | Battles | Armed clash | Military Forces of Uganda (1986-) | ... | Mityana | 0.4015 | 32.0452 | 3 | Africa Research Bulletin | Other | Over 20 rebel groups believed to belong to Dun... | 5 | 1618581439 | UGA | . 5 rows × 31 columns . uganda_conflict_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 7854 entries, 0 to 7853 Data columns (total 31 columns): # Column Non-Null Count Dtype -- -- 0 data_id 7854 non-null object 1 iso 7854 non-null object 2 event_id_cnty 7854 non-null object 3 event_id_no_cnty 7854 non-null object 4 event_date 7854 non-null object 5 year 7854 non-null object 6 time_precision 7854 non-null object 7 event_type 7854 non-null object 8 sub_event_type 7854 non-null object 9 actor1 7854 non-null object 10 assoc_actor_1 7854 non-null object 11 inter1 7854 non-null object 12 actor2 7854 non-null object 13 assoc_actor_2 7854 non-null object 14 inter2 7854 non-null object 15 interaction 7854 non-null object 16 region 7854 non-null object 17 country 7854 non-null object 18 admin1 7854 non-null object 19 admin2 7854 non-null object 20 admin3 7854 non-null object 21 location 7854 non-null object 22 latitude 7854 non-null object 23 longitude 7854 non-null object 24 geo_precision 7854 non-null object 25 source 7854 non-null object 26 source_scale 7854 non-null object 27 notes 7854 non-null object 28 fatalities 7854 non-null object 29 timestamp 7854 non-null object 30 iso3 7854 non-null object dtypes: object(31) memory usage: 1.9+ MB . num_columns = [ &#39;latitude&#39;, &#39;longitude&#39;, &#39;fatalities&#39;, ] for col in num_columns: float_converter(uganda_conflict_df, col) #check uganda_conflict_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 7854 entries, 0 to 7853 Data columns (total 31 columns): # Column Non-Null Count Dtype -- -- 0 data_id 7854 non-null object 1 iso 7854 non-null object 2 event_id_cnty 7854 non-null object 3 event_id_no_cnty 7854 non-null object 4 event_date 7854 non-null object 5 year 7854 non-null object 6 time_precision 7854 non-null object 7 event_type 7854 non-null object 8 sub_event_type 7854 non-null object 9 actor1 7854 non-null object 10 assoc_actor_1 7854 non-null object 11 inter1 7854 non-null object 12 actor2 7854 non-null object 13 assoc_actor_2 7854 non-null object 14 inter2 7854 non-null object 15 interaction 7854 non-null object 16 region 7854 non-null object 17 country 7854 non-null object 18 admin1 7854 non-null object 19 admin2 7854 non-null object 20 admin3 7854 non-null object 21 location 7854 non-null object 22 latitude 7854 non-null float32 23 longitude 7854 non-null float32 24 geo_precision 7854 non-null object 25 source 7854 non-null object 26 source_scale 7854 non-null object 27 notes 7854 non-null object 28 fatalities 7854 non-null float32 29 timestamp 7854 non-null object 30 iso3 7854 non-null object dtypes: float32(3), object(28) memory usage: 1.8+ MB . date_converter(uganda_conflict_df, &#39;event_date&#39;) #check uganda_conflict_df[&#39;event_date&#39;] . 0 2022-07-28 1 2022-07-28 2 2022-07-27 3 2022-07-27 4 2022-07-27 ... 7849 1997-01-11 7850 1997-01-08 7851 1997-01-07 7852 1997-01-01 7853 1997-01-01 Name: event_date, Length: 7854, dtype: datetime64[ns] . uganda_conflict_df=pd.DataFrame(uganda_conflict_df.drop(columns=[&#39;time_precision&#39;, &#39;event_id_cnty&#39;,&#39;event_id_no_cnty&#39;, &#39;geo_precision&#39;,&#39;timestamp&#39;,&#39;year&#39;, &#39;iso&#39;,&#39;iso3&#39;, &#39;region&#39;,&#39;country&#39;])) #check current columns uganda_conflict_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 7854 entries, 0 to 7853 Data columns (total 21 columns): # Column Non-Null Count Dtype -- -- 0 data_id 7854 non-null object 1 event_date 7854 non-null datetime64[ns] 2 event_type 7854 non-null object 3 sub_event_type 7854 non-null object 4 actor1 7854 non-null object 5 assoc_actor_1 7854 non-null object 6 inter1 7854 non-null object 7 actor2 7854 non-null object 8 assoc_actor_2 7854 non-null object 9 inter2 7854 non-null object 10 interaction 7854 non-null object 11 admin1 7854 non-null object 12 admin2 7854 non-null object 13 admin3 7854 non-null object 14 location 7854 non-null object 15 latitude 7854 non-null float32 16 longitude 7854 non-null float32 17 source 7854 non-null object 18 source_scale 7854 non-null object 19 notes 7854 non-null object 20 fatalities 7854 non-null float32 dtypes: datetime64[ns](1), float32(3), object(17) memory usage: 1.2+ MB . print( &#39;admin1 in the conflict dataset should be clean_adm1 in the water dataset, check with:&#39;, uganda_conflict_df[&#39;admin1&#39;].head(1)[0]) print( &#39;admin2 in the conflict dataset should be clean_adm2 in the water dataset, check with:&#39;, uganda_conflict_df[&#39;admin2&#39;].head(1)[0]) print( &#39;admin3 in the conflict dataset should be clean_adm3 in the water dataset, check with:&#39;, uganda_conflict_df[&#39;admin3&#39;].head(1)[0]) print( &#39;location in the conflict dataset should be clean_adm4 in the water dataset, check with:&#39;, uganda_conflict_df[&#39;location&#39;].head(1)[0]) . admin1 in the conflict dataset should be clean_adm1 in the water dataset, check with: Northern admin2 in the conflict dataset should be clean_adm2 in the water dataset, check with: Napak admin3 in the conflict dataset should be clean_adm3 in the water dataset, check with: Bokora location in the conflict dataset should be clean_adm4 in the water dataset, check with: Kalokengel . uganda_conflict_df.rename(columns={ &#39;admin1&#39;: &#39;clean_adm1&#39;, &#39;admin2&#39;: &#39;clean_adm2&#39;, &#39;admin3&#39;: &#39;clean_adm3&#39;, &#39;location&#39;: &#39;clean_adm4&#39; }, inplace=True) . print(uganda_conflict_df.isna().sum().sum()&gt;0, uganda_conflict_df.duplicated().sum()&gt;0, uganda_conflict_df.T.duplicated().sum()&gt;0) . False False False . uganda_conflict_df.to_csv(data_filepath + &#39;ta_3_conflict_df_clean.csv&#39;) . Image(dictionary_filepath+&quot;3A-Conflict-Dictionary.png&quot;) . uganda_conflict_df_upper = uganda_conflict_df.copy() . for col in[&#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4&#39;]: uganda_conflict_df_upper[col] = uganda_conflict_df_upper[col].str.upper() #export to cleaned dataset to csv uganda_conflict_df_upper.to_csv(data_filepath + &#39;ta_3_conflict_df_clean_upper.csv&#39;) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_04_access_conflict_data.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_04_access_conflict_data.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "Demographic data",
            "content": "Accessing Demographic Data . Uganda Department of Statistics Website | Dataset Repository | . We will clean and prepare regional demographic data for further analysis. . %run /Users/thomasadler/Desktop/futuristic-platipus/notebooks/ta_01_packages_functions.py . We have manually chosen the relevant columns from the Ugandan Statistics datasets for multiple reasons: . every region (4) has its own dataset, with inconsistent naming of columns and sheets | there are multiple sheets within each excel workbook, each with an inconsistent number of indexes | manually choosing an initial set of relevant variables is easier when visualizing the full names in an excel workbook and comparing those with other columns | the number of data points is manageable in excel and does not run the risk of the data being cut | minimal data processing has been carried out to avoid any mistakes | . regions_df = [&#39;eastern&#39;, &#39;western&#39;, &#39;central&#39;, &#39;northern&#39;] . eastern_df = pd.DataFrame(pd.read_excel( f&#39;{data_filepath}{regions_df[0]}_demographic.xlsx&#39;)) western_df = pd.DataFrame(pd.read_excel( f&#39;{data_filepath}{regions_df[1]}_demographic.xlsx&#39;)) central_df = pd.DataFrame(pd.read_excel( f&#39;{data_filepath}{regions_df[2]}_demographic.xlsx&#39;)) northern_df = pd.DataFrame(pd.read_excel( f&#39;{data_filepath}{regions_df[3]}_demographic.xlsx&#39;)) . regions_df = [eastern_df, western_df, central_df, northern_df] . demographic = pd.concat(regions_df, axis=0) # check demographic.head() . subcounty parish tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability ... perc_hh_mosquito_net perc_hh_piped_water perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity . 0 Eastern Division | Naluwerere | 5878 | 74.8 | 91.5 | 49.9 | 29.0 | 31.4 | 92.4 | 8.9 | ... | 83.5 | 20.1 | 59.4 | 5.0 | 55.8 | 12.8 | 23.1 | 38.4 | 6.3 | 19.5 | . 1 Eastern Division | Nkusi | 7946 | 74.3 | 88.7 | 58.2 | 14.9 | 41.9 | 93.6 | 7.8 | ... | 86.9 | 34.3 | 10.6 | 1.1 | 25.9 | 33.3 | 44.3 | 12.1 | 8.3 | 44.9 | . 2 Western Division | Bwole | 8370 | 74.5 | 90.9 | 56.8 | 14.1 | 41.9 | 92.8 | 9.7 | ... | 89.7 | 29.7 | 26.9 | 1.2 | 38.4 | 27.8 | 43.8 | 23.7 | 8.4 | 37.4 | . 3 Western Division | Ndifakulya | 6553 | 73.4 | 87.6 | 55.0 | 16.2 | 46.6 | 93.7 | 10.3 | ... | 87.5 | 22.8 | 22.6 | 1.8 | 37.1 | 27.1 | 37.4 | 28.6 | 6.7 | 35.1 | . 4 Budhaya | Budhaya | 5796 | 84.3 | 88.8 | 23.4 | 45.2 | 27.6 | 95.1 | 9.1 | ... | 80.1 | 0.2 | 96.8 | 13.1 | 88.9 | 1.1 | 9.2 | 81.7 | 5.9 | 6.1 | . 5 rows × 29 columns . total_demographic = demographic.copy() . total_demographic.head() . subcounty parish tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability ... perc_hh_mosquito_net perc_hh_piped_water perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity . 0 Eastern Division | Naluwerere | 5878 | 74.8 | 91.5 | 49.9 | 29.0 | 31.4 | 92.4 | 8.9 | ... | 83.5 | 20.1 | 59.4 | 5.0 | 55.8 | 12.8 | 23.1 | 38.4 | 6.3 | 19.5 | . 1 Eastern Division | Nkusi | 7946 | 74.3 | 88.7 | 58.2 | 14.9 | 41.9 | 93.6 | 7.8 | ... | 86.9 | 34.3 | 10.6 | 1.1 | 25.9 | 33.3 | 44.3 | 12.1 | 8.3 | 44.9 | . 2 Western Division | Bwole | 8370 | 74.5 | 90.9 | 56.8 | 14.1 | 41.9 | 92.8 | 9.7 | ... | 89.7 | 29.7 | 26.9 | 1.2 | 38.4 | 27.8 | 43.8 | 23.7 | 8.4 | 37.4 | . 3 Western Division | Ndifakulya | 6553 | 73.4 | 87.6 | 55.0 | 16.2 | 46.6 | 93.7 | 10.3 | ... | 87.5 | 22.8 | 22.6 | 1.8 | 37.1 | 27.1 | 37.4 | 28.6 | 6.7 | 35.1 | . 4 Budhaya | Budhaya | 5796 | 84.3 | 88.8 | 23.4 | 45.2 | 27.6 | 95.1 | 9.1 | ... | 80.1 | 0.2 | 96.8 | 13.1 | 88.9 | 1.1 | 9.2 | 81.7 | 5.9 | 6.1 | . 5 rows × 29 columns . total_demographic.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 7557 entries, 0 to 1650 Data columns (total 29 columns): # Column Non-Null Count Dtype -- -- 0 subcounty 7557 non-null object 1 parish 7557 non-null object 2 tot_pop_parish 7557 non-null int64 3 perc_hh_head_male 7557 non-null float64 4 perc_pop612_primary 7557 non-null float64 5 perc_pop1318_secondary 7557 non-null float64 6 perc_pop18p_illiterate 7557 non-null float64 7 perc_pop017_certificate 7557 non-null float64 8 perc_pop017_both_parents 7557 non-null float64 9 perc_pop2p_disability 7557 non-null float64 10 perc_pop1017_married 7557 non-null float64 11 perc_pop1217_birth 7557 non-null float64 12 perc_pop1464_working 7557 non-null float64 13 perc_pop10p_mobile_phone 7557 non-null float64 14 perc_hh_temp_dwelling 7502 non-null float64 15 perc_pop_5km_dist_primary 7556 non-null float64 16 perc_pop_5km_dist_secondary 7557 non-null float64 17 perc_pop_5km_dist_health 7557 non-null float64 18 perc_pop_5km_dist_police 7557 non-null float64 19 perc_hh_mosquito_net 7557 non-null float64 20 perc_hh_piped_water 7555 non-null float64 21 perc_hh_borehole 7552 non-null float64 22 perc_hh_toilet 7540 non-null float64 23 perc_hh_own_house 7557 non-null float64 24 perc_hh_own_tv 7557 non-null float64 25 perc_hh_bank_acc 7557 non-null float64 26 perc_hh_subs_farm 7557 non-null float64 27 perc_hh_less2meals 7557 non-null float64 28 perc_hh_electricity 7557 non-null float64 dtypes: float64(26), int64(1), object(2) memory usage: 1.7+ MB . total_demographic.isna().sum() . subcounty 0 parish 0 tot_pop_parish 0 perc_hh_head_male 0 perc_pop612_primary 0 perc_pop1318_secondary 0 perc_pop18p_illiterate 0 perc_pop017_certificate 0 perc_pop017_both_parents 0 perc_pop2p_disability 0 perc_pop1017_married 0 perc_pop1217_birth 0 perc_pop1464_working 0 perc_pop10p_mobile_phone 0 perc_hh_temp_dwelling 55 perc_pop_5km_dist_primary 1 perc_pop_5km_dist_secondary 0 perc_pop_5km_dist_health 0 perc_pop_5km_dist_police 0 perc_hh_mosquito_net 0 perc_hh_piped_water 2 perc_hh_borehole 5 perc_hh_toilet 17 perc_hh_own_house 0 perc_hh_own_tv 0 perc_hh_bank_acc 0 perc_hh_subs_farm 0 perc_hh_less2meals 0 perc_hh_electricity 0 dtype: int64 . We fill missing values of a parish by its subcounty average. Due to the low number of missing values, we assume that the average is a good representation of the subcounty&#39;s situation. . null_cols = total_demographic.isna().sum() cols_to_impute = null_cols[null_cols &gt; 0].index # check cols_to_impute . Index([&#39;perc_hh_temp_dwelling&#39;, &#39;perc_pop_5km_dist_primary&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;], dtype=&#39;object&#39;) . for col in cols_to_impute: missing_to_regional_median(total_demographic, col, &#39;subcounty&#39;) # check total_demographic.isna().sum() . subcounty 0 parish 0 tot_pop_parish 0 perc_hh_head_male 0 perc_pop612_primary 0 perc_pop1318_secondary 0 perc_pop18p_illiterate 0 perc_pop017_certificate 0 perc_pop017_both_parents 0 perc_pop2p_disability 0 perc_pop1017_married 0 perc_pop1217_birth 0 perc_pop1464_working 0 perc_pop10p_mobile_phone 0 perc_hh_temp_dwelling 7 perc_pop_5km_dist_primary 0 perc_pop_5km_dist_secondary 0 perc_pop_5km_dist_health 0 perc_pop_5km_dist_police 0 perc_hh_mosquito_net 0 perc_hh_piped_water 0 perc_hh_borehole 0 perc_hh_toilet 2 perc_hh_own_house 0 perc_hh_own_tv 0 perc_hh_bank_acc 0 perc_hh_subs_farm 0 perc_hh_less2meals 0 perc_hh_electricity 0 dtype: int64 . null_cols2 = total_demographic.isna().sum() cols_to_impute2 = null_cols[null_cols &gt; 0].index # check cols_to_impute2 . Index([&#39;perc_hh_temp_dwelling&#39;, &#39;perc_pop_5km_dist_primary&#39;, &#39;perc_hh_piped_water&#39;, &#39;perc_hh_borehole&#39;, &#39;perc_hh_toilet&#39;], dtype=&#39;object&#39;) . For those that still have missing values, due to the fact that the whole subcounty does not have values, we fill the missing values with the country&#39;s average. . for col in cols_to_impute2: total_demographic[col] = total_demographic[col].fillna( total_demographic[col].mean()) # check no more null values total_demographic.isna().sum().sum() == 0 . True . total_demographic.duplicated().sum() == 0 . True . total_demographic.T.duplicated().sum() == 0 . True . We have information for each parish, however we need data for each subcounty. We will use population as a proxy to calculate the weight of each parish in a subcounty. We then calculate a weighted average of parishes to get subcounty values. . tot_pop_subcounty = total_demographic[[ &#39;subcounty&#39;, &#39;tot_pop_parish&#39;]].groupby(&#39;subcounty&#39;).sum() # rename column tot_pop_subcounty.columns = [&#39;tot_pop_subcounty&#39;] # check tot_pop_subcounty . tot_pop_subcounty . subcounty . Abako 24329 | . Abanga 17613 | . Abarilela 24290 | . Aber 33366 | . Abia 23436 | . ... ... | . Yumbe Town Council 34806 | . Zesui 10782 | . Zeu 35354 | . Zirobwe 44992 | . Zombo Town Council 12091 | . 1382 rows × 1 columns . total_demographic = total_demographic.merge( tot_pop_subcounty, how=&#39;left&#39;, on=&#39;subcounty&#39;) # check total_demographic.head() . subcounty parish tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability ... perc_hh_piped_water perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty . 0 Eastern Division | Naluwerere | 5878 | 74.8 | 91.5 | 49.9 | 29.0 | 31.4 | 92.4 | 8.9 | ... | 20.1 | 59.4 | 5.0 | 55.8 | 12.8 | 23.1 | 38.4 | 6.3 | 19.5 | 146794 | . 1 Eastern Division | Nkusi | 7946 | 74.3 | 88.7 | 58.2 | 14.9 | 41.9 | 93.6 | 7.8 | ... | 34.3 | 10.6 | 1.1 | 25.9 | 33.3 | 44.3 | 12.1 | 8.3 | 44.9 | 146794 | . 2 Western Division | Bwole | 8370 | 74.5 | 90.9 | 56.8 | 14.1 | 41.9 | 92.8 | 9.7 | ... | 29.7 | 26.9 | 1.2 | 38.4 | 27.8 | 43.8 | 23.7 | 8.4 | 37.4 | 169457 | . 3 Western Division | Ndifakulya | 6553 | 73.4 | 87.6 | 55.0 | 16.2 | 46.6 | 93.7 | 10.3 | ... | 22.8 | 22.6 | 1.8 | 37.1 | 27.1 | 37.4 | 28.6 | 6.7 | 35.1 | 169457 | . 4 Budhaya | Budhaya | 5796 | 84.3 | 88.8 | 23.4 | 45.2 | 27.6 | 95.1 | 9.1 | ... | 0.2 | 96.8 | 13.1 | 88.9 | 1.1 | 9.2 | 81.7 | 5.9 | 6.1 | 28472 | . 5 rows × 30 columns . total_demographic[&#39;weight&#39;] = total_demographic[&#39;tot_pop_parish&#39;] / total_demographic[&#39;tot_pop_subcounty&#39;] # check all weights equal to one total_demographic[[&#39;subcounty&#39;, &#39;weight&#39;]].groupby(&#39;subcounty&#39;).sum( ).sum() == len(total_demographic[[&#39;subcounty&#39;]].groupby(&#39;subcounty&#39;)) . weight True dtype: bool . total_demographic.iloc[:, 2:-1] = total_demographic.iloc[:, 2:-1].multiply(total_demographic[&#39;weight&#39;], axis=&#39;index&#39;) # check total_demographic.head() . subcounty parish tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability ... perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty weight . 0 Eastern Division | Naluwerere | 235.369865 | 2.995180 | 3.663890 | 1.998121 | 1.161233 | 1.257335 | 3.699928 | 0.356378 | ... | 2.378525 | 0.200213 | 2.234372 | 0.512544 | 0.924982 | 1.537632 | 0.252268 | 0.780829 | 5878.0 | 0.040043 | . 1 Eastern Division | Nkusi | 430.119187 | 4.021880 | 4.801356 | 3.150382 | 0.806541 | 2.268059 | 5.066594 | 0.422216 | ... | 0.573781 | 0.059543 | 1.401974 | 1.802538 | 2.397971 | 0.654976 | 0.449281 | 2.430449 | 7946.0 | 0.054130 | . 2 Western Division | Bwole | 413.419924 | 3.679783 | 4.489829 | 2.805526 | 0.696442 | 2.069569 | 4.583676 | 0.479113 | ... | 1.328673 | 0.059272 | 1.896694 | 1.373127 | 2.163416 | 1.170616 | 0.414902 | 1.847300 | 8370.0 | 0.049393 | . 3 Western Division | Ndifakulya | 253.408292 | 2.838420 | 3.387543 | 2.126882 | 0.626463 | 1.802049 | 3.623433 | 0.398307 | ... | 0.873955 | 0.069607 | 1.434678 | 1.047973 | 1.446280 | 1.105979 | 0.259093 | 1.357337 | 6553.0 | 0.038671 | . 4 Budhaya | Budhaya | 1179.882551 | 17.160818 | 18.076876 | 4.763501 | 9.201292 | 5.618488 | 19.359357 | 1.852473 | ... | 19.705423 | 2.666746 | 18.097232 | 0.223925 | 1.872829 | 16.631540 | 1.201054 | 1.241767 | 5796.0 | 0.203568 | . 5 rows × 31 columns . subcounty_demographic = total_demographic.groupby(&#39;subcounty&#39;).sum() # check that no column is more than 100 (except for population) subcounty_demographic.describe() . tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability perc_pop1017_married perc_pop1217_birth ... perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty weight . count 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | ... | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1382.000000 | 1.382000e+03 | . mean 5325.183537 | 77.089347 | 80.701635 | 29.792665 | 33.362797 | 29.141930 | 91.772449 | 13.642423 | 6.564745 | 8.538391 | ... | 37.962323 | 11.096495 | 81.550674 | 6.662546 | 17.433289 | 79.303604 | 11.223005 | 12.089956 | 25061.251809 | 1.000000e+00 | . std 4841.601497 | 5.125613 | 12.615068 | 9.577757 | 13.373853 | 14.973238 | 2.422723 | 5.800347 | 2.818645 | 3.914319 | ... | 32.345151 | 16.196412 | 17.098956 | 10.063932 | 11.286255 | 20.531131 | 9.146918 | 12.956311 | 28004.997066 | 8.450033e-18 | . min 565.125115 | 43.296939 | 6.469903 | 3.019500 | 5.159501 | 1.896132 | 80.607712 | 2.400000 | 1.100000 | 2.060516 | ... | 0.000000 | 0.000000 | 12.806064 | 0.197382 | 1.831688 | 1.191364 | 1.683737 | 0.483304 | 1981.000000 | 1.000000e+00 | . 25% 2922.142298 | 73.772953 | 78.781441 | 23.387518 | 25.688698 | 17.218885 | 90.523072 | 10.025470 | 4.636206 | 5.890590 | ... | 6.476420 | 2.043361 | 74.093670 | 1.523332 | 9.782145 | 76.522410 | 5.850080 | 4.837981 | 12767.750000 | 1.000000e+00 | . 50% 4349.144386 | 77.310364 | 83.761165 | 28.671131 | 32.654889 | 27.438227 | 91.900018 | 12.706115 | 6.001666 | 7.714616 | ... | 30.362959 | 5.215642 | 87.873951 | 3.117658 | 13.599117 | 87.469722 | 9.005092 | 7.857371 | 19268.000000 | 1.000000e+00 | . 75% 6264.462068 | 80.759590 | 86.656814 | 35.128398 | 39.105892 | 38.857003 | 93.368579 | 16.113406 | 7.951506 | 10.177006 | ... | 66.655302 | 12.242853 | 94.402075 | 7.030110 | 22.011153 | 92.201184 | 12.783530 | 13.648965 | 30635.000000 | 1.000000e+00 | . max 81962.015179 | 89.136705 | 94.120353 | 59.603670 | 95.163615 | 89.807095 | 96.771055 | 70.398504 | 24.485364 | 53.852961 | ... | 99.463761 | 96.092403 | 99.200501 | 69.874708 | 72.581032 | 98.034043 | 70.340232 | 85.396092 | 425070.000000 | 1.000000e+00 | . 8 rows × 29 columns . subcounty_demographic.reset_index(inplace=True) # check subcounty_demographic.head() . subcounty tot_pop_parish perc_hh_head_male perc_pop612_primary perc_pop1318_secondary perc_pop18p_illiterate perc_pop017_certificate perc_pop017_both_parents perc_pop2p_disability perc_pop1017_married ... perc_hh_borehole perc_hh_toilet perc_hh_own_house perc_hh_own_tv perc_hh_bank_acc perc_hh_subs_farm perc_hh_less2meals perc_hh_electricity tot_pop_subcounty weight . 0 Abako | 4980.425131 | 77.188397 | 73.638242 | 23.234560 | 37.155288 | 40.631497 | 89.292223 | 19.016807 | 5.219919 | ... | 27.780579 | 11.052814 | 97.636623 | 0.733992 | 9.180801 | 93.104768 | 11.556529 | 3.969103 | 24329.0 | 1.0 | . 1 Abanga | 3657.634645 | 74.663209 | 49.826100 | 8.726509 | 56.078805 | 6.268466 | 91.904968 | 16.344297 | 8.435729 | ... | 4.249634 | 17.929563 | 94.744581 | 0.576716 | 9.267484 | 92.562215 | 4.859519 | 3.101715 | 17613.0 | 1.0 | . 2 Abarilela | 4316.878551 | 71.659304 | 82.324026 | 23.733903 | 43.352421 | 32.763751 | 92.361029 | 16.989201 | 4.838436 | ... | 96.878987 | 32.313685 | 95.087715 | 1.206439 | 11.167011 | 95.398728 | 14.410782 | 13.117472 | 24290.0 | 1.0 | . 3 Aber | 8844.329617 | 75.875232 | 76.815372 | 22.464650 | 37.663891 | 39.250420 | 91.166310 | 12.758754 | 10.031098 | ... | 72.613025 | 9.453135 | 95.480702 | 1.503926 | 8.704004 | 93.712237 | 6.937463 | 6.639306 | 33366.0 | 1.0 | . 4 Abia | 3923.494880 | 79.001784 | 74.058850 | 22.057540 | 35.890114 | 28.721663 | 89.266701 | 16.557975 | 9.301314 | ... | 42.406439 | 14.932744 | 98.024441 | 0.811487 | 9.335049 | 94.918928 | 21.129971 | 4.331349 | 23436.0 | 1.0 | . 5 rows × 30 columns . subcounty_demographic_clean = pd.DataFrame( subcounty_demographic.drop(columns=[&#39;weight&#39;, &#39;tot_pop_parish&#39;])) # check current columns subcounty_demographic_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1382 entries, 0 to 1381 Data columns (total 28 columns): # Column Non-Null Count Dtype -- -- 0 subcounty 1382 non-null object 1 perc_hh_head_male 1382 non-null float64 2 perc_pop612_primary 1382 non-null float64 3 perc_pop1318_secondary 1382 non-null float64 4 perc_pop18p_illiterate 1382 non-null float64 5 perc_pop017_certificate 1382 non-null float64 6 perc_pop017_both_parents 1382 non-null float64 7 perc_pop2p_disability 1382 non-null float64 8 perc_pop1017_married 1382 non-null float64 9 perc_pop1217_birth 1382 non-null float64 10 perc_pop1464_working 1382 non-null float64 11 perc_pop10p_mobile_phone 1382 non-null float64 12 perc_hh_temp_dwelling 1382 non-null float64 13 perc_pop_5km_dist_primary 1382 non-null float64 14 perc_pop_5km_dist_secondary 1382 non-null float64 15 perc_pop_5km_dist_health 1382 non-null float64 16 perc_pop_5km_dist_police 1382 non-null float64 17 perc_hh_mosquito_net 1382 non-null float64 18 perc_hh_piped_water 1382 non-null float64 19 perc_hh_borehole 1382 non-null float64 20 perc_hh_toilet 1382 non-null float64 21 perc_hh_own_house 1382 non-null float64 22 perc_hh_own_tv 1382 non-null float64 23 perc_hh_bank_acc 1382 non-null float64 24 perc_hh_subs_farm 1382 non-null float64 25 perc_hh_less2meals 1382 non-null float64 26 perc_hh_electricity 1382 non-null float64 27 tot_pop_subcounty 1382 non-null float64 dtypes: float64(27), object(1) memory usage: 302.4+ KB . subcounty_demographic_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1382 entries, 0 to 1381 Data columns (total 28 columns): # Column Non-Null Count Dtype -- -- 0 subcounty 1382 non-null object 1 perc_hh_head_male 1382 non-null float64 2 perc_pop612_primary 1382 non-null float64 3 perc_pop1318_secondary 1382 non-null float64 4 perc_pop18p_illiterate 1382 non-null float64 5 perc_pop017_certificate 1382 non-null float64 6 perc_pop017_both_parents 1382 non-null float64 7 perc_pop2p_disability 1382 non-null float64 8 perc_pop1017_married 1382 non-null float64 9 perc_pop1217_birth 1382 non-null float64 10 perc_pop1464_working 1382 non-null float64 11 perc_pop10p_mobile_phone 1382 non-null float64 12 perc_hh_temp_dwelling 1382 non-null float64 13 perc_pop_5km_dist_primary 1382 non-null float64 14 perc_pop_5km_dist_secondary 1382 non-null float64 15 perc_pop_5km_dist_health 1382 non-null float64 16 perc_pop_5km_dist_police 1382 non-null float64 17 perc_hh_mosquito_net 1382 non-null float64 18 perc_hh_piped_water 1382 non-null float64 19 perc_hh_borehole 1382 non-null float64 20 perc_hh_toilet 1382 non-null float64 21 perc_hh_own_house 1382 non-null float64 22 perc_hh_own_tv 1382 non-null float64 23 perc_hh_bank_acc 1382 non-null float64 24 perc_hh_subs_farm 1382 non-null float64 25 perc_hh_less2meals 1382 non-null float64 26 perc_hh_electricity 1382 non-null float64 27 tot_pop_subcounty 1382 non-null float64 dtypes: float64(27), object(1) memory usage: 302.4+ KB . print(subcounty_demographic_clean.isna().sum().sum() &gt; 0, subcounty_demographic_clean.duplicated().sum() &gt; 0, subcounty_demographic_clean.T.duplicated().sum() &gt; 0) . False False False . subcounty_demographic_clean.rename( columns={&#39;subcounty&#39;: &#39;clean_adm4&#39;}, inplace=True) . subcounty_demographic_clean.to_csv(data_filepath+&#39;ta_2_subcounty_demographic_clean.csv&#39;) . Image(dictionary_filepath+&quot;2A-Demographic-Dictionary.png&quot;) .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_03_access_demographic_data.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_03_access_demographic_data.html",
            "date": " • Aug 16, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "Water point data",
            "content": "Business Problem . Uganda and sub-saharan Africa lack access to basic water services. Not having access to water puts lives at risk through improper sanitation, dehydration. It also reinforce the cycle of poverty and heavily impacts a population that heavily relies on subsistence farming. We want to enable the Ugandan government to repair water point quicker so citizens can have their basic needs and help communities develop and prosper. . Machine Learning Problem . Can we predict the functionality of water infrastructure to repair them quicker using Machine Learning? . Accessing Water Data . Water Point Data Exchange Website | API Guide and Dictionary | Documentation | . We will be accessing water point data from the source above. This notebook will do some initial cleaning and preparing for further analysis. . %run /Users/thomasadler/Desktop/futuristic-platipus/capstone/notebooks/ta_01_packages_functions.py . /Users/thomasadler/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. from pandas import MultiIndex, Int64Index . %run /Users/thomasadler/Desktop/futuristic-platipus/keys.py . Image(images_filepath+&quot;wpdx-api.png&quot;) . socrata_domain = &#39;data.waterpointdata.org&#39; socrata_dataset_identifier = &#39;eqje-vguj&#39; socrata_token = os.environ.get(water_api_key) client = Socrata(socrata_domain, socrata_token, timeout=10) . WARNING:root:Requests made without an app_token will be subject to strict throttling limits. . The goal is to access every water point recorded in Uganda, all the information associated with that water point and put a very high limit, so we make sure we have accessed all possible points. . water_uganda_query = &quot;&quot;&quot; select * where clean_country_name = &#39;Uganda&#39; limit 200000 &quot;&quot;&quot; . results = client.get(socrata_dataset_identifier, query=water_uganda_query) water_df = pd.DataFrame.from_records(results) . uganda_water_df = water_df.copy() . uganda_water_df.tail() . row_id source lat_deg lon_deg report_date status_id water_tech_clean _water_tech_category facility_type clean_country_name ... subjective_quality scheme_id notes photo_lnk lat_deg_original lon_deg_original fecal_coliform_presence installer orig_lnk fecal_coliform_value . 108901 374602 | Ugandan Water Project | 0.6758382999999955 | 32.4640283 | 2022-09-04T00:00:00.000 | Yes | Hand Pump - India Mark II | Hand Pump | Improved | Uganda | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ugandan Water Project (rehabilitation) | NaN | NaN | . 108902 374581 | Ugandan Water Project | 0.6553664659999812 | 32.472553197 | 2022-11-05T00:00:00.000 | Yes | NaN | NaN | Improved | Uganda | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ugandan Water Project | NaN | NaN | . 108903 374572 | Ugandan Water Project | 0.692485682666941 | 32.66798296946349 | 2022-06-30T00:00:00.000 | Yes | NaN | NaN | Improved | Uganda | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ugandan Water Project | NaN | NaN | . 108904 374644 | Ugandan Water Project | 0.18494999999998163 | 32.3369641 | 2022-09-06T00:00:00.000 | Yes | Hand Pump - India Mark II | Hand Pump | Improved | Uganda | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ugandan Water Project (rehabilitation) | NaN | NaN | . 108905 374660 | Ugandan Water Project | 0.5684852999999981 | 32.80591690000001 | 2022-09-05T00:00:00.000 | Yes | Hand Pump - India Mark II | Hand Pump | Improved | Uganda | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ugandan Water Project (rehabilitation) | NaN | NaN | . 5 rows × 67 columns . uganda_water_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 108906 entries, 0 to 108905 Data columns (total 67 columns): # Column Non-Null Count Dtype -- -- 0 row_id 108906 non-null object 1 source 108906 non-null object 2 lat_deg 108906 non-null object 3 lon_deg 108906 non-null object 4 report_date 108906 non-null object 5 status_id 108906 non-null object 6 water_tech_clean 26226 non-null object 7 _water_tech_category 26226 non-null object 8 facility_type 108906 non-null object 9 clean_country_name 108906 non-null object 10 clean_adm1 108906 non-null object 11 clean_adm2 108906 non-null object 12 clean_adm3 108906 non-null object 13 clean_adm4 108906 non-null object 14 country_id 108617 non-null object 15 data_lnk 108906 non-null object 16 distance_to_primary 108906 non-null object 17 distance_to_secondary 108906 non-null object 18 distance_to_tertiary 108906 non-null object 19 distance_to_city 108906 non-null object 20 distance_to_town 108906 non-null object 21 usage_cap 108869 non-null object 22 is_urban 108906 non-null object 23 days_since_report 108906 non-null object 24 staleness_score 108906 non-null object 25 is_latest 108906 non-null bool 26 location_id 108906 non-null object 27 cluster_size 108906 non-null object 28 clean_country_id 108906 non-null object 29 country_name 108617 non-null object 30 water_tech 14322 non-null object 31 status 94815 non-null object 32 adm2 101633 non-null object 33 adm3 11408 non-null object 34 adm1 101306 non-null object 35 new_georeferenced_column_ 108906 non-null object 36 lat_lon_deg 108906 non-null object 37 public_data_source 108906 non-null object 38 count 108906 non-null object 39 created_timestamp 108906 non-null object 40 updated 108906 non-null object 41 water_source_clean 91467 non-null object 42 water_source_category 91467 non-null object 43 wpdx_id 107814 non-null object 44 rehab_priority 18220 non-null object 45 served_population 89341 non-null object 46 local_population 89341 non-null object 47 crucialness 79618 non-null object 48 pressure 79618 non-null object 49 install_year 89181 non-null object 50 management_clean 92281 non-null object 51 status_clean 89408 non-null object 52 activity_id 90774 non-null object 53 water_source 104056 non-null object 54 management 92417 non-null object 55 converted 88237 non-null object 56 pay 37268 non-null object 57 subjective_quality 4406 non-null object 58 scheme_id 11302 non-null object 59 notes 11075 non-null object 60 photo_lnk 5090 non-null object 61 lat_deg_original 1556 non-null object 62 lon_deg_original 1556 non-null object 63 fecal_coliform_presence 1310 non-null object 64 installer 4638 non-null object 65 orig_lnk 1364 non-null object 66 fecal_coliform_value 213 non-null object dtypes: bool(1), object(66) memory usage: 54.9+ MB . We see that all imported columns are of object type, and that we&#39;ll have to fix that next. . We exclude columns which have already been cleaned by the WPD team and stored in another &quot;clean&quot; column. We also exclude columns with links and urls. . uganda_water_df_clean = pd.DataFrame(uganda_water_df.drop(columns=[&#39;clean_country_id&#39;, &#39;activity_id&#39;, &#39;adm1&#39;, &#39;adm2&#39;, &#39;adm3&#39;, &#39;country_id&#39;, &#39;country_name&#39;, &#39;status&#39;, &#39;water_source&#39;, &#39;management&#39;, &#39;water_tech&#39;, &#39;orig_lnk&#39;, &#39;photo_lnk&#39;, &#39;data_lnk&#39;, &#39;public_data_source&#39;, &#39;converted&#39;, &#39;created_timestamp&#39;, &#39;days_since_report&#39;, &#39;updated&#39;])) # check current columns uganda_water_df_clean.columns . Index([&#39;row_id&#39;, &#39;source&#39;, &#39;lat_deg&#39;, &#39;lon_deg&#39;, &#39;report_date&#39;, &#39;status_id&#39;, &#39;water_tech_clean&#39;, &#39;_water_tech_category&#39;, &#39;facility_type&#39;, &#39;clean_country_name&#39;, &#39;clean_adm1&#39;, &#39;clean_adm2&#39;, &#39;clean_adm3&#39;, &#39;clean_adm4&#39;, &#39;distance_to_primary&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_city&#39;, &#39;distance_to_town&#39;, &#39;usage_cap&#39;, &#39;is_urban&#39;, &#39;staleness_score&#39;, &#39;is_latest&#39;, &#39;location_id&#39;, &#39;cluster_size&#39;, &#39;new_georeferenced_column_&#39;, &#39;lat_lon_deg&#39;, &#39;count&#39;, &#39;water_source_clean&#39;, &#39;water_source_category&#39;, &#39;wpdx_id&#39;, &#39;rehab_priority&#39;, &#39;served_population&#39;, &#39;local_population&#39;, &#39;crucialness&#39;, &#39;pressure&#39;, &#39;install_year&#39;, &#39;management_clean&#39;, &#39;status_clean&#39;, &#39;pay&#39;, &#39;subjective_quality&#39;, &#39;scheme_id&#39;, &#39;notes&#39;, &#39;lat_deg_original&#39;, &#39;lon_deg_original&#39;, &#39;fecal_coliform_presence&#39;, &#39;installer&#39;, &#39;fecal_coliform_value&#39;], dtype=&#39;object&#39;) . print(&#39;fecal_coliform_presence distribution:&#39;, uganda_water_df_clean[&#39;fecal_coliform_presence&#39;].value_counts()) print(&#39;is_latest distribution:&#39;, uganda_water_df_clean[&#39;is_latest&#39;].value_counts()) print(&#39;is_urban distribution:&#39;, uganda_water_df_clean[&#39;is_urban&#39;].value_counts()) print(&#39;status_id distribution:&#39;, uganda_water_df_clean[&#39;status_id&#39;].value_counts()) . fecal_coliform_presence distribution: Present 1035 Absent 275 Name: fecal_coliform_presence, dtype: int64 is_latest distribution: True 96578 False 12328 Name: is_latest, dtype: int64 is_urban distribution: False 106175 True 2731 Name: is_urban, dtype: int64 status_id distribution: Yes 87600 No 18731 Unknown 2575 Name: status_id, dtype: int64 . We want to convert yes/no, True/False columns into 1s and 0s, for modelling&#39;s sake. We assume that water points that have an unknown status, are not working. . uganda_water_df_clean[&#39;fecal_coliform_presence&#39;] = uganda_water_df_clean[ &#39;fecal_coliform_presence&#39;].map({ &#39;Present&#39;: 1, &#39;Absent&#39;: 0 }) uganda_water_df_clean[&#39;is_latest&#39;] = uganda_water_df_clean[&#39;is_latest&#39;].astype( &#39;int64&#39;) uganda_water_df_clean[&#39;is_urban&#39;] = uganda_water_df_clean[&#39;is_urban&#39;].map({ True: 1, False: 0 }) uganda_water_df_clean[&#39;status_id&#39;] = uganda_water_df_clean[&#39;status_id&#39;].map({ &#39;Yes&#39;: 1, &#39;No&#39;: 0, &#39;Unknown&#39;: 0 }) # check uganda_water_df_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 108906 entries, 0 to 108905 Data columns (total 48 columns): # Column Non-Null Count Dtype -- -- 0 row_id 108906 non-null object 1 source 108906 non-null object 2 lat_deg 108906 non-null object 3 lon_deg 108906 non-null object 4 report_date 108906 non-null object 5 status_id 108906 non-null int64 6 water_tech_clean 26226 non-null object 7 _water_tech_category 26226 non-null object 8 facility_type 108906 non-null object 9 clean_country_name 108906 non-null object 10 clean_adm1 108906 non-null object 11 clean_adm2 108906 non-null object 12 clean_adm3 108906 non-null object 13 clean_adm4 108906 non-null object 14 distance_to_primary 108906 non-null object 15 distance_to_secondary 108906 non-null object 16 distance_to_tertiary 108906 non-null object 17 distance_to_city 108906 non-null object 18 distance_to_town 108906 non-null object 19 usage_cap 108869 non-null object 20 is_urban 0 non-null float64 21 staleness_score 108906 non-null object 22 is_latest 108906 non-null int64 23 location_id 108906 non-null object 24 cluster_size 108906 non-null object 25 new_georeferenced_column_ 108906 non-null object 26 lat_lon_deg 108906 non-null object 27 count 108906 non-null object 28 water_source_clean 91467 non-null object 29 water_source_category 91467 non-null object 30 wpdx_id 107814 non-null object 31 rehab_priority 18220 non-null object 32 served_population 89341 non-null object 33 local_population 89341 non-null object 34 crucialness 79618 non-null object 35 pressure 79618 non-null object 36 install_year 89181 non-null object 37 management_clean 92281 non-null object 38 status_clean 89408 non-null object 39 pay 37268 non-null object 40 subjective_quality 4406 non-null object 41 scheme_id 11302 non-null object 42 notes 11075 non-null object 43 lat_deg_original 1556 non-null object 44 lon_deg_original 1556 non-null object 45 fecal_coliform_presence 1310 non-null float64 46 installer 4638 non-null object 47 fecal_coliform_value 213 non-null object dtypes: float64(2), int64(2), object(44) memory usage: 39.9+ MB . num_columns = [&#39;distance_to_city&#39;, &#39;distance_to_primary&#39;, &#39;lat_deg&#39;, &#39;lat_deg_original&#39;, &#39;lon_deg&#39;, &#39;lon_deg_original&#39;, &#39;distance_to_secondary&#39;, &#39;distance_to_tertiary&#39;, &#39;distance_to_town&#39;, &#39;fecal_coliform_value&#39;, &#39;cluster_size&#39;, &#39;count&#39;, &#39;crucialness&#39;, &#39;install_year&#39;, &#39;local_population&#39;, &#39;pressure&#39;, &#39;rehab_priority&#39;, &#39;served_population&#39;, &#39;staleness_score&#39;, &#39;usage_cap&#39;] for col in num_columns: float_converter(uganda_water_df_clean, col) # check uganda_water_df_clean.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 108906 entries, 0 to 108905 Data columns (total 48 columns): # Column Non-Null Count Dtype -- -- 0 row_id 108906 non-null object 1 source 108906 non-null object 2 lat_deg 108906 non-null float32 3 lon_deg 108906 non-null float32 4 report_date 108906 non-null object 5 status_id 108906 non-null int64 6 water_tech_clean 26226 non-null object 7 _water_tech_category 26226 non-null object 8 facility_type 108906 non-null object 9 clean_country_name 108906 non-null object 10 clean_adm1 108906 non-null object 11 clean_adm2 108906 non-null object 12 clean_adm3 108906 non-null object 13 clean_adm4 108906 non-null object 14 distance_to_primary 108906 non-null float32 15 distance_to_secondary 108906 non-null float32 16 distance_to_tertiary 108906 non-null float32 17 distance_to_city 108906 non-null float32 18 distance_to_town 108906 non-null float32 19 usage_cap 108869 non-null float32 20 is_urban 0 non-null float64 21 staleness_score 108906 non-null float32 22 is_latest 108906 non-null int64 23 location_id 108906 non-null object 24 cluster_size 108906 non-null float32 25 new_georeferenced_column_ 108906 non-null object 26 lat_lon_deg 108906 non-null object 27 count 108906 non-null float32 28 water_source_clean 91467 non-null object 29 water_source_category 91467 non-null object 30 wpdx_id 107814 non-null object 31 rehab_priority 18220 non-null float32 32 served_population 89341 non-null float32 33 local_population 89341 non-null float32 34 crucialness 79618 non-null float32 35 pressure 79618 non-null float32 36 install_year 89181 non-null float32 37 management_clean 92281 non-null object 38 status_clean 89408 non-null object 39 pay 37268 non-null object 40 subjective_quality 4406 non-null object 41 scheme_id 11302 non-null object 42 notes 11075 non-null object 43 lat_deg_original 1556 non-null float32 44 lon_deg_original 1556 non-null float32 45 fecal_coliform_presence 1310 non-null float64 46 installer 4638 non-null object 47 fecal_coliform_value 213 non-null float32 dtypes: float32(20), float64(2), int64(2), object(24) memory usage: 31.6+ MB . date_converter(uganda_water_df_clean, &#39;report_date&#39;) uganda_water_df_clean[&#39;install_year&#39;]=pd.to_datetime(uganda_water_df_clean[&#39;install_year&#39;], format=&quot;%Y&quot;) # check print(uganda_water_df_clean[&#39;report_date&#39;].head()) print(uganda_water_df_clean[&#39;install_year&#39;].head()) . 0 2005-09-07 1 2005-09-07 2 2005-09-07 3 2005-09-07 4 2005-09-07 Name: report_date, dtype: datetime64[ns] 0 NaT 1 NaT 2 NaT 3 NaT 4 NaT Name: install_year, dtype: datetime64[ns] . str_columns = list(uganda_water_df_clean.select_dtypes(&quot;object&quot;).columns) # remove special characters from string columns for col in str_columns: uganda_water_df_clean[col].str.replace(&#39;[^ w s]&#39;, &#39;&#39;) . uganda_water_df_clean.isna().mean() * 100 . row_id 0.000000 source 0.000000 lat_deg 0.000000 lon_deg 0.000000 report_date 0.000000 status_id 0.000000 water_tech_clean 75.918682 _water_tech_category 75.918682 facility_type 0.000000 clean_country_name 0.000000 clean_adm1 0.000000 clean_adm2 0.000000 clean_adm3 0.000000 clean_adm4 0.000000 distance_to_primary 0.000000 distance_to_secondary 0.000000 distance_to_tertiary 0.000000 distance_to_city 0.000000 distance_to_town 0.000000 usage_cap 0.033974 is_urban 100.000000 staleness_score 0.000000 is_latest 0.000000 location_id 0.000000 cluster_size 0.000000 new_georeferenced_column_ 0.000000 lat_lon_deg 0.000000 count 0.000000 water_source_clean 16.012892 water_source_category 16.012892 wpdx_id 1.002700 rehab_priority 83.269976 served_population 17.965034 local_population 17.965034 crucialness 26.892917 pressure 26.892917 install_year 18.111950 management_clean 15.265458 status_clean 17.903513 pay 65.779663 subjective_quality 95.954309 scheme_id 89.622243 notes 89.830680 lat_deg_original 98.571245 lon_deg_original 98.571245 fecal_coliform_presence 98.797128 installer 95.741281 fecal_coliform_value 99.804418 dtype: float64 . We decide to drop columns which have more than 50% of its values that are missing. We deem these columns not be of good enough quality to be analysed. Some of these columns pertain to the presence of fecal coliform, the technology of the water point, the price of the water and other notes on the quality of the water available. . uganda_water_df_clean = uganda_water_df_clean.dropna( axis=1, thresh=0.5 * len(uganda_water_df_clean)) # check uganda_water_df_clean.isna().mean() * 100 . row_id 0.000000 source 0.000000 lat_deg 0.000000 lon_deg 0.000000 report_date 0.000000 status_id 0.000000 facility_type 0.000000 clean_country_name 0.000000 clean_adm1 0.000000 clean_adm2 0.000000 clean_adm3 0.000000 clean_adm4 0.000000 distance_to_primary 0.000000 distance_to_secondary 0.000000 distance_to_tertiary 0.000000 distance_to_city 0.000000 distance_to_town 0.000000 usage_cap 0.033974 staleness_score 0.000000 is_latest 0.000000 location_id 0.000000 cluster_size 0.000000 new_georeferenced_column_ 0.000000 lat_lon_deg 0.000000 count 0.000000 water_source_clean 16.012892 water_source_category 16.012892 wpdx_id 1.002700 served_population 17.965034 local_population 17.965034 crucialness 26.892917 pressure 26.892917 install_year 18.111950 management_clean 15.265458 status_clean 17.903513 dtype: float64 . The documentation informs us that this dataset is not supposed to have any duplicate columns or rows. . # uganda_water_df_clean.duplicated().sum() . # uganda_water_df_clean.T.duplicated().sum() . We impute the missing values in the remaining columns with the median for their administrative region. We first choose the lowest level, clean_adm4, then if there are remaining missing values we choose the second lowest clean_adm3 and so on. We choose the median so that it is not too sensitive to outliers. . uganda_water_df_clean_numerical = uganda_water_df_clean[ uganda_water_df_clean.select_dtypes(exclude=&#39;object&#39;).columns] # check uganda_water_df_clean_numerical.head() . lat_deg lon_deg report_date status_id distance_to_primary distance_to_secondary distance_to_tertiary distance_to_city distance_to_town usage_cap staleness_score is_latest cluster_size count served_population local_population crucialness pressure install_year . 0 0.158537 | 30.490643 | 2005-09-07 | 1 | 37666.023438 | 4875.484375 | 23.399448 | 45104.835938 | 32223.873047 | 250.0 | 14.327719 | 0 | 76.0 | 1.0 | NaN | NaN | NaN | NaN | NaT | . 1 0.070597 | 30.415651 | 2005-09-07 | 1 | 35843.273438 | 2602.279297 | 971.238464 | 38419.558594 | 24194.054688 | 250.0 | 14.327719 | 0 | 8.0 | 1.0 | NaN | NaN | NaN | NaN | NaT | . 2 0.158667 | 30.490551 | 2005-09-07 | 1 | 37651.726562 | 4860.169922 | 34.916096 | 45094.210938 | 32236.693359 | 250.0 | 14.327719 | 0 | 76.0 | 1.0 | NaN | NaN | NaN | NaN | NaT | . 3 0.430480 | 30.751951 | 2005-09-07 | 0 | 14592.108398 | 16548.333984 | 1269.275391 | 58369.609375 | 23365.746094 | 250.0 | 14.327719 | 1 | 1.0 | 1.0 | 1.0 | 25.0 | 0.04 | 0.004 | NaT | . 4 -0.134680 | 30.351593 | 2005-09-07 | 1 | 29073.130859 | 6369.317871 | 3270.906982 | 45044.160156 | 16042.707031 | 250.0 | 14.327719 | 0 | 2.0 | 1.0 | NaN | NaN | NaN | NaN | NaT | . null_cols = uganda_water_df_clean_numerical.isna().sum() cols_to_impute = null_cols[null_cols &gt; 0].index cols_to_impute = cols_to_impute.drop(&#39;install_year&#39;) # check cols_to_impute . Index([&#39;usage_cap&#39;, &#39;served_population&#39;, &#39;local_population&#39;, &#39;crucialness&#39;, &#39;pressure&#39;], dtype=&#39;object&#39;) . for col in cols_to_impute: plt.figure() sns.distplot(uganda_water_df_clean[col]) plt.axvline(uganda_water_df_clean[col].mean(), c=&#39;r&#39;, label=&#39;mean&#39;) plt.axvline(uganda_water_df_clean[col].median(), c=&#39;gold&#39;, label=&#39;median&#39;) plt.legend() plt.title(f&#39;Density plot of {col}&#39;) plt.show() . We can confirm that the median is the better choice as it represents our data better. . for col in cols_to_impute: missing_to_regional_median(uganda_water_df_clean, col, &#39;clean_adm4&#39;) # check uganda_water_df_clean.isna().sum() . row_id 0 source 0 lat_deg 0 lon_deg 0 report_date 0 status_id 0 facility_type 0 clean_country_name 0 clean_adm1 0 clean_adm2 0 clean_adm3 0 clean_adm4 0 distance_to_primary 0 distance_to_secondary 0 distance_to_tertiary 0 distance_to_city 0 distance_to_town 0 usage_cap 0 staleness_score 0 is_latest 0 location_id 0 cluster_size 0 new_georeferenced_column_ 0 lat_lon_deg 0 count 0 water_source_clean 17439 water_source_category 17439 wpdx_id 1092 served_population 8 local_population 8 crucialness 113 pressure 113 install_year 19725 management_clean 16625 status_clean 19498 dtype: int64 . for col in cols_to_impute: missing_to_regional_median(uganda_water_df_clean, col, &#39;clean_adm3&#39;) # check uganda_water_df_clean.isna().sum() . row_id 0 source 0 lat_deg 0 lon_deg 0 report_date 0 status_id 0 facility_type 0 clean_country_name 0 clean_adm1 0 clean_adm2 0 clean_adm3 0 clean_adm4 0 distance_to_primary 0 distance_to_secondary 0 distance_to_tertiary 0 distance_to_city 0 distance_to_town 0 usage_cap 0 staleness_score 0 is_latest 0 location_id 0 cluster_size 0 new_georeferenced_column_ 0 lat_lon_deg 0 count 0 water_source_clean 17439 water_source_category 17439 wpdx_id 1092 served_population 0 local_population 0 crucialness 0 pressure 0 install_year 19725 management_clean 16625 status_clean 19498 dtype: int64 . for col in cols_to_impute: missing_to_regional_median(uganda_water_df_clean, col, &#39;clean_adm2&#39;) # check uganda_water_df_clean.isna().sum() . row_id 0 source 0 lat_deg 0 lon_deg 0 report_date 0 status_id 0 facility_type 0 clean_country_name 0 clean_adm1 0 clean_adm2 0 clean_adm3 0 clean_adm4 0 distance_to_primary 0 distance_to_secondary 0 distance_to_tertiary 0 distance_to_city 0 distance_to_town 0 usage_cap 0 staleness_score 0 is_latest 0 location_id 0 cluster_size 0 new_georeferenced_column_ 0 lat_lon_deg 0 count 0 water_source_clean 17439 water_source_category 17439 wpdx_id 1092 served_population 0 local_population 0 crucialness 0 pressure 0 install_year 19725 management_clean 16625 status_clean 19498 dtype: int64 . for col in cols_to_impute: missing_to_regional_median(uganda_water_df_clean, col, &#39;clean_adm1&#39;) # check uganda_water_df_clean.isna().sum() . row_id 0 source 0 lat_deg 0 lon_deg 0 report_date 0 status_id 0 facility_type 0 clean_country_name 0 clean_adm1 0 clean_adm2 0 clean_adm3 0 clean_adm4 0 distance_to_primary 0 distance_to_secondary 0 distance_to_tertiary 0 distance_to_city 0 distance_to_town 0 usage_cap 0 staleness_score 0 is_latest 0 location_id 0 cluster_size 0 new_georeferenced_column_ 0 lat_lon_deg 0 count 0 water_source_clean 17439 water_source_category 17439 wpdx_id 1092 served_population 0 local_population 0 crucialness 0 pressure 0 install_year 19725 management_clean 16625 status_clean 19498 dtype: int64 . for col in cols_to_impute: uganda_water_df_clean[col] = uganda_water_df_clean[col].fillna( uganda_water_df_clean[col].median()) # check remaining null values uganda_water_df_clean.isna().sum() . row_id 0 source 0 lat_deg 0 lon_deg 0 report_date 0 status_id 0 facility_type 0 clean_country_name 0 clean_adm1 0 clean_adm2 0 clean_adm3 0 clean_adm4 0 distance_to_primary 0 distance_to_secondary 0 distance_to_tertiary 0 distance_to_city 0 distance_to_town 0 usage_cap 0 staleness_score 0 is_latest 0 location_id 0 cluster_size 0 new_georeferenced_column_ 0 lat_lon_deg 0 count 0 water_source_clean 17439 water_source_category 17439 wpdx_id 1092 served_population 0 local_population 0 crucialness 0 pressure 0 install_year 19725 management_clean 16625 status_clean 19498 dtype: int64 . We will not fill the non-numeric columns that still have missing values as the proportion of missing values is too great (15-25%). We will decide what to do with them later in our analysis. We must do this with great care as omitting or filling these columns/rows will have a large impact on the dataset. . uganda_water_df_clean.to_csv(data_filepath + &#39;ta_1_uganda_water_df_clean.csv&#39;) . Image(dictionary_filepath+&quot;1A-Water-Dictionary.png&quot;) . # #constructing columns of interest # median_columns_adm1=list(cols_to_impute ) # median_columns_adm1.append(&#39;clean_adm1&#39;) # #group by adm2, with median # median_adm1=uganda_water_df_clean[median_columns_adm1].groupby(&#39;clean_adm1&#39;).median() # median_adm1.reset_index(inplace=True) # #merge median dataset with original dataset # uganda_water_df_clean=pd.merge(uganda_water_df_clean, median_adm1, how=&#39;left&#39;, # left_on=uganda_water_df_clean[&#39;clean_adm1&#39;], # right_on=median_adm1[&#39;clean_adm1&#39;], suffixes=(None, &#39;_median_adm1&#39;)) # #fill null values with the median value of its region (adm2) # for col in cols_to_impute: # uganda_water_df_clean[col] = uganda_water_df_clean[col].fillna(uganda_water_df_clean # [f&#39;{col}_median_adm1&#39;]) # #removing key column resulting from the merge # del uganda_water_df_clean[uganda_water_df_clean.columns[0]] # uganda_water_df_clean.head() # #check remaining null values # uganda_water_df_clean.isna().sum() .",
            "url": "https://thomas0299.github.io/futuristic-platipus/fastpages/jupyter/2022/08/16/ta_02_access-water_data.html",
            "relUrl": "/fastpages/jupyter/2022/08/16/ta_02_access-water_data.html",
            "date": " • Aug 16, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Thomas, I am an economist transitioning into Data Science. . Passionate about statistics, machine learning, causal inference and econometrics. | Interested in complexity science, network theory and agent based models. | Fascinated about edible insects, novel food trends and the ways to improve our food supply chain. | Excited by the circular economy and finding solutions to e-waste through entrepreneurship . | Loves weightlifting. | . Don’t hesitate to get in touch: Linkedin Medium University email Personal email .",
          "url": "https://thomas0299.github.io/futuristic-platipus/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://thomas0299.github.io/futuristic-platipus/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}